paste0(df_all_cor$PO4_flag, "; PO4 checks out of range"),
"PO4 checks out of range"
)
}
cat("Assess Blanks")
#Pull out check standards from raw file
NOx_blks <- df_all %>%
filter(str_detect(Sample_Name, "CCB"))%>%
mutate(rep = row_number())
NH3_chks <- df_all %>%
filter(Test == "Ammonia 2")%>%
filter(str_detect(Sample_Name, "Blank"))%>%
mutate(rep = row_number())
PO4_chks <- df_all %>%
filter(Test == "o-PHOS 0.3")%>%
filter(str_detect(Sample_Name, "Blank"))%>%
mutate(rep = row_number())
#Pull out samples from df_all to calc quantile
samples <- df_all %>%
filter(str_detect(Sample_Name, c("GCW|GWI|MSM|SWH")))
#Calculating the lowest 25% of sample concentrations to compare to the blank concentrations
blk_flag_NOx <- samples %>%
filter(Test == "Vanadium NOx") %>%
summarise(Q1 = quantile(Conc, 0.25))   #this gives you the lower 25% quartile of the data
NOx_blks$NOx_diff_flag <-  ifelse(NOx_blks$Conc <= blk_flag_NOx, 'YES', 'NO, rerun')
blk_flag_NH3 <- samples %>%
filter(Test == "Ammonia 2") %>%
summarise(Q1 = quantile(Conc, 0.25))   #this gives you the lower 25% quartile of the data
NH3_chks$NH3_diff_flag <-  ifelse(NH3_chks$Conc <= blk_flag_NH3, 'YES', 'NO, rerun')
blk_flag_PO4 <- samples %>%
filter(Test == "o-PHOS 0.3") %>%
summarise(Q1 = quantile(Conc, 0.25))   #this gives you the lower 25% quartile of the data
PO4_chks$PO4_diff_flag <-  ifelse(PO4_chks$Conc <= blk_flag_PO4, 'YES', 'NO, rerun')
#calculate the percent of check standards that are within the range based on the flag
NOx_blks_percent <- (sum(NOx_blks$NOx_diff_flag == "YES")/nrow(NOx_blks))*100
NH3_blks_percent <- (sum(NH3_chks$NH3_diff_flag == "YES")/nrow(NH3_chks))*100
PO4_blks_percent <- (sum(PO4_chks$PO4_diff_flag == "YES")/nrow(PO4_chks))*100
#report out if flags indicate need for rerun
ifelse(NOx_blks_percent >= 60,
">60% of NOx Blank concentrations are lower than the lower 25% quartile of samples - PROCEED",
"<60% of NOx blaks are lower 25% quartile of samples - REASSESS")
ifelse(NH3_blks_percent >= 60,
">60% of NH3 Blank concentrations are lower than the lower 25% quartile of samples - PROCEED",
"<60% of NH3 blaks are lower 25% quartile of samples - REASSESS")
ifelse(PO4_blks_percent >= 60,
">60% of PO4 Blank concentrations are lower than the lower 25% quartile of samples- PROCEED",
"<60% of PO4 blaks are lower 25% quartile of samples - REASSESS")
#plotting the blanks compared to the lower 25% of conc (what the flag is)
NOx_blks_plot <-  ggplot(data = NOx_blks, aes(x = rep, y = Conc, fill=NOx_diff_flag)) +
geom_bar(stat = 'identity') +
scale_fill_manual(values = c("YES" = "deepskyblue3", "NO, rerun" = "darkred")) +
theme_classic() + labs(x= " ", y="NOx (mg/L)", title="NOx Blanks") +
theme(legend.position="bottom") +
geom_hline(yintercept= as.numeric(blk_flag_NOx), linetype="dashed",
color = "black", linewidth=1)  +
guides(fill=guide_legend(title="Blank Conc <25% Quartile Samples"))
NH3_blks_plot <-  ggplot(data = NH3_chks, aes(x = rep, y = Conc, fill=NH3_diff_flag)) +
geom_bar(stat = 'identity') +
scale_fill_manual(values = c("YES" = "deepskyblue3", "NO, rerun" = "darkred")) +
theme_classic() + labs(x= " ", y="NH3  (mg/L)", title="NH3 Blanks") +
theme(legend.position="bottom") +
geom_hline(yintercept=as.numeric(blk_flag_NH3), linetype="dashed",
color = "black", linewidth=1)  +
guides(fill=guide_legend(title="Blank Conc <25% Quartile Samples"))
PO4_blks_plot <-  ggplot(data = PO4_chks, aes(x = rep, y = Conc, fill=PO4_diff_flag)) +
geom_bar(stat = 'identity') +
scale_fill_manual(values = c("YES" = "deepskyblue3", "NO, rerun" = "darkred")) +
theme_classic() + labs(x= " ", y="PO4 (mg/L)", title="PO4 Blanks") +
theme(legend.position="bottom") +
geom_hline(yintercept=as.numeric(blk_flag_PO4), linetype="dashed",
color = "black", linewidth=1)  +
guides(fill=guide_legend(title="Blank Conc <25% Quartile Samples"))
#Combined Plot
Blks_Plots <- ggarrange(
NOx_blks_plot,
NH3_blks_plot,
PO4_blks_plot,   # (you had NH3 twice!)
nrow = 1,
ncol = 3,
common.legend = TRUE,
legend = "bottom")
print(Blks_Plots)
#find average of run blanks for flagging samples later
# Compute averages
blk_avg_NOx <- mean(NOx_blks$Conc, na.rm = TRUE)
blk_avg_NH3 <- mean(NH3_chks$Conc, na.rm = TRUE)
blk_avg_PO4 <- mean(PO4_chks$Conc, na.rm = TRUE)
# Create a data frame
blank_avgs <- data.frame(
Test = c("NOx", "NH3", "PO4"),
Blank_Mean_Conc = c(blk_avg_NOx, blk_avg_NH3, blk_avg_PO4)
)
# Pretty print
knitr::kable(blank_avgs, caption = "Mean Concentration of Blanks", digits = 4)
#write out a flag to the sample dataframe if more than 60% of the blanks are above the lower 25% quantile of samples
if (NOx_blks_percent <= chks_flag) {
df_all_cor$NOx_flag <- ifelse(
df_all_cor$NOx_flag != "",
paste0(df_all_cor$NOx_flag, "; NOx blanks out of range"),
"NOx blanks out of range"
)
}
if (NH3_blks_percent <= chks_flag) {  # assuming you have tn_chks_percent similarly
df_all_cor$NH3_flag <- ifelse(
df_all_cor$NH3_flag != "",
paste0(df_all_cor$NH3_flag, "; NH3 blanks out of range"),
"NH3 blanks out of range"
)
}
if (PO4_blks_percent <= chks_flag) {  # assuming you have tn_chks_percent similarly
df_all_cor$PO4_flag <- ifelse(
df_all_cor$PO4_flag != "",
paste0(df_all_cor$PO4_flag, "; PO4 blanks out of range"),
"PO4 blanks out of range"
)
}
cat("Analyze Duplicates")
#Getting dataframe of just duplicated samples
df_NOx_dup <- df_all_cor %>%
filter(Test == "Vanadium NOx") %>%
filter(
!grepl("CCV|CCB|Standard|Auto Spike|Abs_Chk_20ppt|Abs_Chk_10ppt", Sample_Name, ignore.case = TRUE),
#^removes autospice, ccv, ccb, standards
!is.na(Sample_Name),                                         # Remove NA
!grepl("^\\d+$", Sample_Name),                               # removes all numbers
!grepl("^\\d{1,2}/\\d{1,2}/\\d{2,4}", Sample_Name)) %>%      # removes all date/time
mutate(`Duplicate?` = if_else(                                  # adds duplicate column
grepl("Duplicate", Sample_Name, ignore.case = TRUE),         # keeps sample ID if there
lag(Sample_Name),                                            # get previous row's SampleID
Sample_Name)) %>%                                            # keeps sample ID if not duplicate
group_by(`Duplicate?`) %>%                                      # groups by duplicate
filter(n() > 1) %>%                                             # filters anything that appears more than once
ungroup() %>%
transmute(
Pair_ID = `Duplicate?`,                                      # changing heading to pair_id
Sample_Name,                                                 #keeping sample name and conc
Conc,                                                        #if sample name duplicate then put duplicate
Type = if_else(str_detect(Sample_Name, "Duplicate"), "Duplicate", "Original"))  #, if not put original to ID
df_NH3_dup <- df_all_cor %>%
filter(Test == "Ammonia 2") %>%
filter(
!grepl("CCV|CCB|Blank|1mg/L ammonia|Abs_Chk_20ppt|Abs_Chk_10ppt|Standard|Auto Spike", Sample_Name, ignore.case = TRUE),
#^removes autospice, ccv, ccb, standards
!is.na(Sample_Name),                                         # Remove NA
!grepl("^\\d+$", Sample_Name),                               # removes all numbers
!grepl("^\\d{1,2}/\\d{1,2}/\\d{2,4}", Sample_Name)) %>%      # removes all date/time
mutate(`Duplicate?` = if_else(                                  # adds duplicate column
grepl("Duplicate", Sample_Name, ignore.case = TRUE),         # keeps sample ID if there
lag(Sample_Name),                                            # get previous row's SampleID
Sample_Name)) %>%                                            # keeps sample ID if not duplicate
group_by(`Duplicate?`) %>%                                      # groups by duplicate
filter(n() > 1) %>%                                             # filters anything that appears more than once
ungroup() %>%
transmute(
Pair_ID = `Duplicate?`,                                      # changing heading to pair_id
Sample_Name,                                                 #keeping sample name and conc
Conc,                                                        #if sample name duplicate then put duplicate
Type = if_else(str_detect(Sample_Name, "Duplicate"), "Duplicate", "Original"))  #, if not put original to ID
df_PO4_dup <- df_all_cor %>%
filter(Test == "o-PHOS 0.3") %>%
filter(
!grepl("CCV|CCB|Standard|Auto Spike|Blank|1mg/L ammonia|Abs_Chk_20ppt|Abs_Chk_10ppt|0.15 mg/L", Sample_Name, ignore.case = TRUE),
#^removes autospice, ccv, ccb, standards
!is.na(Sample_Name),                                         # Remove NA
!grepl("^\\d+$", Sample_Name),                               # removes all numbers
!grepl("^\\d{1,2}/\\d{1,2}/\\d{2,4}", Sample_Name)) %>%      # removes all date/time
mutate(`Duplicate?` = if_else(                                  # adds duplicate column
grepl("Duplicate", Sample_Name, ignore.case = TRUE),         # keeps sample ID if there
lag(Sample_Name),                                            # get previous row's SampleID
Sample_Name)) %>%                                            # keeps sample ID if not duplicate
group_by(`Duplicate?`) %>%                                      # groups by duplicate
filter(n() > 1) %>%                                             # filters anything that appears more than once
ungroup() %>%
transmute(
Pair_ID = `Duplicate?`,                                      # changing heading to pair_id
Sample_Name,                                                 #keeping sample name and conc
Conc,                                                        #if sample name duplicate then put duplicate
Type = if_else(str_detect(Sample_Name, "Duplicate"), "Duplicate", "Original"))
# Duplicate Stats
Nox_dup_chk <- df_NOx_dup %>%
group_by(Pair_ID) %>%  # Use Pair_ID as it groups Originals and Duplicates
filter(n_distinct(Type) == 2) %>%  # Keep only groups that have both Original and Duplicate
summarise(
OG_Conc = Conc[Type == "Original"],
Dup_Conc = Conc[Type == "Duplicate"],
Mean_Conc = mean(c(OG_Conc, Dup_Conc)),
SD_Conc = sd(c(OG_Conc, Dup_Conc)),
CV = (SD_Conc / Mean_Conc) * 100,
pct_diff = abs(Dup_Conc - OG_Conc) / Mean_Conc * 100,
NOx_diff_flag = ifelse(abs(CV) < 10, "YES", "NO, rerun"),
.groups = "drop")
NH3_dup_chk <- df_NH3_dup %>%
group_by(Pair_ID) %>%  # Use Pair_ID as it groups Originals and Duplicates
filter(n_distinct(Type) == 2) %>%  # Keep only groups that have both Original and Duplicate
summarise(
OG_Conc = Conc[Type == "Original"],
Dup_Conc = Conc[Type == "Duplicate"],
Mean_Conc = mean(c(OG_Conc, Dup_Conc)),
SD_Conc = sd(c(OG_Conc, Dup_Conc)),
CV = (SD_Conc / Mean_Conc) * 100,
pct_diff = abs(Dup_Conc - OG_Conc) / Mean_Conc * 100,
NH3_diff_flag = ifelse(abs(CV) < 10, "YES", "NO, rerun"),
.groups = "drop")
PO4_dup_chk <- df_PO4_dup %>%
group_by(Pair_ID) %>%  # Use Pair_ID as it groups Originals and Duplicates
filter(n_distinct(Type) == 2) %>%  # Keep only groups that have both Original and Duplicate
summarise(
OG_Conc = Conc[Type == "Original"],
Dup_Conc = Conc[Type == "Duplicate"],
Mean_Conc = mean(c(OG_Conc, Dup_Conc)),
SD_Conc = sd(c(OG_Conc, Dup_Conc)),
CV = (SD_Conc / Mean_Conc) * 100,
pct_diff = abs(Dup_Conc - OG_Conc) / Mean_Conc * 100,
PO4_diff_flag = ifelse(abs(CV) < 10, "YES", "NO, rerun"),
.groups = "drop")
#calculate the percent of check standards that are within the range based on the flag
NOx_dup_percent <- (sum(Nox_dup_chk$NOx_diff_flag == "YES")/nrow(Nox_dup_chk))*100
NH3_dup_percent <- (sum(NH3_dup_chk$NH3_diff_flag == "YES")/nrow(NH3_dup_chk))*100
PO4_dup_percent <- (sum(PO4_dup_chk$PO4_diff_flag == "YES")/nrow(PO4_dup_chk))*100
#dup flag report out
ifelse(NOx_dup_percent >= chks_flag,
">60% of NOx Duplicates have a CV <10% - PROCEED",
"<60% of NOx Duplicates have a CV <10% - REASSESS")
ifelse(NH3_dup_percent >= chks_flag,
">60% of NH3 Duplicates have a CV <10% - PROCEED",
"<60% of NH3 Duplicates have a CV <10% - REASSESS")
ifelse(PO4_dup_percent >= chks_flag,
">60% of PO4 Duplicates have a CV <10% - PROCEED",
"<60% of PO4 Duplicates have a CV <10% - REASSESS")
#Create row numbers for plotting
Nox_dup_chk <- Nox_dup_chk %>%
mutate(row_num = row_number())
NH3_dup_chk <- NH3_dup_chk %>%
mutate(row_num = row_number())
PO4_dup_chk <- PO4_dup_chk %>%
mutate(row_num = row_number())
#plot dups output as a bar graph to easily check - want any over 10% to be red need to work on this
NOx_dups_plot <- ggplot(data =Nox_dup_chk, aes(x =Pair_ID, y =CV, fill=NOx_diff_flag)) +
geom_bar(stat = 'identity') +
theme_classic() +
labs(x= "Sample ID", y="CV between dups", title = "NOx Duplicates") +
scale_fill_manual(values = c("YES" = "darkslateblue", "NO, rerun" = "darkred")) +
theme(legend.position="none") +
geom_hline(yintercept=10, linetype="dashed",
color = "black", size=1)  +
guides(fill=guide_legend(title="CV Between Dups <10%"))+
theme(axis.text.x = element_text(angle = 90, hjust = 0.5))
NH3_dups_plot <- ggplot(data = NH3_dup_chk, aes(x =Pair_ID, y =CV, fill=NH3_diff_flag)) +
geom_bar(stat = 'identity') +
theme_classic() +
labs(x= "Sample ID", y="CV between dups", title = "NH3 Duplicates") +
scale_fill_manual(values = c("YES" = "darkslateblue", "NO, rerun" = "darkred")) +
theme(legend.position="none") +
geom_hline(yintercept=10, linetype="dashed",
color = "black", size=1) +
guides(fill=guide_legend(title="CV Between Dups <10%"))+
theme(axis.text.x = element_text(angle = 90, hjust = 0.5))
PO4_dups_plot <- ggplot(data =PO4_dup_chk, aes(x =Pair_ID, y =CV, fill=PO4_diff_flag)) +
geom_bar(stat = 'identity') +
theme_classic() +
labs(x= "Sample ID", y="CV between dups", title = "PO4 Duplicates") +
scale_fill_manual(values = c("YES" = "darkslateblue", "NO, rerun" = "darkred")) +
theme(legend.position="none") +
geom_hline(yintercept=10, linetype="dashed",
color = "black", size=1) +
guides(fill=guide_legend(title="CV Between Dups <10%"))+
theme(axis.text.x = element_text(angle = 90, hjust = 0.5))
#Combined Plot
Dups_Plots <- ggarrange(
NOx_dups_plot,
NH3_dups_plot,
PO4_dups_plot,   # (you had NH3 twice!)
nrow = 1,
ncol = 3,
common.legend = TRUE,
legend = "bottom")
print(Dups_Plots)
if (PO4_blks_percent <= chks_flag) {  # assuming you have tn_chks_percent similarly
df_all_cor$PO4_flag <- ifelse(
df_all_cor$PO4_flag != "",
paste0(df_all_cor$PO4_flag, "; PO4 blanks out of range"),
"PO4 blanks out of range"
)
}
#write out a flag to the sample dataframe if more than 60% of the dups have CVs out of range
if (any(NOx_dup_percent <= chks_flag)) {
df_all_cor$NOx_flag <- ifelse(
df_all_cor$NOx_flag != "",
paste0(df_all_cor$NOx_flag, "; NOx dups out of range"),
"NOx dups out of range"
)
}
if (NH3_dup_percent <= chks_flag) {  # assuming you have tn_chks_percent similarly
df_all_cor$NH3_flag <- ifelse(
df_all_cor$NH3_flag != "",
paste0(df_all_cor$NH3_flag, "; NH3 dups out of range"),
"NH3 dups out of range"
)
}
if (PO4_dup_percent <= chks_flag) {  # assuming you have tn_chks_percent similarly
df_all_cor$PO4_flag <- ifelse(
df_all_cor$PO4_flag != "",
paste0(df_all_cor$PO4_flag, "; PO4 dups out of range"),
"PO4 dups out of range"
)
}
#getting spikes and samples pulled
df_NOx_spk <- df_all_cor %>%
filter(Test == "Vanadium NOx") %>%
filter(
!grepl("CCV|CCB|Standard|Duplicate", Sample_Name, ignore.case = TRUE),
#^removes dup, ccv, ccb, standards
!is.na(Sample_Name),                                     # Remove NA
!grepl("^\\d+$", Sample_Name),                           # removes all numbers
!grepl("^\\d{1,2}/\\d{1,2}/\\d{2,4}", Sample_Name)) %>%  # removes all date/time
mutate(`Spike?` = if_else(                                  # adds duplicate column
grepl("Auto Spike", Sample_Name, ignore.case = TRUE),    # keeps sample ID if there
lag(Sample_Name),                                        # get previous row's SampleID
Sample_Name)) %>%                                        # keeps sample ID if not duplicate
group_by(`Spike?`) %>%                                      # groups by duplicate
filter(n() > 1) %>%                                         # filters anything that appears more than once
ungroup()  %>%
transmute(
Pair_ID = `Spike?`,
Sample_Name,
Conc,
Type = if_else(str_detect(Sample_Name, "Auto Spike"), "Auto_Spike", "Original"))
df_NH3_spk <- df_all_cor %>%
filter(Test == "Ammonia 2") %>%
filter(
!grepl("CCV|CCB|Blank|1mg/L ammonia|Standard|Duplicate", Sample_Name, ignore.case = TRUE),
#^removes dup, ccv, ccb, standards
!is.na(Sample_Name),                                         # Remove NA
!grepl("^\\d+$", Sample_Name),                               # removes all numbers
!grepl("^\\d{1,2}/\\d{1,2}/\\d{2,4}", Sample_Name)) %>%      # removes all date/time
mutate(`Spike?` = if_else(                                      # adds duplicate column
grepl("Auto Spike", Sample_Name, ignore.case = TRUE),        # keeps sample ID if there
lag(Sample_Name),                                            # get previous row's SampleID
Sample_Name)) %>%                                            # keeps sample ID if not duplicate
group_by(`Spike?`) %>%                                          # groups by duplicate
filter(n() > 1) %>%                                             # filters anything that appears more than once
ungroup()  %>%
transmute(
Pair_ID = `Spike?`,
Sample_Name,
Conc,
Type = if_else(str_detect(Sample_Name, "Auto Spike"), "Auto_Spike", "Original"))
df_PO4_spk <- df_all_cor %>%
filter(Test == "o-PHOS 0.3") %>%
filter(
!grepl("CCV|CCB|Standard|Duplicate|Blank|0.15 mg/L|peChk_NH3_PO4", Sample_Name, ignore.case = TRUE),
#^removes dup, ccv, ccb, standards
!is.na(Sample_Name),                                         # Remove NA
!grepl("^\\d+$", Sample_Name),                               # removes all numbers
!grepl("^\\d{1,2}/\\d{1,2}/\\d{2,4}", Sample_Name)) %>%      # removes all date/time
mutate(`Spike?` = if_else(                                     # adds duplicate column
grepl("Auto Spike", Sample_Name, ignore.case = TRUE),        # keeps sample ID if there
lag(Sample_Name),                                            # get previous row's SampleID
Sample_Name)) %>%                                            # keeps sample ID if not duplicate
group_by(`Spike?`) %>%                                          # groups by duplicate
filter(n() > 1) %>%                                             # filters anything that appears more than once
ungroup()  %>%
transmute(
Pair_ID = `Spike?`,
Sample_Name,
Conc,
Type = if_else(str_detect(Sample_Name, "Auto Spike"), "Auto_Spike", "Original"))
#checking and flagging against the expected spike conc
df_spk_NOx_chk <- df_NOx_spk %>%
select(Pair_ID, Conc, Type) %>%
pivot_wider(
names_from = Type,
values_from = Conc,
values_fn = mean,  # in case there are duplicates
names_prefix = "" ) %>%
rename(
Spike_Conc = Auto_Spike,
OG_Conc = Original) %>%
filter(!is.na(Spike_Conc), !is.na(OG_Conc)) %>%
rowwise() %>%# keep only rows with both
mutate(
Exp_Conc = OG_Conc + NOx_Spk,
Mean_Conc = mean(c(Spike_Conc, Exp_Conc), na.rm = TRUE),
Pct_Diff = abs(Spike_Conc - Exp_Conc) / Mean_Conc * 100,
SD_Conc = sd(c(Spike_Conc, Exp_Conc)),
CV = (SD_Conc / Mean_Conc) * 100,
Spike_diff_flag = ifelse(CV < 50, "YES", "NO, check"),
Test = "Vanadium NOx") %>%
ungroup()
df_spk_NH3_chk <- df_NH3_spk %>%
select(Pair_ID, Conc, Type) %>%
pivot_wider(
names_from = Type,
values_from = Conc,
values_fn = mean,  # in case there are duplicates
names_prefix = "" ) %>%
rename(
Spike_Conc = Auto_Spike,
OG_Conc = Original) %>%
filter(!is.na(Spike_Conc), !is.na(OG_Conc)) %>%
rowwise() %>%# keep only rows with both
mutate(
Exp_Conc = OG_Conc + NH3_Spk,
Mean_Conc = mean(c(Spike_Conc, Exp_Conc), na.rm = TRUE),
Pct_Diff = abs(Spike_Conc - Exp_Conc) / Mean_Conc * 100,
SD_Conc = sd(c(Spike_Conc, Exp_Conc)),
CV = (SD_Conc / Mean_Conc) * 100,
Spike_diff_flag = ifelse(CV < 50, "YES", "NO, check"),
Test = "Ammonia 2") %>%
ungroup()
df_spk_PO4_chk <- df_PO4_spk %>%
select(Pair_ID, Conc, Type) %>%
pivot_wider(
names_from = Type,
values_from = Conc,
values_fn = mean,  # in case there are duplicates
names_prefix = "" ) %>%
rename(
Spike_Conc = Auto_Spike,
OG_Conc = Original) %>%
filter(!is.na(Spike_Conc), !is.na(OG_Conc)) %>%
rowwise() %>%# keep only rows with both
mutate(
Exp_Conc = OG_Conc + PO4_Spk,
Mean_Conc = mean(c(Spike_Conc, Exp_Conc), na.rm = TRUE),
Pct_Diff = abs(Spike_Conc - Exp_Conc) / Mean_Conc * 100,
SD_Conc = sd(c(Spike_Conc, Exp_Conc)),
CV = (SD_Conc / Mean_Conc) * 100,
Spike_diff_flag = ifelse(CV < 50, "YES", "NO, check"),
Test = "o-PHOS 0.3") %>%
ungroup()
# Combining Auto Spike data frames
df_spk_combo <- bind_rows(df_spk_NOx_chk, df_spk_NH3_chk, df_spk_PO4_chk)
#add column for test ^^ aand then combine
#calculate the percent of check standards that are within the range based on the flag
NOx_spk_percent <- (sum(df_spk_NOx_chk$Spike_diff_flag == "YES")/nrow(df_spk_NOx_chk))*100
NH3_spk_percent <- (sum(df_spk_NH3_chk$Spike_diff_flag == "YES")/nrow(df_spk_NH3_chk))*100
PO4_spk_percent <- (sum(df_spk_PO4_chk$Spike_diff_flag == "YES")/nrow(df_spk_PO4_chk))*100
#spk flag report out
ifelse(NOx_spk_percent >= chks_flag,
">60% of Spikes have a CV <50% - PROCEED",
"<60% of Carbon Spikes have a CV <50% - REASSESS")
ifelse(NH3_spk_percent >= chks_flag,
">60% of Spikes have a CV <50% - PROCEED",
"<60% of Carbon Spikes have a CV <50% - REASSESS")
ifelse(PO4_spk_percent >= chks_flag,
">60% of Spikes have a CV <50% - PROCEED",
"<60% of Carbon Spikes have a CV <50% - REASSESS")
#plot spikes output as a bar graph to easily check - want any over 10% to be red need to work on this
NOx_spk_plot <- ggplot(data =df_spk_NOx_chk, aes(x =Pair_ID, y =CV, fill=Spike_diff_flag)) +
geom_bar(stat = 'identity') +
theme_classic() +
labs(x= "Sample ID", y="NOx N (mg/L)", title = "NOx Auto Spike CV") +
scale_fill_manual(values = c("YES" = "darkcyan", "NO, check" = "darkred")) +
theme(legend.position="none") +
geom_hline(yintercept=50, linetype="dashed",
color = "black", size=1)  +
guides(fill=guide_legend(title="CV Between Spks <50%"))+
theme(axis.text.x = element_text(angle = 90, hjust = 0.5))
NH3_spk_plot <- ggplot(data = df_spk_NH3_chk, aes(x =Pair_ID, y =CV, fill=Spike_diff_flag)) +
geom_bar(stat = 'identity') +
theme_classic() +
labs(x= "Sample ID", y="NH3 N(mg/L)", title = "NH3 Auto Spike CV") +
scale_fill_manual(values = c("YES" = "darkcyan", "NO, check" = "darkred")) +
theme(legend.position="none")  +
geom_hline(yintercept=50, linetype="dashed",
color = "black", size=1)  +
guides(fill=guide_legend(title="CV Between Spks <50%"))+
theme(axis.text.x = element_text(angle = 90, hjust = 0.5))
PO4_spk_plot <- ggplot(data =df_spk_PO4_chk, aes(x =Pair_ID, y =CV, fill=Spike_diff_flag)) +
geom_bar(stat = 'identity') +
theme_classic() +
labs(x= "Sample ID", y="PO4 P(mg/L)", title = "PO4 Auto Spike CV") +
scale_fill_manual(values = c("YES" = "darkcyan", "NO, check" = "darkred")) +
theme(legend.position="none")  +
geom_hline(yintercept=50, linetype="dashed",
color = "black", size=1)  +
guides(fill=guide_legend(title="CV Between Spks <50%"))+
theme(axis.text.x = element_text(angle = 90, hjust = 0.5))
Spk_Plots <- ggarrange(
NOx_spk_plot,
NH3_spk_plot,
PO4_spk_plot,   # (you had NH3 twice!)
nrow = 1,
ncol = 3,
common.legend = TRUE,
legend = "bottom")
print(Spk_Plots)
#write out a flag to the sample dataframe if more than 60% of the dups have CVs out of range
if (NOx_spk_percent <= chks_flag) {
df_all_cor$NOx_flag <- ifelse(
df_all_cor$NOx_flag != "",
paste0(df_all_cor$NOx_flag, "; NOx spikes out of range"),
"NOx spikes out of range"
)
}
if (NH3_spk_percent <= chks_flag) {
df_all_cor$NH3_flag <- ifelse(
df_all_cor$NH3_flag != "",
paste0(df_all_cor$NH3_flag, "; NH3 spikes out of range"),
"NH3 spikes out of range"
)
}
if (PO4_spk_percent <= chks_flag) {
df_all_cor$PO4_flag <- ifelse(
df_all_cor$PO4_flag != "",
paste0(df_all_cor$PO4_flag, "; PO4 spikes out of range"),
"PO4 spikes out of range"
)
}
View(df_all_cor)
View(df_all)
