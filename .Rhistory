dat_raw <- dat_raw[grep("DATAU", dat_raw, invert = TRUE)]
# Double irritatingly, if there's no remark, the software write \t\t, not
# \t""\t, causing a read error. Replace these instances
dat_raw <- gsub("\t\t", "\tnan\t", dat_raw, fixed = TRUE)
dat <- try({
readr::read_table(I(dat_raw), na = "nan", guess_max = 1e4)
})
# If the try() above succeeded, we haev a data frame and can process it
if(is.data.frame(dat)) {
message("\tRead in ", nrow(dat), " rows of data, ",
min(dat$DATE), " to ", max(dat$DATE))
message("\tInstrument serial number: ", sn)
dat$SN <- sn
message("\tInstrument time zone: ", tz)
# We record the time zone but don't convert the timestamps to it as
# that's not needed right now; metadata time is guaranteed to be same
dat$TIMESTAMP <- lubridate::ymd_hms(paste(dat$DATE, dat$TIME))
dat$TZ <- tz
# Remove unneeded Licor DATE and TIME columns
dat$DATE <- dat$TIME <- NULL
dat$Data_file <- basefn
return(dat)
} else {
warning("File read error for ", basefn)
errors <<- errors + 1
return(NULL)
}
}
dat <- lapply(data_files, read_ghg_data)
dat <- do.call("rbind", dat)
#| echo: false
#| output: asis
if(errors) cat("**<span style='color:red'>---> At least one error occurred! <---</span>**")
errors <- 0
# Function to read a metadata file given by 'fn', filename
# Returns NULL if there's an error reading
read_metadata <- function(fn) {
basefn <- basename(fn)
message(Sys.time(), " Processing ", basefn)
metadat_raw <- try({
read_excel(fn)
})
if(is.data.frame(metadat_raw)) {
if(!all(METADATA_REQUIRED_FIELDS %in% names(metadat_raw))) {
warning("Metadata file ", basefn, " doesn't have required fields!")
return(NULL)
}
metadat_raw$Metadata_file <- basefn
# Note that it's guaranteed that metadata time is instrument time,
# so we don't worry about any time zones right now
metadat <- metadat_raw
# Metadata files can, optionally, have "Dead_band" and "Msmt_length" columns
# If not present, insert those columns with NA values
if(!"Dead_band" %in% names(metadat)) {
metadat$Dead_band <- NA_real_
} else {
message("\tCustom Dead_band column exists")
}
if(!"Msmt_stop" %in% names(metadat)) {
metadat$Msmt_stop <- NA_real_
} else {
message("\tCustom Msmt_stop column exists")
}
} else {
warning("File read error for ", basefn)
errors <<- errors + 1
return(NULL)
}
metadat
}
metadat <- lapply(metadata_files, read_metadata)
metadat <- do.call("rbind", metadat)
if(!nrow(metadat)) {stop("No metadata read!")}
metadat$Obs <- seq_len(nrow(metadat))
View(metadat)
#| echo: false
#| output: asis
if(nrow(zero_matches)) {
cat("**<span style='color:red'>---> At least one metadata row had no matching data! <---</span>**\n\n")
}
# Table of zero-match data, if any
if(nrow(zero_matches)) {
knitr::kable(zero_matches)
}
#| echo: false
#| output: asis
unused_files <- setdiff(unique(dat$Data_file), unique(combined_dat$Data_file))
errors <- 0
# Function to read a metadata file given by 'fn', filename
# Returns NULL if there's an error reading
read_metadata <- function(fn) {
basefn <- basename(fn)
message(Sys.time(), " Processing ", basefn)
metadat_raw <- try({
read_excel(fn)
})
if(is.data.frame(metadat_raw)) {
if(!all(METADATA_REQUIRED_FIELDS %in% names(metadat_raw))) {
warning("Metadata file ", basefn, " doesn't have required fields!")
return(NULL)
}
metadat_raw$Metadata_file <- basefn
# Note that it's guaranteed that metadata time is instrument time,
# so we don't worry about any time zones right now
metadat <- metadat_raw
# Metadata files can, optionally, have "Dead_band" and "Msmt_length" columns
# If not present, insert those columns with NA values
if(!"Dead_band" %in% names(metadat)) {
metadat$Dead_band <- NA_real_
} else {
message("\tCustom Dead_band column exists")
}
if(!"Msmt_stop" %in% names(metadat)) {
metadat$Msmt_stop <- NA_real_
} else {
message("\tCustom Msmt_stop column exists")
}
} else {
warning("File read error for ", basefn)
errors <<- errors + 1
return(NULL)
}
metadat
}
metadat <- lapply(metadata_files, read_metadata)
metadat <- do.call("rbind", metadat)
if(!nrow(metadat)) {stop("No metadata read!")}
metadat$Obs <- seq_len(nrow(metadat))
# For each row of metadata, find corresponding observational data
zero_matches <- data.frame()
match_info <- data.frame()
matched_dat <- list()
for(i in seq_len(nrow(metadat))) {
ts <- metadat$Time_start[i]
start_time <- metadat$Date[i] + hour(ts) * 60 * 60 + minute(ts) * 60 + second(ts)
end_time <- start_time + params$MSMT_LENGTH_SEC
# Subset data following timestamp in metadata and store
x <- subset(dat, TIMESTAMP >= start_time & TIMESTAMP < end_time)
#  message("Metadata row ", i, " ", metadat$Plot[i], " start = ", start_time, " matched ", nrow(x), " data rows")
info <- data.frame(Row = i,
Plot = metadat$Plot[i],
start_time = start_time,
Rows_matched = nrow(x),
Min_timestamp = NA,
Max_timestamp = NA)
if(nrow(x)) {
# We have matched data!
x$Obs <- i
# Assign dead band: value given in Quarto params, but can be overridden in metadata
if(is.na(metadat$Dead_band[i])) {
x$DEAD_BAND_SEC <- params$DEAD_BAND_SEC
} else {
x$DEAD_BAND_SEC <- metadat$Dead_band[i]
}
# Assign stop time (in seconds, not including dead band): value given in
# Quarto params, but can be overridden in metadata
if(is.na(metadat$Msmt_stop[i])) {
x$MSMT_STOP_SEC <- params$MSMT_LENGTH_SEC
} else {
x$MSMT_STOP_SEC <- metadat$Msmt_stop[i]
}
# Calculate ELAPSED_SECS, which is relative time (in s) since start of measurement
x$ELAPSED_SECS <- time_length(interval(min(x$TIMESTAMP), x$TIMESTAMP), "seconds")
info$Min_timestamp <- min(x$TIMESTAMP)
info$Max_timestamp <- max(x$TIMESTAMP)
} else {
# No data matched the date and time given in this row of the metadata
message("\tWARNING; file: ", metadat$Metadata_file[i])
zero_matches <- rbind(zero_matches, data.frame(File = metadat$Metadata_file[i],
Row = i,
Date = metadat$Date[i],
Time_start = metadat$Time_start[i]))
}
match_info <- rbind(match_info, info)
matched_dat[[i]] <- x
}
# Combine all subsetted data together and merge with metadata
combined_dat <- do.call("rbind", matched_dat)
combined_dat <- merge(metadat, combined_dat, by = "Obs")
# Compute a few basic stats about the combined data
n <- nrow(combined_dat)
neg_CO2 <- sum(combined_dat$CO2 < 0, na.rm = TRUE)
na_CO2 <- sum(is.na(combined_dat$CO2), na.rm = TRUE)
na_CH4 <- sum(is.na(combined_dat$CH4), na.rm = TRUE)
datatable(match_info)
#| echo: false
#| output: asis
if(nrow(zero_matches)) {
cat("**<span style='color:red'>---> At least one metadata row had no matching data! <---</span>**\n\n")
}
# Table of zero-match data, if any
if(nrow(zero_matches)) {
knitr::kable(zero_matches)
}
#| echo: false
#| output: asis
unused_files <- setdiff(unique(dat$Data_file), unique(combined_dat$Data_file))
if(length(unused_files)) {
cat("**<span style='color:red'>---> At least one data file was unused! <---</span>**\n\n")
}
# Table of unused files, if any
if(length(unused_files)) {
knitr::kable(data.frame(Data_file = unused_files))
}
# Print distribution and (below) plot random subsample of CO2 data
OVERALL_PLOT_N <- 300
summary(combined_dat$CO2)
#| fig-width: 8
#| fig-height: 4
df_split <- split(combined_dat, rep(1:3, each = nrow(combined_dat) / 3))
for (obs_group in df_split) {
obs_group <- bind_rows(obs_group)
ylim_co2 <- quantile(obs_group$CO2, probs = c(0.05, 0.95), na.rm = TRUE)
dat_small <- obs_group[sample.int(n, OVERALL_PLOT_N, replace = TRUE),]
print(ggplot(dat_small, aes(TIMESTAMP, CO2, color=Plot)) +
geom_point(na.rm = TRUE) +
coord_cartesian(ylim = ylim_co2))
}
# Print distribution and (below) plot random subsample of CH4 data
summary(combined_dat$CH4)
#| fig-width: 8
#| fig-height: 4
for (obs_group in df_split) {
ylim_ch4 <- quantile(obs_group$CH4, probs = c(0.05, 0.95), na.rm = TRUE)
dat_small <- obs_group[sample.int(n, OVERALL_PLOT_N, replace = TRUE),]
print(ggplot(dat_small, aes(TIMESTAMP, CH4, color = Plot)) +
geom_point(na.rm = TRUE) +
coord_cartesian(ylim = ylim_ch4))
}
obs_list <- split(combined_dat, combined_dat$Obs)
grouped_obs_list <- split(obs_list, ceiling(seq_along(obs_list)/12))
for (obs_group in grouped_obs_list) {
for (list in obs_group) {
data.frame(list)
}
obs_group <- bind_rows(obs_group)
#| fig-width: 8
print(ggplot(obs_group, aes(ELAPSED_SECS, CO2, group = Obs)) +
geom_point(na.rm = TRUE, color = "purple") +
facet_wrap(~Plot + Date, scales = "free") +
# Plot both linear and curvilinear fits
#geom_smooth(method = lm, formula = 'y ~ poly(x, 2)', na.rm = TRUE, linetype = 2, color = "blue") +
geom_smooth(method = lm, formula = 'y ~ x', na.rm = TRUE, color = "black", linewidth = 0.5) +
geom_vline(aes(xintercept = DEAD_BAND_SEC), linetype = 2, color = "green") +
geom_vline(aes(xintercept = MSMT_STOP_SEC), linetype = 2, color = "red"))
print(ggplot(obs_group, aes(ELAPSED_SECS, CH4, group = Obs)) +
geom_point(na.rm = TRUE, color = "blue") +
facet_wrap(~Plot + Date, scales = "free") +
#geom_smooth(method = lm, formula = 'y ~ poly(x, 2)', na.rm = TRUE, linetype = 2, color = "blue") +
geom_smooth(method = lm, formula = 'y ~ x', na.rm = TRUE, color = "black", linewidth = 0.5) +
geom_vline(aes(xintercept = DEAD_BAND_SEC), linetype = 2, color = "green") +
geom_vline(aes(xintercept = MSMT_STOP_SEC), linetype = 2, color = "red"))
}
obs_list <- split(combined_dat, combined_dat$Obs)
grouped_obs_list <- split(obs_list, ceiling(seq_along(obs_list)/12))
for (obs_group in grouped_obs_list) {
for (list in obs_group) {
data.frame(list)
}
obs_group <- bind_rows(obs_group)
#| fig-width: 8
print(ggplot(obs_group, aes(ELAPSED_SECS, CO2, group = Obs)) +
geom_point(na.rm = TRUE, color = "orchid") +
facet_wrap(~Plot + Date, scales = "free") +
# Plot both linear and curvilinear fits
#geom_smooth(method = lm, formula = 'y ~ poly(x, 2)', na.rm = TRUE, linetype = 2, color = "blue") +
geom_smooth(method = lm, formula = 'y ~ x', na.rm = TRUE, color = "darkslateblue", linewidth = 0.5) +
geom_vline(aes(xintercept = DEAD_BAND_SEC), linetype = 2, color = "gray40") +
geom_vline(aes(xintercept = MSMT_STOP_SEC), linetype = 2, color = "black"))
print(ggplot(obs_group, aes(ELAPSED_SECS, CH4, group = Obs)) +
geom_point(na.rm = TRUE, color = "skyblue") +
facet_wrap(~Plot + Date, scales = "free") +
#geom_smooth(method = lm, formula = 'y ~ poly(x, 2)', na.rm = TRUE, linetype = 2, color = "blue") +
geom_smooth(method = lm, formula = 'y ~ x', na.rm = TRUE, color = "navy", linewidth = 0.5) +
geom_vline(aes(xintercept = DEAD_BAND_SEC), linetype = 2, color = "gray40") +
geom_vline(aes(xintercept = MSMT_STOP_SEC), linetype = 2, color = "black"))
}
library(fluxfinder)
summary(combined_dat)
View(combined_dat)
#| include: false
library(rmarkdown)
library(readr)
library(lubridate)
library(ggplot2)
theme_set(theme_bw())
library(ggrepel)
library(readxl)
library(broom)
library(DT)
library(MASS)
library(tidyr)
library(dplyr)
library(fluxfinder)
# These columns are REQUIRED to be present in the metadata file(s)
# (NB there are can be other columns present; they will be carried through to the results)
METADATA_REQUIRED_FIELDS <- c("Date", "Time_start", "Plot", "Area", "Volume", "Temp")
# Data files must end with ".txt" and may be in sub-folders
data_files <- list.files(params$data_folder,
pattern = "*txt$",
full.names = TRUE, recursive = TRUE)
# Metadata files must end with ".xlsx" and may be in sub-folders
metadata_files <- list.files(params$metadata_folder,
pattern = "*xlsx$",
full.names = TRUE, recursive = TRUE)
#SW made the metadata file a csv to be visable on Github and there is only one
#metadata_files <- "COMPASS_Synoptic_TreeFlux_Metadata_2023.csv"
#change units
#so we will use temp and volume from metadata
#using the fluxfinder conversion function to get nmol or umol units
combind_dat$CH4_nmol <- ffi_ppb_to_nmol(combind_dat$CH4,
volume = combined_dat$Volume, #m3
temp = combined_dat$Temp) #degrees C
#| include: false
library(rmarkdown)
library(readr)
library(lubridate)
library(ggplot2)
theme_set(theme_bw())
library(ggrepel)
library(readxl)
library(broom)
library(DT)
library(MASS)
library(tidyr)
library(dplyr)
library(fluxfinder)
# These columns are REQUIRED to be present in the metadata file(s)
# (NB there are can be other columns present; they will be carried through to the results)
METADATA_REQUIRED_FIELDS <- c("Date", "Time_start", "Plot", "Area", "Volume", "Temp")
# Data files must end with ".txt" and may be in sub-folders
data_files <- list.files(params$data_folder,
pattern = "*txt$",
full.names = TRUE, recursive = TRUE)
# Metadata files must end with ".xlsx" and may be in sub-folders
metadata_files <- list.files(params$metadata_folder,
pattern = "*xlsx$",
full.names = TRUE, recursive = TRUE)
#SW made the metadata file a csv to be visable on Github and there is only one
#metadata_files <- "COMPASS_Synoptic_TreeFlux_Metadata_2023.csv"
#change units
#so we will use temp and volume from metadata
#using the fluxfinder conversion function to get nmol or umol units
combined_dat$CH4_nmol <- ffi_ppb_to_nmol(combined_dat$CH4,
volume = combined_dat$Volume, #m3
temp = combined_dat$Temp) #degrees C
combined_dat$CO2_umol <- ffi_ppm_to_umol(combind_dat$CO2,
volume = combined_dat$Volume, #m3
temp = combined_dat$Temp) #degrees C
#| include: false
library(rmarkdown)
library(readr)
library(lubridate)
library(ggplot2)
theme_set(theme_bw())
library(ggrepel)
library(readxl)
library(broom)
library(DT)
library(MASS)
library(tidyr)
library(dplyr)
library(fluxfinder)
# These columns are REQUIRED to be present in the metadata file(s)
# (NB there are can be other columns present; they will be carried through to the results)
METADATA_REQUIRED_FIELDS <- c("Date", "Time_start", "Plot", "Area", "Volume", "Temp")
# Data files must end with ".txt" and may be in sub-folders
data_files <- list.files(params$data_folder,
pattern = "*txt$",
full.names = TRUE, recursive = TRUE)
# Metadata files must end with ".xlsx" and may be in sub-folders
metadata_files <- list.files(params$metadata_folder,
pattern = "*xlsx$",
full.names = TRUE, recursive = TRUE)
#SW made the metadata file a csv to be visable on Github and there is only one
#metadata_files <- "COMPASS_Synoptic_TreeFlux_Metadata_2023.csv"
combined_dat$CO2_umol <- ffi_ppm_to_umol(combined_dat$CO2,
volume = combined_dat$Volume, #m3
temp = combined_dat$Temp) #degrees C
#area from metadata used to get a concentration per area
combind_dat$CH4_nmol_m2 <- combined_dat$CH4_nmol / combined_dat$Area
#| include: false
library(rmarkdown)
library(readr)
library(lubridate)
library(ggplot2)
theme_set(theme_bw())
library(ggrepel)
library(readxl)
library(broom)
library(DT)
library(MASS)
library(tidyr)
library(dplyr)
library(fluxfinder)
# These columns are REQUIRED to be present in the metadata file(s)
# (NB there are can be other columns present; they will be carried through to the results)
METADATA_REQUIRED_FIELDS <- c("Date", "Time_start", "Plot", "Area", "Volume", "Temp")
# Data files must end with ".txt" and may be in sub-folders
data_files <- list.files(params$data_folder,
pattern = "*txt$",
full.names = TRUE, recursive = TRUE)
# Metadata files must end with ".xlsx" and may be in sub-folders
metadata_files <- list.files(params$metadata_folder,
pattern = "*xlsx$",
full.names = TRUE, recursive = TRUE)
#SW made the metadata file a csv to be visable on Github and there is only one
#metadata_files <- "COMPASS_Synoptic_TreeFlux_Metadata_2023.csv"
#area from metadata used to get a concentration per area
combined_dat$CH4_nmol_m2 <- combined_dat$CH4_nmol / combined_dat$Area
combined_dat$CO2_umol_m2 <- combined_dat$CO2_umol / combined_dat$Area
#| include: false
library(rmarkdown)
library(readr)
library(lubridate)
library(ggplot2)
theme_set(theme_bw())
library(ggrepel)
library(readxl)
library(broom)
library(DT)
library(MASS)
library(tidyr)
library(dplyr)
library(fluxfinder)
# These columns are REQUIRED to be present in the metadata file(s)
# (NB there are can be other columns present; they will be carried through to the results)
METADATA_REQUIRED_FIELDS <- c("Date", "Time_start", "Plot", "Area", "Volume", "Temp")
# Data files must end with ".txt" and may be in sub-folders
data_files <- list.files(params$data_folder,
pattern = "*txt$",
full.names = TRUE, recursive = TRUE)
# Metadata files must end with ".xlsx" and may be in sub-folders
metadata_files <- list.files(params$metadata_folder,
pattern = "*xlsx$",
full.names = TRUE, recursive = TRUE)
#SW made the metadata file a csv to be visable on Github and there is only one
#metadata_files <- "COMPASS_Synoptic_TreeFlux_Metadata_2023.csv"
fluxes_ch4 <- ffi_compute_fluxes(combined_dat,
group_column = "Plot",
time_column = "final_datetime",
gas_column = "CH4_nmol_m2",
dead_band = "Dead_band")
#| include: false
library(rmarkdown)
library(readr)
library(lubridate)
library(ggplot2)
theme_set(theme_bw())
library(ggrepel)
library(readxl)
library(broom)
library(DT)
library(MASS)
library(tidyr)
library(dplyr)
library(fluxfinder)
# These columns are REQUIRED to be present in the metadata file(s)
# (NB there are can be other columns present; they will be carried through to the results)
METADATA_REQUIRED_FIELDS <- c("Date", "Time_start", "Plot", "Area", "Volume", "Temp")
# Data files must end with ".txt" and may be in sub-folders
data_files <- list.files(params$data_folder,
pattern = "*txt$",
full.names = TRUE, recursive = TRUE)
# Metadata files must end with ".xlsx" and may be in sub-folders
metadata_files <- list.files(params$metadata_folder,
pattern = "*xlsx$",
full.names = TRUE, recursive = TRUE)
#SW made the metadata file a csv to be visable on Github and there is only one
#metadata_files <- "COMPASS_Synoptic_TreeFlux_Metadata_2023.csv"
#need to create a date_time column in dataframe
combined_dat$datetime <- as.POSIXct(
paste(combined_dat$Date, format(combined_dat$Time_start, "%H:%M:%S")),
tz = "EST"
)
fluxes_ch4 <- ffi_compute_fluxes(combined_dat,
group_column = "Plot",
time_column = "datetime",
gas_column = "CH4_nmol_m2",
dead_band = "Dead_band")
#| include: false
library(rmarkdown)
library(readr)
library(lubridate)
library(ggplot2)
theme_set(theme_bw())
library(ggrepel)
library(readxl)
library(broom)
library(DT)
library(MASS)
library(tidyr)
library(dplyr)
library(fluxfinder)
# These columns are REQUIRED to be present in the metadata file(s)
# (NB there are can be other columns present; they will be carried through to the results)
METADATA_REQUIRED_FIELDS <- c("Date", "Time_start", "Plot", "Area", "Volume", "Temp")
# Data files must end with ".txt" and may be in sub-folders
data_files <- list.files(params$data_folder,
pattern = "*txt$",
full.names = TRUE, recursive = TRUE)
# Metadata files must end with ".xlsx" and may be in sub-folders
metadata_files <- list.files(params$metadata_folder,
pattern = "*xlsx$",
full.names = TRUE, recursive = TRUE)
#SW made the metadata file a csv to be visable on Github and there is only one
#metadata_files <- "COMPASS_Synoptic_TreeFlux_Metadata_2023.csv"
fluxes_ch4 <- ffi_compute_fluxes(combined_dat,
group_column = "Plot",
time_column = "datetime",
gas_column = "CH4_nmol_m2",
dead_band = 0)
