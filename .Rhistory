#Pull out the blanks from raw file
blks_raw <- all_dat %>%
filter(grepl("Lab Blank", sample_ID))
blks_raw <- blks_raw %>%
mutate(rep = row_number())
#Check if the blanks are above the lower 25% quantile of your data
blk_flag_cl <- quantile(all_dat$Cl_ppm, prob=c(.25))   #this gives you the lower 25% quantile of the data
blks_raw$Cl_diff_flag <-  ifelse(blks_raw$Cl_ppm <= blk_flag_cl, 'YES', 'No, check')
blk_flag_so4 <- quantile(all_dat$SO4_ppm, prob=c(.25))   #this gives you the lower 25% quantile of the data
blks_raw$so4_diff_flag <-  ifelse(blks_raw$SO4_ppm <= blk_flag_so4, 'YES', 'No, check')
#calculate the percent of check standards that are within the range based on the flag
cl_blks_percent <- (sum(blks_raw$Cl_diff_flag == "YES")/nrow(blks_raw))*100
so4_blks_percent <- (sum(blks_raw$so4_diff_flag == "YES")/nrow(blks_raw))*100
#report out if flags indicate need for rerun
ifelse(cl_blks_percent >= chks_flag, ">80% of Chloride Blank concentrations are lower 25% quartile of samples",
"<80% of Chloride blanks are lower 25% quartile of samples - REASSESS")
ifelse(so4_blks_percent >= chks_flag, ">80% of Sulfate Blank concentrations are lower 25% quartile of samples",
"<80% of Sulfate blanks are lower 25% quartile of samples - REASSESS")
########Blanks are so low that they don't show up on the plot############
##Maybe add 25% quartile printed onto graph instead
##Add a different line to check that they're below
#Plot the blanks vs. the lower 25% quantile of your data in this run (black line)
cl_blks <-  ggplot(data = blks_raw, aes(x = rep, y = Cl_ppm, fill=Cl_diff_flag)) +
geom_bar(stat = 'identity') +
scale_fill_manual(values = c("YES" = "darkblue", "No, check" = "darkgrey")) +
theme_classic() + labs(x= " ", y="Cl  (mg/L)", title="Blanks: Chloride") +
theme(legend.position="bottom") +  geom_hline(yintercept=blk_flag_cl, linetype="dashed",
color = "black", linewidth=1)  +
guides(fill=guide_legend(title="Blank Conc <25% Quartile Samples"))
so4_blks <-  ggplot(data = blks_raw, aes(x = rep, y = SO4_ppm, fill=so4_diff_flag)) +
geom_bar(stat = 'identity') +
scale_fill_manual(values = c("YES" = "darkblue", "No, check" = "darkgrey")) +
theme_classic() + labs(x= " ", y="SO4  (mg/L)", title="Blanks: Sulfate") +
theme(legend.position="bottom") +  geom_hline(yintercept=blk_flag_so4, linetype="dashed",
color = "black", linewidth=1)  +
guides(fill=guide_legend(title="Blank Conc <25% Quartile Samples"))
ggarrange(cl_blks, so4_blks, nrow=1, ncol=2)
#print out the average blank concentrations
blk_avg_cl <- mean(blks_raw$Cl_ppm)
cat("Chloride blanks mean ppm:")
print(blk_avg_cl)
blk_avg_so4 <- mean(blks_raw$SO4_ppm)
cat("Sulfate blanks mean ppm:")
print(blk_avg_so4)
#write out a flag to the sample dataframe if more than 80% of the blanks are above the lower 25% quantile of samples
if (cl_blks_percent <= chks_flag) {
all_dat$Cl_flag <- ifelse(
all_dat$Cl_flag != "",
paste0(all_dat$Cl_flag, "; Cl blanks out of range"),
"Cl blanks out of range"
)
}
if (so4_blks_percent <= chks_flag) {
all_dat$SO4_flag <- ifelse(
all_dat$SO4_flag != "",
paste0(all_dat$SO4_flag, "; SO4 blanks out of range"),
"SO4 blanks out of range"
)
}
View(blks_raw)
View(all_dat)
#print out the average blank concentrations
blk_avg_cl <- mean(blks_raw$Cl_ppm, na.rm = T)
cat("Chloride blanks mean ppm:")
print(blk_avg_cl)
blk_avg_so4 <- mean(blks_raw$SO4_ppm, na.rm = T)
cat("Sulfate blanks mean ppm:")
print(blk_avg_so4)
View(blks_raw)
cat("Assess Duplicates")
#pull out any rows that have "dup" in the sample_name column
dups <- all_dat %>%
select(!c(sample_name, sample_type, SO4_area, Cl_area, Cl_flag, SO4_flag)) %>%
filter(str_detect(sample_ID, "dup"))      #have to change this to match data
#create a new dataframe and remove dups from sample dataframe
dat_raw2 <- all_dat %>%
filter(!str_detect(sample_ID, "dup")) %>%
select(!c(sample_name, sample_type, SO4_area, Cl_area, Cl_flag, SO4_flag))
#remove the dup from these IDs so we will have duplicate sample names
dups <- dups %>%
mutate(sample_ID = gsub("_dup", "", as.character(sample_ID))) %>%
rename(
sample_ID = sample_ID,
SO4_ppm_dup = SO4_ppm,
Cl_ppm_dup = Cl_ppm
)
#merge with the dataframe so we have a column for the conc and the dup
QAdups <- merge(dat_raw2, dups)
#create a dataframe to compare Cl dups
df2 <- as.data.frame(QAdups$Cl_ppm)
df2$dups <- QAdups$Cl_ppm_dup
#calculate the cv of the duplicates
df2$sds <- apply(df2,1,sd)
df2$mean <- apply(df2, 1, mean)
QAdups$Cl_dups_cv <- (df2$sds/df2$mean) * 100
QAdups$Cl_dups_cv_flag <-  ifelse(QAdups$Cl_dups_cv <chk_flag_dups, 'YES', 'No, check')
#create a dataframe to compare SO4 dups
df3 <- as.data.frame(QAdups$SO4_ppm)
df3$dups <- QAdups$SO4_ppm_dup
#calculate the cv of the duplicates
df3$sds <- apply(df3,1,sd)
df3$mean <- apply(df3, 1, mean)
QAdups$SO4_dups_cv <- (df3$sds/df3$mean) * 100
QAdups$SO4_dups_cv_flag <-  ifelse(QAdups$SO4_dups_cv <chk_flag_dups, 'YES', 'No, check')
#Put all the dups together and create row numbers for plotting
QAdups <- QAdups %>%
mutate(row_num = row_number())
# QAdups
#plot dups output as a bar graph to easily check
Cl_dups <- ggplot(data =QAdups, aes(x =row_num, y =Cl_dups_cv, fill=Cl_dups_cv_flag)) +
geom_bar(stat = 'identity') +
theme_classic() + labs(x= " ", y="CV of Chloride Duplicates") +
scale_fill_manual(values = c("YES" = "darkgreen", "No, check" = "red")) +
theme(legend.position="none") +  geom_hline(yintercept=10, linetype="dashed",
color = "black", linewidth=1)  +
guides(fill=guide_legend(title="CV Between Dups <10%"))
SO4_dups <- ggplot(data =QAdups, aes(x =row_num, y =SO4_dups_cv, fill=SO4_dups_cv_flag)) +
geom_bar(stat = 'identity') +
theme_classic() + labs(x= " ", y="CV of Sulfate Duplicates") +
scale_fill_manual(values = c("YES" = "darkgreen", "No, check" = "red")) +
theme(legend.position="none") +  geom_hline(yintercept=10, linetype="dashed",
color = "black", linewidth=1) +
guides(fill=guide_legend(title="CV Between Dups <10%"))
ggarrange(Cl_dups, SO4_dups,ncol=2, nrow=1)
#Zeros will create NAs in the flag column, so we need to switch those to Yes's
QAdups <- QAdups %>%
mutate(Cl_dups_cv_flag = if_else(is.na(Cl_dups_cv), "YES", Cl_dups_cv_flag)) %>%
mutate(SO4_dups_cv_flag = if_else(is.na(SO4_dups_cv), "YES", SO4_dups_cv_flag))
#calculate the percent of dups that are within the range based on the flag
cl_dups_percent <- (sum(QAdups$Cl_dups_cv_flag == "YES")/nrow(QAdups))*100
so4_dups_percent <- (sum(QAdups$SO4_dups_cv_flag == "YES")/nrow(QAdups))*100
#report out if the dups are within range
ifelse(cl_dups_percent >= chks_flag, ">80% of Chloride Duplicates have a CV <10%",
"<80% of Chloride Duplicates have a CV <10% - REASSESS")
ifelse(so4_dups_percent >= chks_flag, ">80% of Sulfate Duplicates have a CV <10%",
"<80% of Sulfate Duplicates have a CV <10% - REASSESS")
#write out a flag to the sample dataframe if more than 80% of the dups have CVs out of range
if (cl_dups_percent <= chks_flag) {
all_dat$Cl_flag <- ifelse(
all_dat$Cl_flag != "",
paste0(all_dat$Cl_flag, "; Cl dups cv out of range"),
"Cl dups cv out of range"
)
}
if (so4_dups_percent <= chks_flag) {
all_dat$SO4_flag <- ifelse(
all_dat$SO4_flag != "",
paste0(all_dat$SO4_flag, "; SO4 dups cv out of range"),
"SO4 dups cv out of range"
)
}
#Calculate percent difference between duplicates
QAdups$Cl_dups_diff <- ((abs(QAdups$Cl_ppm - QAdups$Cl_ppm_dup))/((QAdups$Cl_ppm + QAdups$Cl_ppm_dup)/2)) * 100
QAdups$Cl_dups_diff_flag <-  ifelse(QAdups$Cl_dups_diff <chk_flag_dups, 'YES', 'No, check')
QAdups$SO4_dups_diff <- ((abs(QAdups$SO4_ppm - QAdups$SO4_ppm_dup))/((QAdups$SO4_ppm + QAdups$SO4_ppm_dup)/2)) * 100
QAdups$SO4_dups_diff_flag <-  ifelse(QAdups$SO4_dups_diff <chk_flag_dups, 'YES', 'No, check')
#plot dups output as a bar graph to easily check
Cl_dups1 <- ggplot(data =QAdups, aes(x =row_num, y =Cl_dups_diff, fill=Cl_dups_diff_flag)) +
geom_bar(stat = 'identity') +
theme_classic() + labs(x= " ", y="Difference Between Chloride Duplicates (%)") +
scale_fill_manual(values = c("YES" = "darkgreen", "No, check" = "red")) +
theme(legend.position="none") +  geom_hline(yintercept=10, linetype="dashed",
color = "black", linewidth=1)  +
guides(fill=guide_legend(title="CV Between Dups <10%"))
SO4_dups1 <- ggplot(data =QAdups, aes(x =row_num, y =SO4_dups_diff, fill=SO4_dups_diff_flag)) +
geom_bar(stat = 'identity') +
theme_classic() + labs(x= " ", y="Difference Between Sulfate Duplicates (%)") +
scale_fill_manual(values = c("YES" = "darkgreen", "No, check" = "red")) +
theme(legend.position="none") +  geom_hline(yintercept=10, linetype="dashed",
color = "black", linewidth=1) +
guides(fill=guide_legend(title="CV Between Dups <10%"))
ggarrange(Cl_dups1, SO4_dups1,ncol=2, nrow=1)
#Zeros will create NAs in the flag column, so we need to switch those to Yes's
QAdups <- QAdups %>%
mutate(Cl_dups_diff_flag = if_else(is.na(Cl_dups_diff), "YES", Cl_dups_diff_flag)) %>%
mutate(SO4_dups_diff_flag = if_else(is.na(SO4_dups_diff), "YES", SO4_dups_diff_flag))
#calculate the percent of dups that are within the range based on the flag
cl_dups_diff_percent <- (sum(QAdups$Cl_dups_diff_flag == "YES")/nrow(QAdups))*100
so4_dups_diff_percent <- (sum(QAdups$SO4_dups_diff_flag == "YES")/nrow(QAdups))*100
#report out if the dups are within range
ifelse(cl_dups_diff_percent >= chks_flag, ">80% of Chloride Duplicates have a percent difference <10%",
"<80% of Chloride Duplicates have a CV <10% - REASSESS")
ifelse(so4_dups_diff_percent >= chks_flag, ">80% of Sulfate Duplicates have a percent difference <10%",
"<80% of Sulfate Duplicates have a CV <10% - REASSESS")
#write out a flag to the sample dataframe if more than 80% of the dups have percent differences out of range
if (cl_dups_diff_percent <= chks_flag) {
all_dat$Cl_flag <- ifelse(
all_dat$Cl_flag != "",
paste0(all_dat$Cl_flag, "; Cl dups perc diff out of range"),
"Cl dups perc diff out of range"
)
}
if (so4_dups_diff_percent <= chks_flag) {
all_dat$SO4_flag <- ifelse(
all_dat$SO4_flag != "",
paste0(all_dat$SO4_flag, "; SO4 dups perc diff out of range"),
"SO4 dups perc diff out of range"
)
}
cat("Unit Conversion and Salinity Calculation")
# Convert ppm to mmol/L
all_dat$SO4_mM <- (all_dat$SO4_ppm / s_mw)
all_dat$Cl_mM <- (all_dat$Cl_ppm / cl_mw)
# Calculate Salinity
# calculated using the Knudsen equation
# Salinity = 0.03 + 1.8050 * Chlorinity
# Ref: A Practical Handbook of Seawater Analysis by Strickland & Parsons (P. 11)
# =((1.807*Cl_ppm)+0.026)/1000
all_dat$salinity <- ((1.8070 * all_dat$Cl_ppm) + 0.026) / 1000
#Need to determine dilution factors for your samples
#for Steph / COMPASS this depends on the site so...
all_dat$Dilution <- 1
all_dat$Dilution <-  ifelse(str_detect(all_dat$sample_ID, "MSM") & str_detect(all_dat$sample_ID, "UP"), 50, all_dat$Dilution)
all_dat$Dilution <-  ifelse(str_detect(all_dat$sample_ID, "MSM") & str_detect(all_dat$sample_ID, "TR"), 50, all_dat$Dilution)
all_dat$Dilution <-  ifelse(str_detect(all_dat$sample_ID, "MSM") & str_detect(all_dat$sample_ID, "WC"), 100, all_dat$Dilution)
all_dat$Dilution <-  ifelse(str_detect(all_dat$sample_ID, "MSM") & str_detect(all_dat$sample_ID, "SW"), 100, all_dat$Dilution)
all_dat$Dilution <-  ifelse(str_detect(all_dat$sample_ID, "GCW") & str_detect(all_dat$sample_ID, "UP"), 50, all_dat$Dilution)
all_dat$Dilution <-  ifelse(str_detect(all_dat$sample_ID, "GCW") & str_detect(all_dat$sample_ID, "TR"), 50, all_dat$Dilution)
all_dat$Dilution <-  ifelse(str_detect(all_dat$sample_ID, "GCW") & str_detect(all_dat$sample_ID, "WC"), 100, all_dat$Dilution)
all_dat$Dilution <-  ifelse(str_detect(all_dat$sample_ID, "GCW") & str_detect(all_dat$sample_ID, "SW"), 100, all_dat$Dilution)
all_dat$Dilution <-  ifelse(str_detect(all_dat$sample_ID, "GWI") & str_detect(all_dat$sample_ID, "UP"), 100, all_dat$Dilution)
all_dat$Dilution <-  ifelse(str_detect(all_dat$sample_ID, "GWI") & str_detect(all_dat$sample_ID, "TR"), 100, all_dat$Dilution)
all_dat$Dilution <-  ifelse(str_detect(all_dat$sample_ID, "GWI") & str_detect(all_dat$sample_ID, "WC"), 200, all_dat$Dilution)
all_dat$Dilution <-  ifelse(str_detect(all_dat$sample_ID, "GWI") & str_detect(all_dat$sample_ID, "SW"), 200, all_dat$Dilution)
all_dat$Dilution <-  ifelse(str_detect(all_dat$sample_ID, "SWH"), 50, all_dat$Dilution)
head(all_dat)
cat("Assess Spikes")
#pull out any rows that have "spk" in the Sample ID column
spks <- all_dat %>%
select(!c(sample_name, sample_type, SO4_area, Cl_ppm, Cl_mM, Cl_area, Cl_flag, SO4_flag, salinity, Dilution)) %>%
filter(str_detect(sample_ID, "spk"))      #have to change this to match data
head(spks)
#create a new dataframe and remove dups from sample dataframe
dat_spks <- all_dat %>%
filter(!str_detect(sample_ID, "spk")) %>%
select(!c(sample_name, sample_type, SO4_area, Cl_ppm,  Cl_mM, Cl_area, Cl_flag, SO4_flag, salinity))
#remove the dup from these IDs so we will have duplicate sample names
spks <- spks %>%
mutate(sample_ID = gsub("_spk", "", as.character(sample_ID))) %>%
rename(
sample_ID = sample_ID,
SO4_mM_spk = SO4_mM,
SO4_ppm_spk = SO4_ppm
)
#put it back together with the old data set and look for duplicates
QAspks <- merge(dat_spks, spks, by = "sample_ID")
head(QAspks)
#spike for these samples was 10uL of the 250 µg/mL SO4 standard
QAspks$SO4_spk_Conc <- spk_Conc     # mmoles of SO4 in spike
head(QAspks)
#Set Sample volumes in uL
QAspks$SampleVol <- 1
QAspks$SampleVol <-  ifelse(QAspks$Dilution == 50, 1501, QAspks$SampleVol)
QAspks$SampleVol <-  ifelse(QAspks$Dilution == 100, 1475, QAspks$SampleVol)
QAspks$SampleVol <-  ifelse(QAspks$Dilution == 200, 1462, QAspks$SampleVol)
#change sample volume to L
QAspks$SampleVol <- QAspks$SampleVol/Con1
head(QAspks)
#gives us the total SO4 in the sample in mmoles
QAspks$SO4_Total_unspkd <- (QAspks$SO4_mM/QAspks$Dilution)*(QAspks$SampleVol)
#gives us the total SO4 in the spiked sample in mmoles
QAspks$SO4_Total_spkd <- (QAspks$SO4_mM_spk/QAspks$Dilution)*(QAspks$SampleVol+spkvol)
#gives us expected SO4 in the spiked sample in mmoles
QAspks$SO4_expctd_spkd <-  (QAspks$SO4_Total_unspkd + QAspks$SO4_spk_Conc)
#gives us recovery of SO4 in the spiked sample in mmoles (actual/expected * 100)
QAspks$spk_recovery <-    (QAspks$SO4_Total_spkd/QAspks$SO4_expctd_spkd)*100
#flags if recovery of SO4 is outside range
QAspks$SO4_spks_flag <-  ifelse(QAspks$spk_recovery <= high_recovery_cutoff & QAspks$spk_recovery >= low_recovery_cutoff , 'Yes', 'No, check')
head(QAspks)
#plot spk recoveries output as a bar graph to easily check - want any over 10% to be red need to work on this
spksbar <- ggplot(data = QAspks, aes(x = sample_ID, y = spk_recovery, fill=SO4_spks_flag)) +
geom_bar(stat = 'identity') +
theme_bw() + labs(x= "Sample ID", y="Spike Recovery (%)") +
geom_hline(yintercept=80, linetype="dashed", color = "black", linewidth=1) +
geom_hline(yintercept=120, linetype="dashed", color = "black", linewidth=1)+
scale_fill_manual(values = c("Yes" = "darkgreen", "No, check" = "darkred"))+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
theme(legend.position="none")
spksbar
#check for percent of no, checks to see if it  would warrant reruns
Perc_spks <- QAspks %>%
group_by(SO4_spks_flag) %>%
summarise(no_rows = length(SO4_spks_flag))
Perc_spks$Total <- length(QAspks$SO4_spks_flag)
Perc_spks$Percent <- (Perc_spks$no_rows / Perc_spks$Total)*100
head(Perc_spks)
#report out if the dups are within range
ifelse(Perc_spks$Percent/100 >= chks_flag, ">80% of SO4 spikes have a recovery between the high and low cutoff - PROCEED",
">80% of SO4 spikes have a recovery between the high and low cutoff - REASSESS")
#write out a flag to the sample dataframe if less than 80% of the SO4 spikes are within range
if (Perc_spks$Percent/100 <= chks_flag) {
all_dat$SO4_flag <- ifelse(
all_dat$SO4_flag != "",
paste0(all_dat$SO4_flag, "; SO4 spikes out of range"),
"SO4 spikes out of range"
)
}
cat("Sample Flagging")
#Undilute samples
all_dat$Cl_ppm_undil <- all_dat$Cl_ppm/all_dat$Dilution
all_dat$SO4_ppm_undil <- all_dat$SO4_ppm/all_dat$Dilution
#Remove standards
dat_flagged <- all_dat %>%
filter(!str_detect(sample_ID, "Standard"))
#Flagging data if the concentration is outside the standards range and based on blanks
dat_flagged <- dat_flagged %>%
mutate(
Cl_flag = if_else(Cl_ppm_undil > top_std_cl,
if_else(Cl_flag != "" & !is.na(Cl_flag),
paste0(Cl_flag, "; value above cal curve"), "value above cal curve"), Cl_flag),
SO4_flag = if_else(SO4_ppm_undil > top_std_so4,
if_else(SO4_flag != "" & !is.na(SO4_flag),
paste0(SO4_flag, "; value above cal curve"), "value above cal curve"), SO4_flag) )
#Plot data and change colors based on flags to check it:
cl_samples_flag <-  ggplot(data = dat_flagged, aes(x = sample_name, y = Cl_ppm_undil, fill=Cl_flag)) +
geom_bar(stat = 'identity') +
scale_fill_manual(values=c("darkgreen", "red"))+
theme_classic() + labs(x= " ", y="C (mg/L)", title="Cl: Green = Within Range of Curve") +
theme(legend.position="none") +
theme(axis.text.x = element_blank())
so4_samples_flag <-  ggplot(data = dat_flagged, aes(x = sample_name, y = SO4_ppm_undil, fill=SO4_flag)) +
geom_bar(stat = 'identity') +
scale_fill_manual(values=c("darkgreen", "red"))+
theme_classic() + labs(x= " ", y="N (mg/L)", title="SO4: Green = Within Range of Curve") +
theme(legend.position="none") +
theme(axis.text.x = element_blank())
ggarrange(cl_samples_flag, so4_samples_flag, nrow=1, ncol=2)
cat("Check Sample IDs with Metadata")
#remove duplicates from the sample dataframe bc we are just taking the first dup run
all_data_flagged <- dat_flagged %>%
filter(!str_detect(sample_ID, "dup")) %>%
filter(!str_detect(sample_ID, "Lab Blank")) %>%
mutate(sample_ID = sub("^[^_]+_", "", sample_ID))
#select(!Excess_Info)
#check to see if all samples are present in the metadata
all_data_flagged$sample_ID <- toupper(all_data_flagged$sample_ID)
dionex_metadata$Cl_SO4_ID <- toupper(dionex_metadata$Cl_SO4_ID)
all_present <- all(all_data_flagged$sample_ID %in% dionex_metadata$Cl_SO4_ID)
if (all_present) {
message("All sample IDs are present in metadata.")
} else {
message("Some sample IDs are missing from metadata.")
# Optional: Which ones are missing?
missing_ids <- setdiff(all_data_flagged$sample_ID, dionex_metadata$Cl_SO4_ID)
print(missing_ids)
}
dionex_metadata_selected <- dionex_metadata %>%
select(Cl_SO4_ID, Year, Month, Day, Depth_cm, Lysimeter, Time..24hr., Time.Zone_EDT.EST,  Field.Notes)
#merge metadata with sample run data
merged_data <- all_data_flagged %>%
left_join(dionex_metadata_selected, by = c("sample_ID" = "Cl_SO4_ID"))
df_all_clean <- merged_data %>%
#filter(str_detect(Sample_Name, "GCW|GWI|MSM|SWH")) %>%
#mutate(Run_Time = lubridate::mdy_hm(Run_Time)) %>%
separate(
col = sample_name,
sep = "_",
into = c("Sample_Number", "Site_Code", "Date" ,"Zone", "LysID", "Depth"),
remove = FALSE)
############### THIS IS ONLY FOR 2023 when SWAMP was called UP and UPLAND was called UPCON ##############
# df_all_clean <- df_all_clean %>%
#   mutate(
#     Zone = case_when(
#       Site_Code == "SWH" & Zone == "UP" ~ "SWAMP",
#       Site_Code == "SWH" & Zone == "UPCON" ~ "UP",
#       TRUE ~ `Zone`
#     ))
cat("Visualize Data")
#Plot samples to get a first look at concentrations (sanity check)
data_plotting <- df_all_clean
#Order by Zone from Upland to Surface Water
data_plotting$Zone = factor(data_plotting$Zone, levels = c("UP", "TR", "SWAMP", "WC", "SW"))
data_plotting <- data_plotting[order(data_plotting$Zone), ]
#group the data for plotting
data_plotting <- data_plotting %>%
group_by(Site_Code) %>%
mutate(row_num = factor(row_number())) %>%  # create row_num as factor per group
ungroup()
#Plot data and change colors based on Zone:
viz_cl_plot <- ggplot(data_plotting, aes(x = row_num, y = Cl_ppm, fill = Zone)) +
geom_bar(stat = "identity", position = position_dodge2(preserve = "single")) +
facet_grid(~ Site_Code, scales="free_x") +
scale_fill_manual(values = c(
"UP" = "#20063B",
"TR" = "#FFBC42",
"SWAMP" = "darkgrey",
"WC" = "#419973",
"SW" = "#25ABE6"
)) +
theme_classic() +
theme(axis.text.x = element_blank()) +
labs(x = " ", y = "Cl (mg/L)", title = "Samples: Chloride") +
scale_x_discrete(drop = TRUE)
viz_so4_plot <-  ggplot(data_plotting, aes(x = row_num, y = SO4_ppm, fill = Zone)) +
geom_bar(stat = "identity", position = position_dodge2(preserve = "single")) +
facet_grid(~ Site_Code, scales="free_x") +
scale_fill_manual(values = c(
"UP" = "#20063B",
"TR" = "#FFBC42",
"SWAMP" = "darkgrey",
"WC" = "#419973",
"SW" = "#25ABE6"
)) +
theme_classic() +
theme(axis.text.x = element_blank()) +
labs(x = " ", y = "SO4 (mg/L)", title = "Samples: SO4") +
scale_x_discrete(drop = TRUE)
ggarrange(viz_cl_plot, viz_so4_plot, nrow=2, ncol=1)
cat("Export Processed Data")
#Prepare data to be exported - if there is anything else to add
#Add any necessary identifiers to the samples  ### VERY IMPORTANT AND STANDARD FOR PROJECT ####
#example read in sample IDs list and merge
#create required ID columns in R, etc.
final_data <- df_all_clean %>%
mutate(
Project = "COMPASS: Synoptic",   # new column with same value on every row
Region = "CB",
Run_notes = run_notes,     # new column with notes about the run
Analysis_rundate = print(Date_Run)
)
colnames(final_data)
final_data <- final_data %>%
rename(
Time = Time..24hr.,
Time_Zone = Time.Zone_EDT.EST,
Replicate = Lysimeter,
Sample_ID = sample_ID,
Field_notes = Field.Notes,
Site = Site_Code
# add more rename pairs as needed
) %>%
select(
Project, Region, Site, Zone, Replicate, Depth_cm,
Sample_ID, Year, Month, Day, Time, Time_Zone,
SO4_mM, Cl_mM, salinity, Cl_flag, SO4_flag,
Analysis_rundate,  Run_notes, Field_notes
# list columns in the order you want them
)
head(final_data)
#will put final data in processed data folder
#Write out data frame
write.csv(final_data, processed_file_name)
View(final_data)
#Packages that are required
lapply(c(
"dplyr", "ggplot2", "ggpubr", "stringr",
"purrr", "tidyverse", "here", "broom", "tibble",
"googledrive", "googlesheets4", "data.table",
"matrixStats", "gridExtra", "grid", "tidyverse", "formatR", "knitr"),
library, character.only = TRUE)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
#identify section
cat("Setup Information")
###### Run information - PLEASE CHANGE
Date_Run = "2024-01-01"  #Date that instrument was run
Run_by = "Zoe Read"  #Instrument user
Script_run_by = "Zoe Read" #Code user
run_notes = "All SO4 blanks were zero" #any notes from the run
samples <- c("GCW", "GWI", "MSM", "SWH") #whatever identifies your samples within the same names
samples_pattern <- paste(samples, collapse = "|")
#samples_pattern <- "GCW" #use this instead of the line above if you have only one site code
chks_name = "Check Standard"  #what did you name your check standards?
###### File Names - PLEASE CHANGE
#file path and name for raw summary data file
# raw_file_name_cl = "Porewater/Sulfate_Chloride/Synoptic_CB/2024/Raw Data/COMPASS_Synoptic_CB_MonMon_202408_Cl.txt"
# raw_file_name_so4 = "Porewater/Sulfate_Chloride/Synoptic_CB/2024/Raw Data/COMPASS_Synoptic_CB_MonMon_202408_SO4.txt"
raw_file_name_cl = "Raw Data/COMPASS_Synoptic_CB_MonMon_202408_Cl.txt"
raw_file_name_so4 = "Raw Data/COMPASS_Synoptic_CB_MonMon_202408_SO4.txt"
#file path and name of processed data file
# processed_file_name = "Porewater/Sulfate_Chloride/Synoptic_CB/2024/Processed Data/COMPASS_SynopticCB_PW_Processed_Cl_SO4_202408.csv"
processed_file_name = "Processed Data/COMPASS_SynopticCB_PW_Processed_Cl_SO4_202408.csv"
###### Log Files - PLEASE CHECK
#downloaded metadata csv - downloaded from Google drive as csv for this year
# Raw_Metadata = "Porewater/Sulfate_Chloride/Synoptic_CB/2024/Raw Data/COMPASS_SynopticCB_PW_SampleLog_2024.csv"
Raw_Metadata = "Raw Data/COMPASS_SynopticCB_PW_SampleLog_2024.csv"
#qaqc log file path for this year
# Log_path = "Porewater/Sulfate_Chloride/Synoptic_CB/2024/Raw Data/COMPASS_Synoptic_Cl_SO4_QAQClog_2024.csv"
Log_path = "Raw Data/COMPASS_Synoptic_Cl_SO4_QAQClog_2024.csv"
#Link to the protocol used for analysis
#steph will add this soon
#Coefficients / constants that are needed for calculations
cl_mw <- 35.45     #molecular weight of Chloride, g/mol
s_mw <- 32.06      #molecular weight of sulfur, g/mol
Con1 <- 1000000    #conversion factor value for spike volumes (uL -> L)
#Flag cutoffs
r2_cutoff = 0.98            #this is the level below which we want to rerun or consider a curve
chk_flag_std_s = 10         #this is the maximum cv allowed for sulfate check standards
chk_flag_std_cl = 5         #this is the maximum cv allowed for chloride check standards
chk_flag_std_perc = 15      #this is the maximum perc diff allowed for check standards
chk_flag_dups = 10          #this is the maximum cv allowed for duplicates
high_recovery_cutoff = 120  #this is the maximum percent recovery of SO4 allowed in spiked samples
low_recovery_cutoff = 80    #this is the minimum percent recovery of SO4 allowed in spiked samples
chks_flag = 0.80            #if less than this percent of samples pass a check, a flag is added
#Standard concentrations - Update if running different standard curve:
standards <- tibble(
sample_ID = c("Standard 1", "Standard 2", "Standard 3", "Standard 4", "Standard 5"),
SO4_std_conc = c(0.5, 1.0, 2.0, 10, 20),  #ug/mL
Cl_std_conc = c(5, 10, 20, 100, 200))     #ug/mL
#Spike concentration calc
#spike for these samples was 10uL of the 250 µg/mL standard
spk_std <- (250/s_mw)         # mM of SO4 calculated from 250 ug/mL SO4 spike solution
spkvol <- 10                  # uL volume of spike added
spkvol <- spkvol/Con1         # L volume of spike added
spk_Conc <- (spk_std)*spkvol  # mmoles of SO4 added to each spiked sample
#Top standard Concentrations- Update if running different standard curve:
top_std_cl = 200   #ug/mL
top_std_so4 = 20   #ug/mL
#Set time zone
common_tz = "Etc/GMT+5"
Sys.setenv(TZ = "America/New_York")
#read in the raw metadata file
raw_metadata <- read.csv(Raw_Metadata)
