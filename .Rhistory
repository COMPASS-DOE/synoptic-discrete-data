#remove the dup from these IDs so we will have duplicate sample names
#dups$sample_ID<-gsub("_dup","",as.character(dups$sample_ID))
#dups <- all_dat %>%
# select(!c(sample_name, sample_type, SO4_area, Cl_area, Cl_flag, SO4_flag)) #remove unneeded columns
#colnames(dups) <- c('sample_ID',  "SO4_ppm_dup", 'CL_ppm_dup')
dups <- dups %>%
mutate(sample_ID = gsub("_dup", "", as.character(sample_ID))) %>%
rename(
sample_ID = sample_ID,
SO4_ppm_dup = SO4_ppm,
Cl_ppm_dup = Cl_ppm
)
#merge with the dataframe so we have a column for the conc and the dup
QAdups <- merge(dat_raw2, dups)
#create a dataframe to compare npoc dups
df2 <- as.data.frame(QAdups$Cl_ppm)
df2$dups <- QAdups$CL_ppm_dup
#calculate the cv of the duplicates
df2$sds <- apply(df2,1,sd)
df2$mean <- apply(df2, 1, mean)
QAdups$Cl_dups_cv <- (df2$sds/df2$mean) * 100
QAdups$Cl_dups_cv_flag <-  ifelse(QAdups$Cl_dups_cv <10, 'YES', 'NO, rerun')
#create a dataframe to compare tdn dups
df3 <- as.data.frame(QAdups$SO4_ppm)
df3$dups <- QAdups$SO4_ppm_dup
#calculate the cv of the duplicates
df3$sds <- apply(df3,1,sd)
df3$mean <- apply(df3, 1, mean)
QAdups$SO4_dups_cv <- (df3$sds/df3$mean) * 100
QAdups$SO4_dups_cv_flag <-  ifelse(QAdups$SO4_dups_cv <10, 'YES', 'NO, rerun')
#Put all the dups together and create row numbers for plotting
QAdups <- QAdups %>%
mutate(row_num = row_number())
cat("Assess Duplicates")
#Take a look at the raw data
#head(all_dat)
#pull out any rows that have "dup" in the sample_name column
dups <- all_dat %>%
select(!c(sample_name, sample_type, SO4_area, Cl_area, Cl_flag, SO4_flag)) %>%
filter(str_detect(sample_ID, "dup"))      #have to change this to match data
#create a new dataframe and remove dups from sample dataframe
dat_raw2 <- all_dat %>%
filter(!str_detect(sample_ID, "dup")) %>%
select(!c(sample_name, sample_type, SO4_area, Cl_area, Cl_flag, SO4_flag))
#remove the dup from these IDs so we will have duplicate sample names
#dups$sample_ID<-gsub("_dup","",as.character(dups$sample_ID))
#dups <- all_dat %>%
# select(!c(sample_name, sample_type, SO4_area, Cl_area, Cl_flag, SO4_flag)) #remove unneeded columns
#colnames(dups) <- c('sample_ID',  "SO4_ppm_dup", 'CL_ppm_dup')
dups <- dups %>%
mutate(sample_ID = gsub("_dup", "", as.character(sample_ID))) %>%
rename(
sample_ID = sample_ID,
SO4_ppm_dup = SO4_ppm,
Cl_ppm_dup = Cl_ppm
)
#merge with the dataframe so we have a column for the conc and the dup
QAdups <- merge(dat_raw2, dups)
#create a dataframe to compare npoc dups
df2 <- as.data.frame(QAdups$Cl_ppm)
df2$dups <- QAdups$Cl_ppm_dup
#calculate the cv of the duplicates
df2$sds <- apply(df2,1,sd)
df2$mean <- apply(df2, 1, mean)
QAdups$Cl_dups_cv <- (df2$sds/df2$mean) * 100
QAdups$Cl_dups_cv_flag <-  ifelse(QAdups$Cl_dups_cv <10, 'YES', 'NO, rerun')
#create a dataframe to compare tdn dups
df3 <- as.data.frame(QAdups$SO4_ppm)
df3$dups <- QAdups$SO4_ppm_dup
#calculate the cv of the duplicates
df3$sds <- apply(df3,1,sd)
df3$mean <- apply(df3, 1, mean)
QAdups$SO4_dups_cv <- (df3$sds/df3$mean) * 100
QAdups$SO4_dups_cv_flag <-  ifelse(QAdups$SO4_dups_cv <10, 'YES', 'NO, rerun')
#Put all the dups together and create row numbers for plotting
QAdups <- QAdups %>%
mutate(row_num = row_number())
#head(QAdups)
cat("Assess Duplicates")
#Take a look at the raw data
#head(all_dat)
#pull out any rows that have "dup" in the sample_name column
dups <- all_dat %>%
select(!c(sample_name, sample_type, SO4_area, Cl_area, Cl_flag, SO4_flag)) %>%
filter(str_detect(sample_ID, "dup"))      #have to change this to match data
#create a new dataframe and remove dups from sample dataframe
dat_raw2 <- all_dat %>%
filter(!str_detect(sample_ID, "dup")) %>%
select(!c(sample_name, sample_type, SO4_area, Cl_area, Cl_flag, SO4_flag))
#remove the dup from these IDs so we will have duplicate sample names
#dups$sample_ID<-gsub("_dup","",as.character(dups$sample_ID))
#dups <- all_dat %>%
# select(!c(sample_name, sample_type, SO4_area, Cl_area, Cl_flag, SO4_flag)) #remove unneeded columns
#colnames(dups) <- c('sample_ID',  "SO4_ppm_dup", 'CL_ppm_dup')
dups <- dups %>%
mutate(sample_ID = gsub("_dup", "", as.character(sample_ID))) %>%
rename(
sample_ID = sample_ID,
SO4_ppm_dup = SO4_ppm,
Cl_ppm_dup = Cl_ppm
)
#merge with the dataframe so we have a column for the conc and the dup
QAdups <- merge(dat_raw2, dups)
#create a dataframe to compare npoc dups
df2 <- as.data.frame(QAdups$Cl_ppm)
df2$dups <- QAdups$Cl_ppm_dup
#calculate the cv of the duplicates
df2$sds <- apply(df2,1,sd)
df2$mean <- apply(df2, 1, mean)
QAdups$Cl_dups_cv <- (df2$sds/df2$mean) * 100
QAdups$Cl_dups_cv_flag <-  ifelse(QAdups$Cl_dups_cv <10, 'YES', 'NO, rerun')
#create a dataframe to compare tdn dups
df3 <- as.data.frame(QAdups$SO4_ppm)
df3$dups <- QAdups$SO4_ppm_dup
#calculate the cv of the duplicates
df3$sds <- apply(df3,1,sd)
df3$mean <- apply(df3, 1, mean)
QAdups$SO4_dups_cv <- (df3$sds/df3$mean) * 100
QAdups$SO4_dups_cv_flag <-  ifelse(QAdups$SO4_dups_cv <10, 'YES', 'NO, rerun')
#Put all the dups together and create row numbers for plotting
QAdups <- QAdups %>%
mutate(row_num = row_number())
#head(QAdups)
#plot dups output as a bar graph to easily check - want any over 10% to be red need to work on this
Cl_dups <- ggplot(data =QAdups, aes(x =row_num, y =Cl_dups_cv, fill=Cl_dups_cv_flag)) +
geom_bar(stat = 'identity') +
theme_classic() + labs(x= " ", y="CV of NPOC Duplicates") +
scale_fill_manual(values = c("YES" = "darkgreen", "NO, rerun" = "red")) +
theme(legend.position="none") +  geom_hline(yintercept=10, linetype="dashed",
color = "black", size=1)  +
guides(fill=guide_legend(title="CV Between Dups <10%"))
SO4_dups <- ggplot(data =QAdups, aes(x =row_num, y =SO4_dups_cv, fill=SO4_dups_cv_flag)) +
geom_bar(stat = 'identity') +
theme_classic() + labs(x= " ", y="CV of TN Duplicates") +
scale_fill_manual(values = c("YES" = "darkgreen", "NO, rerun" = "red")) +
theme(legend.position="none") +  geom_hline(yintercept=10, linetype="dashed",
color = "black", size=1) +
guides(fill=guide_legend(title="CV Between Dups <10%"))
ggarrange(Cl_dups, SO4_dups,ncol=2, nrow=1)
#calculate the percent of check standards that are within the range based on the flag
cl_dups_percent <- (sum(QAdups$Cl_dups_cv_flag == "YES")/nrow(QAdups))*100
so4_dups_percent <- (sum(QAdups$SO4_dups_cv_flag == "YES")/nrow(QAdups))*100
#report out if the dups are within range
ifelse(cl_dups_percent >= chks_flag, ">60% of Carbon Duplicates have a CV <10%",
"<60% of Carbon Duplicates have a CB <10% - REASSESS")
ifelse(so4_dups_percent >= chks_flag, ">60% of Nitrogen Duplicates have a CV <10%",
"<60% of Nitrogen Duplicates have a CB <10% - REASSESS")
#write out a flag to the sample dataframe if more than 60% of the dups have CVs out of range
if (cl_dups_percent <= chks_flag) {
all_dat$Cl_flag <- ifelse(
all_dat$Cl_flag != "",
paste0(all_dat$Cl_flag, "; Cl dups out of range"),
"Cl dups out of range"
)
}
cl_dups_percent
cl_dups_percent <- (sum(QAdups$Cl_dups_cv_flag == "YES")/nrow(QAdups))*100
cl_dups_percent
#Zeros will create NAs in the flag column, so we need to switch those to Yes's
QAdups <- QAdups %>%
mutate(Cl_dups_cv_flag = if_else(is.na(Cl_dups_cv_flag), "YES", Cl_dups_cv_flag))
QAdups <- QAdups %>%
mutate(Cl_dups_cv_flag = if_else(is.na(Cl_dups_cv), "YES", Cl_dups_cv_flag))
cat("Assess Duplicates")
#Take a look at the raw data
#head(all_dat)
#pull out any rows that have "dup" in the sample_name column
dups <- all_dat %>%
select(!c(sample_name, sample_type, SO4_area, Cl_area, Cl_flag, SO4_flag)) %>%
filter(str_detect(sample_ID, "dup"))      #have to change this to match data
#create a new dataframe and remove dups from sample dataframe
dat_raw2 <- all_dat %>%
filter(!str_detect(sample_ID, "dup")) %>%
select(!c(sample_name, sample_type, SO4_area, Cl_area, Cl_flag, SO4_flag))
#remove the dup from these IDs so we will have duplicate sample names
#dups$sample_ID<-gsub("_dup","",as.character(dups$sample_ID))
#dups <- all_dat %>%
# select(!c(sample_name, sample_type, SO4_area, Cl_area, Cl_flag, SO4_flag)) #remove unneeded columns
#colnames(dups) <- c('sample_ID',  "SO4_ppm_dup", 'CL_ppm_dup')
dups <- dups %>%
mutate(sample_ID = gsub("_dup", "", as.character(sample_ID))) %>%
rename(
sample_ID = sample_ID,
SO4_ppm_dup = SO4_ppm,
Cl_ppm_dup = Cl_ppm
)
#merge with the dataframe so we have a column for the conc and the dup
QAdups <- merge(dat_raw2, dups)
#create a dataframe to compare npoc dups
df2 <- as.data.frame(QAdups$Cl_ppm)
df2$dups <- QAdups$Cl_ppm_dup
#calculate the cv of the duplicates
df2$sds <- apply(df2,1,sd)
df2$mean <- apply(df2, 1, mean)
QAdups$Cl_dups_cv <- (df2$sds/df2$mean) * 100
QAdups$Cl_dups_cv_flag <-  ifelse(QAdups$Cl_dups_cv <10, 'YES', 'NO, rerun')
#create a dataframe to compare tdn dups
df3 <- as.data.frame(QAdups$SO4_ppm)
df3$dups <- QAdups$SO4_ppm_dup
#calculate the cv of the duplicates
df3$sds <- apply(df3,1,sd)
df3$mean <- apply(df3, 1, mean)
QAdups$SO4_dups_cv <- (df3$sds/df3$mean) * 100
QAdups$SO4_dups_cv_flag <-  ifelse(QAdups$SO4_dups_cv <10, 'YES', 'NO, rerun')
#Put all the dups together and create row numbers for plotting
QAdups <- QAdups %>%
mutate(row_num = row_number())
#head(QAdups)
#plot dups output as a bar graph to easily check - want any over 10% to be red need to work on this
Cl_dups <- ggplot(data =QAdups, aes(x =row_num, y =Cl_dups_cv, fill=Cl_dups_cv_flag)) +
geom_bar(stat = 'identity') +
theme_classic() + labs(x= " ", y="CV of NPOC Duplicates") +
scale_fill_manual(values = c("YES" = "darkgreen", "NO, rerun" = "red")) +
theme(legend.position="none") +  geom_hline(yintercept=10, linetype="dashed",
color = "black", size=1)  +
guides(fill=guide_legend(title="CV Between Dups <10%"))
SO4_dups <- ggplot(data =QAdups, aes(x =row_num, y =SO4_dups_cv, fill=SO4_dups_cv_flag)) +
geom_bar(stat = 'identity') +
theme_classic() + labs(x= " ", y="CV of TN Duplicates") +
scale_fill_manual(values = c("YES" = "darkgreen", "NO, rerun" = "red")) +
theme(legend.position="none") +  geom_hline(yintercept=10, linetype="dashed",
color = "black", size=1) +
guides(fill=guide_legend(title="CV Between Dups <10%"))
ggarrange(Cl_dups, SO4_dups,ncol=2, nrow=1)
#Zeros will create NAs in the flag column, so we need to switch those to Yes's
QAdups <- QAdups %>%
mutate(Cl_dups_cv_flag = if_else(is.na(Cl_dups_cv), "YES", Cl_dups_cv_flag)) %>%
mutate(SO4_dups_cv_flag = if_else(is.na(SO4_dups_cv), "YES", SO4_dups_cv_flag))
#calculate the percent of check standards that are within the range based on the flag
cl_dups_percent <- (sum(QAdups$Cl_dups_cv_flag == "YES")/nrow(QAdups))*100
so4_dups_percent <- (sum(QAdups$SO4_dups_cv_flag == "YES")/nrow(QAdups))*100
#report out if the dups are within range
ifelse(cl_dups_percent >= chks_flag, ">60% of Carbon Duplicates have a CV <10%",
"<60% of Carbon Duplicates have a CB <10% - REASSESS")
ifelse(so4_dups_percent >= chks_flag, ">60% of Nitrogen Duplicates have a CV <10%",
"<60% of Nitrogen Duplicates have a CB <10% - REASSESS")
#pull out any rows that have "spk" in the SampleID column
spks <- sampledat %>%
select(!c(sample_name, sample_type, SO4_area, Cl_ppm, Cl_area, Cl_flag, SO4_flag)) %>%
filter(str_detect(sample_ID, "spk"))      #have to change this to match data
#pull out any rows that have "spk" in the SampleID column
spks <- all_dat %>%
select(!c(sample_name, sample_type, SO4_area, Cl_ppm, Cl_area, Cl_flag, SO4_flag)) %>%
filter(str_detect(sample_ID, "spk"))      #have to change this to match data
head(spks)
#create a new dataframe and remove dups from sample dataframe
dat_spks <- all_dat %>%
filter(!str_detect(sample_ID, "spk")) %>%
select(!c(sample_name, sample_type, SO4_area, Cl_ppm, Cl_area, Cl_flag, SO4_flag))
#remove the dup from these IDs so we will have duplicate sample names
spks <- spks %>%
mutate(sample_ID = gsub("_spk", "", as.character(sample_ID))) %>%
rename(
sample_ID = sample_ID,
SO4_ppm_spk = SO4_ppm
)
#spks$Sample_ID<-gsub("_spk","",as.character(spks$Sample_ID))
#spks <- spks[ ,-c(2,3, 5,6)]
#colnames(spks) <- c('Sample_ID', 'SO4_mM_spk')
#head(spks)
#put it back together with the old data set and look for duplicates
QAspks <- merge(dat_spks, spks)
head(QAspks)
View(QAspks)
#Spike concentration calc:
spk_std <- (250/smw)    # in mM
spk_std <- (250/s_mw)    # in mM
spkvol <- 10             # in uL
spkvol <- spkvol/1000000
#spike for these samples was 10uL of the 250mM standard
spk_Conc <- (spk_std)*spkvol
View(all_dat)
#identify section
cat("Setup")
#Link to the protocol used for analysis
#steph will add this soon
#Packages that are required
lapply(c(
"dplyr", "ggplot2", "ggpubr", "stringr",
"purrr", "tidyverse", "here", "broom", "tibble",
"googledrive", "googlesheets4", "data.table",
"matrixStats", "gridExtra", "grid"),
library, character.only = TRUE)
#any coefficients / constants that are needed for calculations
cl_mw <- 35.45     #molecular weight of Chloride: 35.45
s_mw <- 32.06      #molecular weight of sulfur: 32.06
Con1 <- 1000       # conversion factor value
Con2 <- 1000000    # conversion factor value
#Flag that we
r2_cutoff = 0.98  #this is the level below which we want to rerun or consider a curve
chk_flag = 0.15   #for the RSD (relative standard deviation)
chk_conc_flag = 15 #this is the level cutoff for percent difference of check standards vs. the concentration they are meant to be
chks_flag = 0.50 #this is the percent of chks we want to have a CV less than 10, usually 60
rep_flag = 25 #this is a 25% error between samples
#blank_flag - calculated based on samples later in this code as lower 25% quantile of sample concentrations
#standard concentrations - Update if running different checks:
standards <- tibble(
sample_ID = c("Standard 1", "Standard 2", "Standard 3", "Standard 4", "Standard 5"),
SO4_std_conc = c(0.5, 1.0, 2.0, 10, 20),
Cl_std_conc = c(5, 10, 20, 100, 200)
)
#Spike concentration calc:
spk_std <- (250/s_mw)    # in mM
spkvol <- 10             # in uL
spkvol <- spkvol/1000000
#spike for these samples was 10uL of the 250mM standard
spk_Conc <- (spk_std)*spkvol
#Top standard Concentrations- Update if running different standard curve:
top_std_c1 = 200
top_std_so4 = 20
#Set time zone
common_tz = "Etc/GMT+5"
Sys.setenv(TZ = "America/New_York")
#plot indicators
site_order <- c('GCW', 'MSM', 'GWI', 'SWH')
plot_order <- c('UP', 'SWAMP', 'TR', 'WC', 'SW')
plot_colors <- c("#20063B", "darkgrey", "#FFBC42", "#419973", "#25ABE6" )
## Remove once you fix the flagging chunk
dat_flagged <- all_dat
## Remove once you fix the flagging chunk
dat_flagged <- all_dat
cat("Visualize Data")
#Plot samples to get a first look at concentrations (sanity check)
IDs <- data.frame(do.call('rbind', strsplit(as.character(dat_flagged$sample_name),'_',fixed=TRUE)))
colnames(IDs) <- c("Sample_Number", "Site_Code","Date" ,"Zone", "Lysimeter", "Depth", "Excess_Info")
#head(IDs)
#rejoin them to the dataframe
dat_flagged_id <- cbind(IDs, dat_flagged)
View(dat_flagged_id)
#Pull in data that from the raw data file based on the sample info input above
dat_flagged <- all_dat %>%
filter(str_detect(sample_ID, samples_pattern))
cat("Visualize Data")
#Plot samples to get a first look at concentrations (sanity check)
IDs <- data.frame(do.call('rbind', strsplit(as.character(dat_flagged$sample_name),'_',fixed=TRUE)))
colnames(IDs) <- c("Sample_Number", "Site_Code","Date" ,"Zone", "Lysimeter", "Depth", "Excess_Info")
#head(IDs)
#rejoin them to the dataframe
dat_flagged_id <- cbind(IDs, dat_flagged)
View(dat_flagged_id)
#Pull in data that from the raw data file based on the sample info input above
dat_flagged <- all_dat %>%
filter(!str_detect(sample_ID, "PPR"))
filter(str_detect(sample_ID, samples_pattern))
#Pull in data that from the raw data file based on the sample info input above
dat_flagged <- all_dat %>%
filter(!str_detect(sample_ID, "PPR")) %>%
filter(str_detect(sample_ID, samples_pattern))
cat("Visualize Data")
#Plot samples to get a first look at concentrations (sanity check)
IDs <- data.frame(do.call('rbind', strsplit(as.character(dat_flagged$sample_name),'_',fixed=TRUE)))
colnames(IDs) <- c("Sample_Number", "Site_Code","Date" ,"Zone", "Lysimeter", "Depth", "Excess_Info")
#head(IDs)
#rejoin them to the dataframe
dat_flagged_id <- cbind(IDs, dat_flagged)
#group the data for plotting
dat_flagged_id <- dat_flagged_id %>%
group_by(Site_Code) %>%
mutate(row_num = factor(row_number())) %>%  # create row_num as factor per group
ungroup()
## Remove once you fix the flagging chunk
#Pull in data that from the raw data file based on the sample info input above
dat_flagged <- all_dat %>%
filter(!str_detect(sample_ID, "PPR")) %>%
filter(str_detect(sample_ID, samples_pattern))
cat("Visualize Data")
#Plot samples to get a first look at concentrations (sanity check)
IDs <- data.frame(do.call('rbind', strsplit(as.character(dat_flagged$sample_name),'_',fixed=TRUE)))
colnames(IDs) <- c("Sample_Number", "Site_Code","Date" ,"Zone", "Lysimeter", "Depth", "Excess_Info")
#head(IDs)
#rejoin them to the dataframe
dat_flagged_id <- cbind(IDs, dat_flagged)
#group the data for plotting
dat_flagged_id <- dat_flagged_id %>%
group_by(Site_Code) %>%
mutate(row_num = factor(row_number())) %>%  # create row_num as factor per group
ungroup()
#Plot data and change colors based on flags to check it:
viz_cl_plot <- ggplot(dat_flagged_id, aes(x = factor(row_num), y = Cl_ppm, fill = Zone)) +
geom_bar(stat = "identity", position = position_dodge2(preserve = "single")) +
facet_grid(~ Site_Code, scales="free_x") +
scale_fill_manual(values = c(
"UP" = "#20063B",
"TR" = "#FFBC42",
"SWAMP" = "darkgrey",
"WC" = "#419973",
"SW" = "#25ABE6"
)) +
theme_classic() +
labs(x = " ", y = "Cl (mg/L)", title = "Samples: Chloride") +
theme(legend.position = "none") +
scale_x_discrete(drop = TRUE)
viz_so4_plot <-  ggplot(dat_flagged_id, aes(x = row_num, y = SO4_ppm, fill = Zone)) +
geom_bar(stat = "identity", position = position_dodge2(preserve = "single")) +
facet_grid(~ Site_Code, scales="free_x") +
scale_fill_manual(values = c(
"UP" = "#20063B",
"TR" = "#FFBC42",
"SWAMP" = "darkgrey",
"WC" = "#419973",
"SW" = "#25ABE6"
)) +
theme_classic() +
labs(x = " ", y = "TN (mg/L)", title = "Samples: TN") +
theme(legend.position = "none") +
scale_x_discrete(drop = TRUE)
#print(viz_c_plot)
#print(viz_n_plot)
ggarrange(viz_cl_plot, viz_so4_plot, nrow=2, ncol=1)
## Remove once you fix the flagging chunk
#Pull in data that from the raw data file based on the sample info input above
dat_flagged <- all_dat %>%
filter(!str_detect(sample_ID, "PPR")) %>%
filter(!str_detect(sample_ID, "_dup")) %>%
filter(!str_detect(sample_ID, "_spk")) %>%
filter(str_detect(sample_ID, samples_pattern))
cat("Visualize Data")
#Plot samples to get a first look at concentrations (sanity check)
IDs <- data.frame(do.call('rbind', strsplit(as.character(dat_flagged$sample_name),'_',fixed=TRUE)))
colnames(IDs) <- c("Sample_Number", "Site_Code","Date" ,"Zone", "Lysimeter", "Depth", "Excess_Info")
## Remove once you fix the flagging chunk
#Pull in data that from the raw data file based on the sample info input above
dat_flagged <- all_dat %>%
filter(!str_detect(sample_ID, "PPR")) %>%
filter(!str_detect(sample_ID, "_dup")) %>%
filter(!str_detect(sample_ID, "_spk")) %>%
filter(str_detect(sample_ID, samples_pattern))
cat("Visualize Data")
#Plot samples to get a first look at concentrations (sanity check)
IDs <- data.frame(do.call('rbind', strsplit(as.character(dat_flagged$sample_name),'_',fixed=TRUE)))
colnames(IDs) <- c("Sample_Number", "Site_Code","Date" ,"Zone", "Lysimeter", "Depth") #, "Excess_Info")
#head(IDs)
#rejoin them to the dataframe
dat_flagged_id <- cbind(IDs, dat_flagged)
#group the data for plotting
dat_flagged_id <- dat_flagged_id %>%
group_by(Site_Code) %>%
mutate(row_num = factor(row_number())) %>%  # create row_num as factor per group
ungroup()
#Plot data and change colors based on flags to check it:
viz_cl_plot <- ggplot(dat_flagged_id, aes(x = factor(row_num), y = Cl_ppm, fill = Zone)) +
geom_bar(stat = "identity", position = position_dodge2(preserve = "single")) +
facet_grid(~ Site_Code, scales="free_x") +
scale_fill_manual(values = c(
"UP" = "#20063B",
"TR" = "#FFBC42",
"SWAMP" = "darkgrey",
"WC" = "#419973",
"SW" = "#25ABE6"
)) +
theme_classic() +
labs(x = " ", y = "Cl (mg/L)", title = "Samples: Chloride") +
theme(legend.position = "none") +
scale_x_discrete(drop = TRUE)
viz_so4_plot <-  ggplot(dat_flagged_id, aes(x = row_num, y = SO4_ppm, fill = Zone)) +
geom_bar(stat = "identity", position = position_dodge2(preserve = "single")) +
facet_grid(~ Site_Code, scales="free_x") +
scale_fill_manual(values = c(
"UP" = "#20063B",
"TR" = "#FFBC42",
"SWAMP" = "darkgrey",
"WC" = "#419973",
"SW" = "#25ABE6"
)) +
theme_classic() +
labs(x = " ", y = "TN (mg/L)", title = "Samples: TN") +
theme(legend.position = "none") +
scale_x_discrete(drop = TRUE)
#print(viz_c_plot)
#print(viz_n_plot)
ggarrange(viz_cl_plot, viz_so4_plot, nrow=2, ncol=1)
cat("Check Sample IDs with Metadata")
#remove duplicates from the sample dataframe bc we are just taking the first dup run
all_data_flagged <- dat_flagged_id %>%
filter(!str_detect(sample_ID, "dup")) #%>%
#select(!Excess_Info)
#check to see if all samples are present in the metadata
all_present <- all(all_data_flagged$sample_ID %in% dionex_metadata$Cl_SO4_ID)
if (all_present) {
message("All sample IDs are present in metadata.")
} else {
message("Some sample IDs are missing from metadata.")
# Optional: Which ones are missing?
missing_ids <- setdiff(all_data_flagged$sample_ID, dionex_metadata$Cl_SO4_ID)
print(missing_ids)
}
dionex_metadata_selected <- dionex_metadata %>%
select(Cl_SO4_ID, Year, Month, Day, Depth_cm, Lysimeter, Time..24hr., Time.Zone_EDT.EST,  Field.Notes)
#merge metadata with sample run data
merged_data <- all_data_flagged %>%
left_join(dionex_metadata_selected, by = c("sample_ID" = "Cl_SO4_ID"))
cat("Check Sample IDs with Metadata")
#remove duplicates from the sample dataframe bc we are just taking the first dup run
all_data_flagged <- dat_flagged_id %>%
filter(!str_detect(sample_ID, "dup")) %>%
mutate(sample_ID = sub("^[^_]+_", "", sample_ID))
#select(!Excess_Info)
#check to see if all samples are present in the metadata
all_present <- all(all_data_flagged$sample_ID %in% dionex_metadata$Cl_SO4_ID)
if (all_present) {
message("All sample IDs are present in metadata.")
} else {
message("Some sample IDs are missing from metadata.")
# Optional: Which ones are missing?
missing_ids <- setdiff(all_data_flagged$sample_ID, dionex_metadata$Cl_SO4_ID)
print(missing_ids)
}
dionex_metadata_selected <- dionex_metadata %>%
select(Cl_SO4_ID, Year, Month, Day, Depth_cm, Lysimeter, Time..24hr., Time.Zone_EDT.EST,  Field.Notes)
#merge metadata with sample run data
merged_data <- all_data_flagged %>%
left_join(dionex_metadata_selected, by = c("sample_ID" = "Cl_SO4_ID"))
