TRUE ~ `Zone`
))
cat("Visualize Data")
### Nitrite + Nitrate
NOx_forplot <- df_all_clean %>%
filter(Test == "Vanadium NOx")
#group the data for plotting
NOx_forplot <- NOx_forplot %>%
group_by(Site) %>%
mutate(row_num = factor(row_number())) %>%  # create row_num as factor per group
ungroup()
viz_NOx_plot <-  ggplot(data = NOx_forplot, aes(x = factor(row_num), y = Conc, fill=Zone)) +
geom_bar(stat = "identity", position = position_dodge2(preserve = "single"),
color="black") +
facet_grid(~ Site, scales="free_x") +
scale_fill_manual(values = c("UP" = "#20063B",
"TR" = "#FFBC42",
"SWAMP" = "darkgrey",
"WC" = "#419973",
"SW" = "#25ABE6")) +
theme_classic() +
labs(x= " ", y="NOx (mg/L)", title="Porewater NOx") +
theme(legend.position = "none") +
scale_x_discrete(drop = TRUE)+
theme(axis.text.x = element_text(angle = 90, hjust = 0.5))
### Ammonia
NH3_forplot <- df_all_clean %>%
filter(Test == "Ammonia 2")
#group the data for plotting
NH3_forplot <- NH3_forplot %>%
group_by(Site) %>%
mutate(row_num = factor(row_number())) %>%  # create row_num as factor per group
ungroup()
viz_NH3_plot <- ggplot(data = NH3_forplot, aes(x = factor(row_num), y = Conc, fill=Zone)) +
geom_bar(stat = "identity", position = position_dodge2(preserve = "single"),
color="black") +
facet_grid(~ Site, scales="free_x") +
scale_fill_manual(values = c("UP" = "#20063B",
"TR" = "#FFBC42",
"SWAMP" = "darkgrey",
"WC" = "#419973",
"SW" = "#25ABE6")) +
theme_classic() +
labs(x= " ", y="NH3 (mg/L)", title="Porewater NH3") +
theme(legend.position = "none") +
scale_x_discrete(drop = TRUE)+
theme(axis.text.x = element_text(angle = 90, hjust = 0.5))
### Phosphate
PO4_forplot <- df_all_clean %>%
filter(Test == "o-PHOS 0.3")
#group the data for plotting
PO4_forplot <- PO4_forplot %>%
group_by(Site) %>%
mutate(row_num = factor(row_number())) %>%  # create row_num as factor per group
ungroup()
viz_PO4_plot <- ggplot(data = PO4_forplot, aes(x = factor(row_num), y = Conc, fill=Zone)) +
geom_bar(stat = "identity", position = position_dodge2(preserve = "single"),
color="black") +
facet_grid(~ Site, scales="free_x") +
scale_fill_manual(values = c("UP" = "#20063B",
"TR" = "#FFBC42",
"SWAMP" = "darkgrey",
"WC" = "#419973",
"SW" = "#25ABE6")) +
theme_classic() +
labs(x= " ", y="PO4 (mg/L)", title="Porewater PO4") +
theme(legend.position = "none") +
scale_x_discrete(drop = TRUE)+
theme(axis.text.x = element_text(angle = 90, hjust = 0.5))
print(viz_NOx_plot)
print(viz_NH3_plot)
print(viz_PO4_plot)
cat("Export Processed Data")
#pivot the data set wider to make it wide format
final_data1 <- df_all_clean %>%
pivot_wider(
id_cols = Sample_Name,
names_from = Test,
values_from = Conc,
names_glue = "{Test}_Conc"
)
final_data2 <- df_all_clean %>%
pivot_wider(
id_cols = Sample_Name,
names_from = Test,
values_from = Conc_uM,
names_glue = "{Test}_Conc_uM"
)
final_data3 <- df_all_clean %>%
pivot_wider(
id_cols = Sample_Name,
names_from = Test,
values_from = Conc_flag,
names_glue = "{Test}_Conc_flag"
)
#take out only the columns we want to merge
df_all_clean_cols <- df_all_clean %>%
select(Sample_Name, Site, Zone, Depth, Depth_cm, Lysimeter,
Year, Month, Day, Time..24hr., Time.Zone_EDT.EST,
NOx_flag, NH3_flag, PO4_flag,
Field.Notes)
df_all_clean_cols_one_row <- df_all_clean_cols %>%
group_by(Sample_Name) %>%
slice(1) %>%  # or use summarise() if you want to aggregate
ungroup()
#merge these together
data_list <- list(df_all_clean_cols_one_row, final_data1, final_data2, final_data3)
final_data4 <- reduce(data_list, full_join, by = c("Sample_Name"))
#Add project information
final_data_labeled <- final_data4 %>%
mutate(
Project = "COMPASS: Synoptic",   # new column with same value on every row
Region = "CB",
Run_notes = run_notes,
Analysis_rundate = print(run_date)# new column with notes about the run
)
#Prepare data to be exported
final_data <- final_data_labeled %>%
rename(
Site = Site,
Sample_ID = Sample_Name,
Time = Time..24hr.,
Time_Zone = Time.Zone_EDT.EST,
Replicate = Lysimeter,
NOx_Conc_mgL = `Vanadium NOx_Conc`,
NOx_Conc_uM = `Vanadium NOx_Conc_uM`,
NOx_Conc_Flag = `Vanadium NOx_Conc_flag`,
NOx_QAQC_Flag = NOx_flag,
NH3_Conc_mgL = `Ammonia 2_Conc`,
NH3_Conc_uM = `Ammonia 2_Conc_uM`,
NH3_Conc_Flag =`Ammonia 2_Conc_flag`,
NH3_QAQC_Flag = NH3_flag,
PO4_Conc_mgL = `o-PHOS 0.3_Conc`,
PO4_Conc_uM = `o-PHOS 0.3_Conc_uM`,
PO4_Conc_Flag =`o-PHOS 0.3_Conc_flag`,
PO4_QAQC_Flag = PO4_flag,
Field_notes = Field.Notes
# add more rename pairs as needed
) %>%
select(Project, Region, Site, Zone, Replicate, Depth_cm,
Sample_ID, Year, Month, Day, Time, Time_Zone,
NOx_Conc_mgL, NOx_Conc_uM, NOx_Conc_Flag, NOx_QAQC_Flag,
NH3_Conc_mgL, NH3_Conc_uM, NH3_Conc_Flag, NH3_QAQC_Flag,
PO4_Conc_mgL, PO4_Conc_uM, PO4_Conc_Flag, PO4_QAQC_Flag,
Analysis_rundate,  Run_notes, Field_notes)
#Write out data frame
write.csv(final_data, final_path)
View(final_data)
View(raw_metadata)
#let you know which section you are in
cat("Setup")
#a link to the Gitbook or whatever protocol you are using for this analysis
#load/install packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
dplyr,
purrr,
ggplot2,
ggpubr,
tidyr,
tidyverse,
tinytex,
stringr,
readr,
LaTeX,
MacTeX,
tinytex,
here,
broom)
#Coefficients / constants that are needed for calculations
N_mw <- 14.0067    # molecular weight of N
P_mw <- 30.973762  # molecular weight of P
Con1 <- 1000       # conversion factor value
Con2 <- 1000000    # conversion factor value
#Detection limit and top standards for flagging
NOx_dl <- 0.025  #mgL
NH3_dl <- 0.02  #mgL
PO4_dl <- 0.003 #mgL
NOx_top <- 1  #mgL
NH3_top <- 2  #mgL
PO4_top <- 0.3 #mgL
#Check Standard concnetrations
NOx_CCV <- 0.5
NH3_CCV <- 1.0
PO4_CCV <- 0.15
#Spike Concentrations
NOx_Spk <- 0.5 #ppm or mg/L
NH3_Spk <- 1
PO4_Spk <- 0.152
#expected ranges for sample concentrations used for flags
r2_cutoff = 0.990
chk_flag = 0.10
chk_conc_flag = 15 #cutoff level for percent difference of check stds vs. expected concentration
chks_flag = 60
rep_flag = 25
#^this is a 25% error between samples
#blank_flag is calculated based on samples later in this code
cat("Run Information: Input by User") #lets you know what section you're in
#set the run date & user name
run_date <- "20240114"
sample_year <- 2023
sample_month <- 06
user <- "Stephanie Wilson"
#identify the files you want to read in
#read in as a list to accommadate ultiple runs in a month
NOx_files <- c("Raw Data/SEAL_COMPASS_Synoptic_NOx_June2023_1.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NOx_June2023_2.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NOx_June2023_3.csv")
NH3_PO4_files <- c("Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_June2023_1.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_June2023_2.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_June2023_3.csv")
# Define the file path for QAQC log file - NO Need to change just check year
file_path <- "Raw Data/SEAL_COMPASS_Synoptic_QAQC_Log_2023.csv"
# Define Final Path for Processed Data
final_path <- "Processed Data/COMPASS_Synoptic_Nutrients_202306.csv"
#record any notes about the run or anything other info here:
run_notes <- "There are two sample names we suspect were input incorrectly,
they are listed below and have been checked against metadata. The metadata from Goodwin ans Sweethall samples is not present."
#duplicate sample names to be changed
#list the sample iDs that are messed up and create a list
#with run number as well so that we can change them below
wrong_names <- c("GCW_202304_TR_LysC_45cm", "GCW_202304_TR_LysA_20cm_8",
"GWI_202304_UP_LysA_20cm", "GWI_202304_UP_LysA_20cm")
wrong_nums <- c(20, 16, 46, 44)
correct_names <- c("GCW_202304_TR_LysB_45cm", "GCW_202304_TR_LysA_20cm",
"GWI_202304_UP_LysA_10cm", "GWI_202304_UP_LysA_10cm")
#can't determine from metadata - for now unsure
remove_names <- c("GCW_202304_TR_LysA_20cm", "GCW_202304_TR_LysA_20cm",
"GCW_202304_TR_LysB_20cm_13", "GCW_202304_TR_LysB_20cm_13")
#couldn't tell which onethis is from the metadata, no A_10cm which is what we thought
#marked on the sheet, need to check sample vials in freezer
#to see if we have a A_10cm from GCW_TR to be sure
remove_nums <- c(15, 13, 21, 19 )
#Set up file path for metadata
#downloaded metadata csv - downloaded from Google drive as csv for this year
#https://docs.google.com/spreadsheets/d/1HCAN0_q6y17x0RUXVzID09hVal-RfwWc/edit?usp=sharing&ouid=108994740386869376571&rtpof=true&sd=true
Raw_Metadata_Path <- file.path("Raw Data", "COMPASS_SynopticCB_PW_SampleLog_2023.csv")
#let you know which section you are in
cat("Setup")
#a link to the Gitbook or whatever protocol you are using for this analysis
#load/install packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
dplyr,
purrr,
ggplot2,
ggpubr,
tidyr,
tidyverse,
tinytex,
stringr,
readr,
LaTeX,
MacTeX,
tinytex,
here,
broom)
#Coefficients / constants that are needed for calculations
N_mw <- 14.0067    # molecular weight of N
P_mw <- 30.973762  # molecular weight of P
Con1 <- 1000       # conversion factor value
Con2 <- 1000000    # conversion factor value
#Detection limit and top standards for flagging
NOx_dl <- 0.025  #mgL
NH3_dl <- 0.02  #mgL
PO4_dl <- 0.003 #mgL
NOx_top <- 1  #mgL
NH3_top <- 2  #mgL
PO4_top <- 0.3 #mgL
#Check Standard concnetrations
NOx_CCV <- 0.5
NH3_CCV <- 1.0
PO4_CCV <- 0.15
#Spike Concentrations
NOx_Spk <- 0.5 #ppm or mg/L
NH3_Spk <- 1
PO4_Spk <- 0.152
#expected ranges for sample concentrations used for flags
r2_cutoff = 0.990
chk_flag = 0.10
chk_conc_flag = 15 #cutoff level for percent difference of check stds vs. expected concentration
chks_flag = 60
rep_flag = 25
#^this is a 25% error between samples
#blank_flag is calculated based on samples later in this code
#read in the raw metadata file
raw_metadata <- readr::read_csv(
here("Raw Data", "COMPASS_SynopticCB_PW_SampleLog_2023.csv"))
#make a new columns in the metadata with important info:
metadata <- raw_metadata %>%
mutate(Depth = paste0(Depth_cm, "cm")) %>%
mutate(LysID = paste0("Lys", Lysimeter)) %>%
mutate(YearMonth = sprintf("%d%02d", Year, Month))  %>%
mutate(`Transect Location` = case_when(
`Transect Location` == "Transition" ~ "TR",
`Transect Location` == "Wetland"    ~ "WC",
`Transect Location` == "Upland"     ~ "UP",
`Transect Location` == "Surface Water" ~ "SW",
TRUE                 ~ `Transect Location`    # keep original value if no match
))
#Create NUTR IDs from what was collected for comparison later
metadata <- metadata %>%
mutate(NUTR_ID = ifelse(NUTR == "x",
paste(Site,
YearMonth,
`Transect Location`,
LysID,
Depth,
sep = "_"),
NA) )
#Change the SW lines because they don't have lysimeters or a depth
metadata <- metadata %>%
mutate(
NUTR_ID = if_else(
`Transect Location` == "SW",
# Modify the string:
NUTR_ID %>%
str_replace("_LysA", "_A") %>%                    # Replace "_LysA" with "_A"
str_replace("_LysB", "_B") %>%                    # Replace "_LysB" with "_B"
str_replace("_LysC", "_C") %>%                    # Replace "_LysC" with "_C"
str_replace("_0cm$", ""),                         # Remove trailing "_0cm"
NUTR_ID  # else keep original
)
)
#Take out the columns and rows that are not relevant
nutr_metadata <- metadata %>%
select(NUTR_ID, Year, Month, Day, YearMonth, Site, Zone, Lysimeter, LysID, Depth_cm,
Depth, Time..24hr., Time.Zone_EDT.EST, Field.Notes, ) %>%
# only keep specific columns
filter(!is.na(NUTR_ID) & NUTR_ID != "")  # remove missing/blank NUTR_ID rows
#read in the raw metadata file
raw_metadata <- readr::read_csv(
here("Raw Data", "COMPASS_SynopticCB_PW_SampleLog_2023.csv"))
#make a new columns in the metadata with important info:
metadata <- raw_metadata %>%
mutate(Depth = paste0(Depth_cm, "cm")) %>%
mutate(LysID = paste0("Lys", Lysimeter)) %>%
mutate(YearMonth = sprintf("%d%02d", Year, Month))  %>%
mutate(Zone = case_when(
`Transect Location` == "Transition" ~ "TR",
`Transect Location` == "Wetland"    ~ "WC",
`Transect Location` == "Upland"     ~ "UP",
`Transect Location` == "Surface Water" ~ "SW",
TRUE                 ~ `Transect Location`    # keep original value if no match
))
#Create NUTR IDs from what was collected for comparison later
metadata <- metadata %>%
mutate(NUTR_ID = ifelse(NUTR == "x",
paste(Site,
YearMonth,
`Transect Location`,
LysID,
Depth,
sep = "_"),
NA) )
#Change the SW lines because they don't have lysimeters or a depth
metadata <- metadata %>%
mutate(
NUTR_ID = if_else(
`Transect Location` == "SW",
# Modify the string:
NUTR_ID %>%
str_replace("_LysA", "_A") %>%                    # Replace "_LysA" with "_A"
str_replace("_LysB", "_B") %>%                    # Replace "_LysB" with "_B"
str_replace("_LysC", "_C") %>%                    # Replace "_LysC" with "_C"
str_replace("_0cm$", ""),                         # Remove trailing "_0cm"
NUTR_ID  # else keep original
)
)
#Take out the columns and rows that are not relevant
nutr_metadata <- metadata %>%
select(NUTR_ID, Year, Month, Day, YearMonth, Site, Zone, Lysimeter, LysID, Depth_cm,
Depth, Time..24hr., Time.Zone_EDT.EST, Field.Notes, ) %>%
# only keep specific columns
filter(!is.na(NUTR_ID) & NUTR_ID != "")  # remove missing/blank NUTR_ID rows
View(raw_metadata)
#read in the raw metadata file
raw_metadata <- readr::read_csv(
here("Raw Data", "COMPASS_SynopticCB_PW_SampleLog_2023.csv"))
#make a new columns in the metadata with important info:
metadata <- raw_metadata %>%
mutate(Depth = paste0(Depth_cm, "cm")) %>%
mutate(LysID = paste0("Lys", Lysimeter)) %>%
mutate(YearMonth = sprintf("%d%02d", Year, Month))  %>%
mutate(Zone = case_when(
`Transect Location` == "Transition" ~ "TR",
`Transect Location` == "Wetland"    ~ "WC",
`Transect Location` == "Upland"     ~ "UP",
`Transect Location` == "Surface Water" ~ "SW",
TRUE                 ~ `Transect Location`    # keep original value if no match
))
#Create NUTR IDs from what was collected for comparison later
metadata <- metadata %>%
mutate(NUTR_ID = ifelse(NUTR == "x",
paste(Site,
YearMonth,
`Transect Location`,
LysID,
Depth,
sep = "_"),
NA) )
#Change the SW lines because they don't have lysimeters or a depth
metadata <- metadata %>%
mutate(
NUTR_ID = if_else(
`Transect Location` == "SW",
# Modify the string:
NUTR_ID %>%
str_replace("_LysA", "_A") %>%                    # Replace "_LysA" with "_A"
str_replace("_LysB", "_B") %>%                    # Replace "_LysB" with "_B"
str_replace("_LysC", "_C") %>%                    # Replace "_LysC" with "_C"
str_replace("_0cm$", ""),                         # Remove trailing "_0cm"
NUTR_ID  # else keep original
)
)
#Take out the columns and rows that are not relevant
nutr_metadata <- metadata %>%
select(NUTR_ID, Year, Month, Day, YearMonth, Site, Zone, Lysimeter, LysID, Depth_cm,
Depth, `Time (24hr)`, Time.Zone_EDT.EST, Field.Notes, ) %>%
# only keep specific columns
filter(!is.na(NUTR_ID) & NUTR_ID != "")  # remove missing/blank NUTR_ID rows
#read in the raw metadata file
raw_metadata <- readr::read_csv(
here("Raw Data", "COMPASS_SynopticCB_PW_SampleLog_2023.csv"))
#make a new columns in the metadata with important info:
metadata <- raw_metadata %>%
mutate(Depth = paste0(Depth_cm, "cm")) %>%
mutate(LysID = paste0("Lys", Lysimeter)) %>%
mutate(YearMonth = sprintf("%d%02d", Year, Month))  %>%
mutate(Zone = case_when(
`Transect Location` == "Transition" ~ "TR",
`Transect Location` == "Wetland"    ~ "WC",
`Transect Location` == "Upland"     ~ "UP",
`Transect Location` == "Surface Water" ~ "SW",
TRUE                 ~ `Transect Location`    # keep original value if no match
))
#Create NUTR IDs from what was collected for comparison later
metadata <- metadata %>%
mutate(NUTR_ID = ifelse(NUTR == "x",
paste(Site,
YearMonth,
`Transect Location`,
LysID,
Depth,
sep = "_"),
NA) )
#Change the SW lines because they don't have lysimeters or a depth
metadata <- metadata %>%
mutate(
NUTR_ID = if_else(
`Transect Location` == "SW",
# Modify the string:
NUTR_ID %>%
str_replace("_LysA", "_A") %>%                    # Replace "_LysA" with "_A"
str_replace("_LysB", "_B") %>%                    # Replace "_LysB" with "_B"
str_replace("_LysC", "_C") %>%                    # Replace "_LysC" with "_C"
str_replace("_0cm$", ""),                         # Remove trailing "_0cm"
NUTR_ID  # else keep original
)
)
#Take out the columns and rows that are not relevant
nutr_metadata <- metadata %>%
select(NUTR_ID, Year, Month, Day, YearMonth, Site, Zone, Lysimeter, LysID, Depth_cm,
Depth, `Time (24hr)`, `Time Zone_EDT/EST`, Field.Notes, ) %>%
# only keep specific columns
filter(!is.na(NUTR_ID) & NUTR_ID != "")  # remove missing/blank NUTR_ID rows
#read in the raw metadata file
raw_metadata <- readr::read_csv(
here("Raw Data", "COMPASS_SynopticCB_PW_SampleLog_2023.csv"))
#make a new columns in the metadata with important info:
metadata <- raw_metadata %>%
mutate(Depth = paste0(Depth_cm, "cm")) %>%
mutate(LysID = paste0("Lys", Lysimeter)) %>%
mutate(YearMonth = sprintf("%d%02d", Year, Month))  %>%
mutate(Zone = case_when(
`Transect Location` == "Transition" ~ "TR",
`Transect Location` == "Wetland"    ~ "WC",
`Transect Location` == "Upland"     ~ "UP",
`Transect Location` == "Surface Water" ~ "SW",
TRUE                 ~ `Transect Location`    # keep original value if no match
))
#Create NUTR IDs from what was collected for comparison later
metadata <- metadata %>%
mutate(NUTR_ID = ifelse(NUTR == "x",
paste(Site,
YearMonth,
`Transect Location`,
LysID,
Depth,
sep = "_"),
NA) )
#Change the SW lines because they don't have lysimeters or a depth
metadata <- metadata %>%
mutate(
NUTR_ID = if_else(
`Transect Location` == "SW",
# Modify the string:
NUTR_ID %>%
str_replace("_LysA", "_A") %>%                    # Replace "_LysA" with "_A"
str_replace("_LysB", "_B") %>%                    # Replace "_LysB" with "_B"
str_replace("_LysC", "_C") %>%                    # Replace "_LysC" with "_C"
str_replace("_0cm$", ""),                         # Remove trailing "_0cm"
NUTR_ID  # else keep original
)
)
#Take out the columns and rows that are not relevant
nutr_metadata <- metadata %>%
select(NUTR_ID, Year, Month, Day, YearMonth, Site, Zone, Lysimeter, LysID, Depth_cm,
Depth, `Time (24hr)`, `Time Zone_EDT/EST`, `Field Notes`, ) %>%
# only keep specific columns
filter(!is.na(NUTR_ID) & NUTR_ID != "")  # remove missing/blank NUTR_ID rows
View(metadata)
