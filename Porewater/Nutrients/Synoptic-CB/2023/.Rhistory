NH3_QAQC_Flag = NH3_flag,
PO4_Conc_mgL = `o-PHOS 0.3_Conc`,
PO4_Conc_uM = `o-PHOS 0.3_Conc_uM`,
PO4_Conc_Flag =`o-PHOS 0.3_Conc_flag`,
PO4_QAQC_Flag = PO4_flag,
Field_notes = Field.Notes
# add more rename pairs as needed
) %>%
select(Project, Region, Site, Zone, Replicate, Depth_cm,
Sample_ID, Year, Month, Day, Time, Time_Zone,
NOx_Conc_mgL, NOx_Conc_uM, NOx_Conc_Flag, NOx_QAQC_Flag,
NH3_Conc_mgL, NH3_Conc_uM, NH3_Conc_Flag, NH3_QAQC_Flag,
PO4_Conc_mgL, PO4_Conc_uM, PO4_Conc_Flag, PO4_QAQC_Flag,
Analysis_rundate,  Run_notes, Field_notes)
#Write out data frame
write.csv(final_data, final_path)
redoA <-  read.csv("Raw Data/SEAL_COMPASS_Synoptic_NOx_May2023_3_redoA.csv")
redo <-  read.csv("Raw Data/SEAL_COMPASS_Synoptic_NOx_May2023_3_redo.csv")
redo_vs_redoA <- anti_join(redoA, redo)
View(redo)
View(redo_vs_redoA)
redoA_vs_redo <- anit_join(redo, redoA)
redo_vs_redoA <- anti_join(redoA, redo)
redoA_vs_redo <- anti_join(redo, redoA)
NOx_files <- c("Raw Data/SEAL_COMPASS_Synoptic_NOx_April2023_1.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NOx_April2023_TEMPEST_May2023_2.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NOx_May2023_1.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NOx_May2023_2_redo.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NOx_May2023_3_redo.csv")
NH3_PO4_files <- c("Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_April2023_1.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_April2023_TEMPEST_May2023_2.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_May_1redopo4.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_May_3.csv")
# Define the file path for QAQC log file - NO Need to change just check year
file_path <- "Raw Data/SEAL_COMPASS_Synoptic_QAQC_Log_2023.csv"
final_path_april <- "Raw Data/*COMPASS_Synoptic_Nutrients_2023_April.csv"
file_path_may <- "Raw Data/*COMPASS_Synoptic_Nutrients_2023_May.csv"
#set file path for data - in run info chunk
path <- ("file path")
#Read in Raw Data
data_NOx <- map(NOx_files, read_csv)
data_NH3_PO4 <- map(NH3_PO4_files, read_csv)
cat("Run Information: I. Van Benschoten") #lets you know what section you're in
#check if redo and redoA are the same
redoA <-  read.csv("Raw Data/SEAL_COMPASS_Synoptic_NOx_May2023_3_redoA.csv")
redo <-  read.csv("Raw Data/SEAL_COMPASS_Synoptic_NOx_May2023_3_redo.csv")
redo_vs_redoA <- anti_join(redoA, redo)
redoA_vs_redo <- anti_join(redo, redoA)
#identify the files you want to read in
#read in as a list to accommadate ultiple runs in a month
NOx_files <- c("Raw Data/SEAL_COMPASS_Synoptic_NOx_April2023_1.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NOx_April2023_TEMPEST_May2023_2.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NOx_May2023_1.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NOx_May2023_2_redo.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NOx_May2023_3_redo.csv")
NH3_PO4_files <- c("Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_April2023_1.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_April2023_TEMPEST_May2023_2.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_May2023_1redopo4.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_May2023_3.csv")
# Define the file path for QAQC log file - NO Need to change just check year
file_path <- "Raw Data/SEAL_COMPASS_Synoptic_QAQC_Log_2023.csv"
final_path_april <- "Raw Data/*COMPASS_Synoptic_Nutrients_2023_April.csv"
file_path_may <- "Raw Data/*COMPASS_Synoptic_Nutrients_2023_May.csv"
#some packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
dplyr,
purrr,
ggplot2,
ggpubr,
tidyr,
tidyverse,
tinytex,
stringr,
readr,
tinytex,
broom)
#set file path for data - in run info chunk
path <- ("file path")
#Read in Raw Data
data_NOx <- map(NOx_files, read_csv)
data_NH3_PO4 <- map(NH3_PO4_files, read_csv)
# Combining Files
df_combo <- bind_rows(data_NOx, data_NH3_PO4)
# Rename columns
df_combo_rename <- df_combo %>%
rename('Conc' = ...6,
'Absorbance' = ...7,
'Dilution' = ...9,
'Sample_Name' = ...4,
'Test' = ...13,
'Run_Time' = ...15,
'Unit' = ...12,
'Run_Number' = ...5)
#making list to remove columns
cols_to_remove <- c("RUNSTARTED", "...8", "...10", "...11", "...14")
#Removing columns
df <- df_combo_rename %>%
select(-all_of(cols_to_remove)) %>%
select(!c(1,2))%>%
select(Sample_Name, Run_Number, Conc, Absorbance, Dilution, Unit, Test, Run_Time)
#Checking column headers
head(df)
df_all <- df %>%
mutate(Run_Number = as.numeric(Run_Number))
View(df_all)
df_april <- df_all %>%
filter(str_detect(Sample_Name, "202304"))
View(df_april)
df_april <- df_all %>%
filter(str_detect(Sample_Name, "202304"))
df_may <- df_all %>%
filter(str_detect(Sample_Name, "202305"))
write.csv(df_april, file_path_april)
cat("Run Information: I. Van Benschoten") #lets you know what section you're in
#check if redo and redoA are the same
redoA <-  read.csv("Raw Data/SEAL_COMPASS_Synoptic_NOx_May2023_3_redoA.csv")
redo <-  read.csv("Raw Data/SEAL_COMPASS_Synoptic_NOx_May2023_3_redo.csv")
redo_vs_redoA <- anti_join(redoA, redo)
redoA_vs_redo <- anti_join(redo, redoA)
#identify the files you want to read in
#read in as a list to accommadate ultiple runs in a month
NOx_files <- c("Raw Data/SEAL_COMPASS_Synoptic_NOx_April2023_1.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NOx_April2023_TEMPEST_May2023_2.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NOx_May2023_1.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NOx_May2023_2_redo.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NOx_May2023_3_redo.csv")
NH3_PO4_files <- c("Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_April2023_1.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_April2023_TEMPEST_May2023_2.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_May2023_1redopo4.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_May2023_3.csv")
# Define the file path for QAQC log file - NO Need to change just check year
file_path_april <- "Raw Data/*COMPASS_Synoptic_Nutrients_2023_April.csv"
file_path_may <- "Raw Data/*COMPASS_Synoptic_Nutrients_2023_May.csv"
#some packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
dplyr,
purrr,
ggplot2,
ggpubr,
tidyr,
tidyverse,
tinytex,
stringr,
readr,
tinytex,
broom)
#set file path for data - in run info chunk
path <- ("file path")
#Read in Raw Data
data_NOx <- map(NOx_files, read_csv)
data_NH3_PO4 <- map(NH3_PO4_files, read_csv)
# Combining Files
df_combo <- bind_rows(data_NOx, data_NH3_PO4)
# Rename columns
df_combo_rename <- df_combo %>%
rename('Conc' = ...6,
'Absorbance' = ...7,
'Dilution' = ...9,
'Sample_Name' = ...4,
'Test' = ...13,
'Run_Time' = ...15,
'Unit' = ...12,
'Run_Number' = ...5)
#making list to remove columns
cols_to_remove <- c("RUNSTARTED", "...8", "...10", "...11", "...14")
#Removing columns
df <- df_combo_rename %>%
select(-all_of(cols_to_remove)) %>%
select(!c(1,2))%>%
select(Sample_Name, Run_Number, Conc, Absorbance, Dilution, Unit, Test, Run_Time)
#Checking column headers
head(df)
df_all <- df %>%
mutate(Run_Number = as.numeric(Run_Number))
df_april <- df_all %>%
filter(str_detect(Sample_Name, "202304"))
df_may <- df_all %>%
filter(str_detect(Sample_Name, "202305"))
write.csv(df_april, file_path_april)
file_path_april <- "Raw Data/COMPASS_Synoptic_Nutrients_clean_2023_April.csv"
file_path_may <- "Raw Data/COMPASS_Synoptic_Nutrients_clean_2023_May.csv"
write.csv(df_april, file_path_april)
write.csv(df_may, file_path_may)
#let you know which section you are in
cat("Setup")
#a link to the Gitbook or whatever protocol you are using for this analysis
#load/install packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
dplyr,
purrr,
ggplot2,
ggpubr,
tidyr,
tidyverse,
stringr,
readr,
LaTeX,
writexl,
tinytex,
write_excel,
broom)
#Coefficients / constants that are needed for calculations
N_mw <- 14.0067    # molecular weight of N
P_mw <- 30.973762  # molecular weight of P
Con1 <- 1000       # conversion factor value
Con2 <- 1000000    # conversion factor value
#Detection limit and top standards for flagging
NOx_dl <- 0.025  #mgL
NH3_dl <- 0.02  #mgL
PO4_dl <- 0.003 #mgL
NOx_top <- 1  #mgL
NH3_top <- 2  #mgL
PO4_top <- 0.3 #mgL
#Check Standard concnetrations
NOx_CCV <- 0.5
NH3_CCV <- 1.0
PO4_CCV <- 0.15
#Spike Concentrations
NOx_Spk <- 0.5 #ppm or mg/L
NH3_Spk <- 1
PO4_Spk <- 0.152
#expected ranges for sample concentrations used for flags
r2_cutoff = 0.990
chk_flag = 0.10
chk_conc_flag = 15 #cutoff level for percent difference of check stds vs. expected concentration
chks_flag = 60
rep_flag = 25
#^this is a 25% error between samples
#blank_flag is calculated based on samples later in this code
#pe check Concentrations
NH3_pe <- 0.948
NOx_pe <- 0.706
PO4_pe <- 0.818
cat("Run Information: Input by User") #lets you know what section you're in
#set the run date & user name
run_date <- "20240604"
sample_year <- 2023
sample_month <- 05
user <- "Stephanie Wilson"
#identify the files you want to read in
#read in as a list to accommodate multiple runs in a month
files <- c("Raw Data/COMPASS_Synoptic_Nutrients_clean_2023_May.csv")
# Define the file path for QAQC log file - NO Need to change just check year
file_path <- "Raw Data/SEAL_COMPASS_Synoptic_QAQC_Log_2023.csv"
final_path <- "Processed Data/COMPASS_Synoptic_Nutrients_202305.csv"
#record any notes about the run or anything other info here:
run_notes <- "Multiple months of data were mixed together so they were parsed and cleaned prior to read in. Autospikes for PO4 not included in this run. "
#duplicate sample names to be changed
#list the sample iDs that are messed up and create a list
#with run number as well so that we can change them below
# wrong_names <- c("GCW_202304_TR_LysC_45cm", "GCW_202304_TR_LysA_20cm_8",
#                  "GWI_202304_UP_LysA_20cm", "GWI_202304_UP_LysA_20cm")
#  wrong_nums <- c(20, 16, 46, 44)
#  correct_names <- c("GCW_202304_TR_LysB_45cm", "GCW_202304_TR_LysA_20cm",
#                     "GWI_202304_UP_LysA_10cm", "GWI_202304_UP_LysA_10cm")
#can't determine from metadata - for now unsure
# remove_names <- c("GCW_202304_TR_LysA_20cm", "GCW_202304_TR_LysA_20cm",
#                  "GCW_202304_TR_LysB_20cm_13", "GCW_202304_TR_LysB_20cm_13")
#     #couldn't tell which onethis is from the metadata, no A_10cm which is what we thought
#marked on the sheet, need to check sample vials in freezer
#to see if we have a A_10cm from GCW_TR to be sure
#remove_nums <- c(15, 13, 21, 19 )
#Set up file path for metadata
#downloaded metadata csv - downloaded from Google drive as csv for this year
#https://docs.google.com/spreadsheets/d/1HCAN0_q6y17x0RUXVzID09hVal-RfwWc/edit?usp=sharing&ouid=108994740386869376571&rtpof=true&sd=true
Raw_Metadata = "Raw Data/COMPASS_SynopticCB_PW_SampleLog_2023.csv"
#let you know which section you are in
cat("Setup")
#a link to the Gitbook or whatever protocol you are using for this analysis
#load/install packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
dplyr,
purrr,
ggplot2,
ggpubr,
tidyr,
tidyverse,
stringr,
readr,
LaTeX,
writexl,
tinytex,
write_excel,
broom)
#Coefficients / constants that are needed for calculations
N_mw <- 14.0067    # molecular weight of N
P_mw <- 30.973762  # molecular weight of P
Con1 <- 1000       # conversion factor value
Con2 <- 1000000    # conversion factor value
#Detection limit and top standards for flagging
NOx_dl <- 0.025  #mgL
NH3_dl <- 0.02  #mgL
PO4_dl <- 0.003 #mgL
NOx_top <- 1  #mgL
NH3_top <- 2  #mgL
PO4_top <- 0.3 #mgL
#Check Standard concnetrations
NOx_CCV <- 0.5
NH3_CCV <- 1.0
PO4_CCV <- 0.15
#Spike Concentrations
NOx_Spk <- 0.5 #ppm or mg/L
NH3_Spk <- 1
PO4_Spk <- 0.152
#expected ranges for sample concentrations used for flags
r2_cutoff = 0.990
chk_flag = 0.10
chk_conc_flag = 15 #cutoff level for percent difference of check stds vs. expected concentration
chks_flag = 60
rep_flag = 25
#^this is a 25% error between samples
#blank_flag is calculated based on samples later in this code
#pe check Concentrations
NH3_pe <- 0.948
NOx_pe <- 0.706
PO4_pe <- 0.818
#read in the raw metadata file
raw_metadata <- read.csv(Raw_Metadata)
#make a new columns in the metadata with important info:
metadata <- raw_metadata %>%
mutate(Depth = paste0(Depth_cm, "cm")) %>%
mutate(LysID = paste0("Lys", Lysimeter)) %>%
mutate(YearMonth = sprintf("%d%02d", Year, Month))  %>%
mutate(Zone = case_when(
`Transect.Location` == "Transition" ~ "TR",
`Transect.Location` == "Wetland"    ~ "WC",
`Transect.Location` == "Upland"     ~ "UP",
`Transect.Location` == "Surface Water" ~ "SW",
TRUE                 ~ `Transect.Location`    # keep original value if no match
))
#Create NUTR IDs from what was collected for comparison later
metadata <- metadata %>%
mutate(NUTR_ID = ifelse(NUTR == "x",
paste(Site,
YearMonth,
Zone,
LysID,
Depth,
sep = "_"),
NA) )
#Change the SW lines because they don't have lysimeters or a depth
metadata <- metadata %>%
mutate(
NUTR_ID = if_else(
Zone == "SW",
# Modify the string:
NUTR_ID %>%
str_replace("_LysA", "_A") %>%                    # Replace "_LysA" with "_A"
str_replace("_LysB", "_B") %>%                    # Replace "_LysB" with "_B"
str_replace("_LysC", "_C") %>%                    # Replace "_LysC" with "_C"
str_replace("_0cm$", ""),                         # Remove trailing "_0cm"
NUTR_ID  # else keep original
)
)
#Take out the columns and rows that are not relevant
nutr_metadata <- metadata %>%
select(NUTR_ID, Year, Month, Day, YearMonth, Site, Zone, Lysimeter, LysID, Depth_cm,
Depth, Time..24hr., Time.Zone_EDT.EST, Field.Notes, ) %>%
# only keep specific columns
filter(!is.na(NUTR_ID) & NUTR_ID != "")  # remove missing/blank NUTR_ID rows
cat("Import Data")
#set file path for data - in run info chunk
path <- ("file path")
#Read in Raw Data
df_all <- map(files, read_csv)
cat("Assess Standard Curves")
#Pull out standards
stds <- df_all %>%
filter(str_detect(Sample_Name, "Standard"))
#Read in Raw Data
df_all <- read.csv(files)
stds <- df_all %>%
filter(str_detect(Sample_Name, "Standard"))
cat("Assess Standard Curves")
#Pull out standards
stds <- df_all %>%
filter(str_detect(Sample_Name, "Standard"))
#Making standards dataframe based on the test
stds_NOx <- stds[stds$Test == "Vanadium NOx", ]
stds_NH3 <- stds[stds$Test == "Ammonia 2", ]
stds_PO4 <- stds[stds$Test == "o-PHOS 0.3", ]
#Inputting Standard Values Based on Protocol (LINK PROTOCOL)
stds_NOx <- stds_NOx %>%
mutate(`Conc` = case_when(
Sample_Name == "Standard 0" ~  0.0,
Sample_Name == "Standard 1" ~  0.0,
Sample_Name == "Standard 90" ~ 0.0222,
Sample_Name == "Standard 91" ~ 0.05,
Sample_Name == "Standard 92" ~ 0.1,
Sample_Name == "Standard 93" ~ 0.25,
Sample_Name == "Standard 94" ~ 0.5,
Sample_Name == "Standard 95" ~ 0.75,
Sample_Name == "Standard 96" ~ 1.0,
TRUE ~ `Conc`),  # leave unchanged if no match
Run_Date = format(mdy_hm(Run_Time), "%m-%d-%Y")) %>%
filter(!Sample_Name %in% c("Nitrate Standard" , "Nitrite Standard"))
#ID x and y
x1 <- stds_NOx$Absorbance
y1 <- stds_NOx$Conc
stds_NH3 <- stds_NH3 %>%
mutate(`Conc` = case_when(
Sample_Name == "Standard 0" ~  0.0,
Sample_Name == "Standard 1" ~  0.0,
Sample_Name == "Standard .0389" ~ 0.0389,
Sample_Name == "Standard .1000" ~ 0.1,
Sample_Name == "Standard .2000" ~ 0.2,
Sample_Name == "Standard .5000" ~ 0.5,
Sample_Name == "Standard 1.0000" ~ 1.0,
Sample_Name == "Standard 1.5000" ~ 1.5,
Sample_Name == "Standard 2.0000" ~ 2,
TRUE ~ `Conc`),  # leave unchanged if no match
Run_Date = format(mdy_hm(Run_Time), "%m-%d-%Y"))
# identifying x and y
x2 <- stds_NH3$Absorbance
y2 <- stds_NH3$Conc
stds_PO4 <- stds_PO4 %>%
mutate(`Conc` = case_when(
Sample_Name == "Standard 0" ~  0.0,
Sample_Name == "Standard 1" ~  0.0,
Sample_Name == "Standard 90" ~ 0.0060,
Sample_Name == "Standard 91" ~ 0.0150,
Sample_Name == "Standard 92" ~ 0.0300,
Sample_Name == "Standard 93" ~ 0.0750,
Sample_Name == "Standard 94" ~ 0.1500,
Sample_Name == "Standard 95" ~ 0.2250,
Sample_Name == "Standard 96" ~ 0.3000,
TRUE ~ `Conc`),  # leave unchanged if no match
Run_Date = format(mdy_hm(Run_Time), "%m-%d-%Y"))
#ID x and y
x3 <- stds_PO4$Absorbance
y3 <- stds_PO4$Conc
#generating line of best fit aka standard curves
#NOx
# Fit the quadratic model
quad_reg_NOx <- lm(y1 ~ x1 + I(x1^2))
View(stds_NH3)
View(stds)
file_path_all <- "Raw Data/COMPASS_Synoptic_Nutrients_df_all_2023.csv"
cat("Run Information: I. Van Benschoten") #lets you know what section you're in
#check if redo and redoA are the same
redoA <-  read.csv("Raw Data/SEAL_COMPASS_Synoptic_NOx_May2023_3_redoA.csv")
redo <-  read.csv("Raw Data/SEAL_COMPASS_Synoptic_NOx_May2023_3_redo.csv")
redo_vs_redoA <- anti_join(redoA, redo)
redoA_vs_redo <- anti_join(redo, redoA)
#identify the files you want to read in
#read in as a list to accommadate ultiple runs in a month
NOx_files <- c("Raw Data/SEAL_COMPASS_Synoptic_NOx_April2023_1.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NOx_April2023_TEMPEST_May2023_2.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NOx_May2023_1.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NOx_May2023_2_redo.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NOx_May2023_3_redo.csv")
NH3_PO4_files <- c("Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_April2023_1.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_April2023_TEMPEST_May2023_2.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_May2023_1redopo4.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_May2023_3.csv")
# Define the file path for QAQC log file - NO Need to change just check year
file_path_april <- "Raw Data/COMPASS_Synoptic_Nutrients_clean_2023_April.csv"
file_path_may <- "Raw Data/COMPASS_Synoptic_Nutrients_clean_2023_May.csv"
file_path_all <- "Raw Data/COMPASS_Synoptic_Nutrients_df_all_2023.csv"
#some packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
dplyr,
purrr,
ggplot2,
ggpubr,
tidyr,
tidyverse,
tinytex,
stringr,
readr,
tinytex,
broom)
#set file path for data - in run info chunk
path <- ("file path")
#Read in Raw Data
data_NOx <- map(NOx_files, read_csv)
data_NH3_PO4 <- map(NH3_PO4_files, read_csv)
# Combining Files
df_combo <- bind_rows(data_NOx, data_NH3_PO4)
# Rename columns
df_combo_rename <- df_combo %>%
rename('Conc' = ...6,
'Absorbance' = ...7,
'Dilution' = ...9,
'Sample_Name' = ...4,
'Test' = ...13,
'Run_Time' = ...15,
'Unit' = ...12,
'Run_Number' = ...5)
#making list to remove columns
cols_to_remove <- c("RUNSTARTED", "...8", "...10", "...11", "...14")
#Removing columns
df <- df_combo_rename %>%
select(-all_of(cols_to_remove)) %>%
select(!c(1,2))%>%
select(Sample_Name, Run_Number, Conc, Absorbance, Dilution, Unit, Test, Run_Time)
#Checking column headers
head(df)
df_all <- df %>%
mutate(Run_Number = as.numeric(Run_Number))
df_april <- df_all %>%
filter(str_detect(Sample_Name, "202304"))
df_may <- df_all %>%
filter(str_detect(Sample_Name, "202305"))
write.csv(df_april, file_path_april)
write.csv(df_may, file_path_may)
write.csv(df_all, file_path_all)
