#Convert values based on the Test ID
samples <- samples %>%
mutate(
Conc_uM = case_when(
Test == "Vanadium NOx" ~ (((as.numeric(samples$Conc))/Con1)/N_mw)*Con2,
Test == "Ammonia 2" ~ (((as.numeric(samples$Conc))/Con1)/N_mw)*Con2,
Test == "o-PHOS 0.3" ~ (((as.numeric(samples$Conc))/Con1)/P_mw)*Con2,
TRUE ~ as.numeric(NA)  # fallback in case of unexpected value
),
# Replace negatives with 0 in 'value' and 'value_converted'
Conc = pmax(Conc, 0),
Conc_uM = pmax(Conc_uM, 0)
)
head(samples)
cat("Sample Flagging")
#Flagging data if the concentration is outside the standards range
samples_flagged <- samples %>%
mutate(
Conc_flag = case_when(
Test == "Vanadium NOx" & Conc < NOx_dl ~ "bdl",
Test == "Vanadium NOx" & Conc > NOx_top    ~ "adl",
Test == "Vanadium NOx"               ~ "Within_Range",
Test == "Ammonia 2" & Conc < NH3_dl ~ "bdl",
Test == "Ammonia 2" & Conc > NH3_top    ~ "adl",
Test == "Ammonia 2"                ~ "Within_Range",
Test == "o-PHOS 0.3" & Conc < PO4_dl  ~ "bdl",
Test == "o-PHOS 0.3" & Conc > PO4_top   ~ "adl",
Test == "o-PHOS 0.3"                ~ "Within_Range",
TRUE ~ NA_character_  # fallback for unexpected values
)
)
cat("Sample Processing")
samples_flagged <- samples_flagged %>%
filter(str_detect(Sample_Name, "GCW|GWI|MSM|SWH")) %>%
filter(!str_detect(Sample_Name, "RHZ|PPR")) %>%
mutate(Run_Time = lubridate::mdy_hm(Run_Time)) %>%
separate(
col = Sample_Name,
sep = "_",
into = c("Site", "Samp_Time", "Zone", "Replicate", "Depth"),
remove = FALSE) %>%
mutate(Samp_Time = ym(Samp_Time))
cat("Rhizon Samples")
# Filter rhizon and peeper samples
df_rhizon <- df_all %>%
filter(str_detect(Sample_Name, "RHZ"))
df_peep <- df_all %>%
filter(str_detect(Sample_Name, "PPR"))
# Timestamp for backups
timestamp <- format(Sys.time(), "%Y-%m-%d_%H%M")
# Paths
folder_path <- file.path("Raw Data", "Rhizon+Peeper")
dir.create(folder_path, recursive = TRUE, showWarnings = FALSE)
rhizon_main <- file.path(folder_path, "rhizon_data.csv")
peeper_main <- file.path(folder_path, "peeper_data.csv")
rhizon_backup <- file.path(folder_path, paste0("rhizon_data_", timestamp, ".csv"))
peeper_backup <- file.path(folder_path, paste0("peeper_data_", timestamp, ".csv"))
# Write timestamped backups
write.csv(df_rhizon, rhizon_backup, row.names = FALSE)
write.csv(df_peep, peeper_backup, row.names = FALSE)
# Overwrite the main files with latest data
write.csv(df_rhizon, rhizon_main, row.names = FALSE)
write.csv(df_peep, peeper_main, row.names = FALSE)
## ^^ I think there is a cleaner way to write this out, but this should work for now ^^
cat("Check Sample IDs with Metadata")
#check to see if all samples are present in the metadata
all_present <- all(samples_flagged$Sample_Name %in% nutr_metadata$NUTR_ID)
if (all_present) {
message("All sample IDs are present in metadata.")
} else {
message("Some sample IDs are missing from metadata.")
# Optional: Which ones are missing?
missing_ids <- setdiff(samples_flagged$Sample_Name, nutr_metadata$NUTR_ID)
print(missing_ids)
}
nutr_metadata_selected <- nutr_metadata %>%
select(NUTR_ID, Year, Month, Day, Depth_cm, Lysimeter, Time..24hr., Time.Zone_EDT.EST,  Field.Notes)
#merge metadata with sample run data
merged_data <- samples_flagged %>%
left_join(nutr_metadata_selected, by = c("Sample_Name" = "NUTR_ID"))
df_all_clean <- merged_data %>%
#filter(str_detect(Sample_Name, "GCW|GWI|MSM|SWH")) %>%
#mutate(Run_Time = lubridate::mdy_hm(Run_Time)) %>%
separate(
col = Sample_Name,
sep = "_",
into = c("Site", "Samp_Time", "Zone", "Replicate", "Depth"),
remove = FALSE) %>%
mutate(Samp_Time = ym(Samp_Time))
############### THIS IS ONLY FOR 2023 when SWAMP was called UP and UPLAND was called UPCON ##############
df_all_clean <- df_all_clean %>%
mutate(
Zone = case_when(
Site == "SWH" & Zone == "UP" ~ "SWAMP",
Site == "SWH" & Zone == "UPCON" ~ "UP",
TRUE ~ `Zone`
))
#let you know which section you are in
cat("Run Information: Input by User")
#set the run date & user name
run_date <- "20240114"
sample_year <- 2023
sample_month <- 06
user <- "Stephanie Wilson"
#identify the files you want to read in
#read in as a list to accommadate ultiple runs in a month
NOx_files <- c("Raw Data/SEAL_COMPASS_Synoptic_NOx_June2023_1.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NOx_June2023_2.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NOx_June2023_3.csv")
NH3_PO4_files <- c("Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_June2023_1.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_June2023_2.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_June2023_3.csv")
# Define the file path for QAQC log file - NO Need to change just check year
file_path <- "Raw Data/SEAL_COMPASS_Synoptic_QAQC_Log_2023.csv"
final_path <- "Processed Data/COMPASS_Synoptic_Nutrients_202306.csv"
#record any notes about the run or anything other info here:
run_notes <- "There are two sample names we suspect were input incorrectly,
they are listed below and have been checked against metadata. The metadata from Goodwin ans Sweethall samples is not present."
#duplicate sample names to be changed
#list the sample iDs that are messed up and create a list
#with run number as well so that we can change them below
wrong_names <- c("GCW_202304_TR_LysC_45cm", "GCW_202304_TR_LysA_20cm_8",
"GWI_202304_UP_LysA_20cm", "GWI_202304_UP_LysA_20cm")
wrong_nums <- c(20, 16, 46, 44)
correct_names <- c("GCW_202304_TR_LysB_45cm", "GCW_202304_TR_LysA_20cm",
"GWI_202304_UP_LysA_10cm", "GWI_202304_UP_LysA_10cm")
#can't determine from metadata - for now unsure
remove_names <- c("GCW_202304_TR_LysA_20cm", "GCW_202304_TR_LysA_20cm",
"GCW_202304_TR_LysB_20cm_13", "GCW_202304_TR_LysB_20cm_13")
#couldn't tell which onethis is from the metadata, no A_10cm which is what we thought
#marked on the sheet, need to check sample vials in freezer
#to see if we have a A_10cm from GCW_TR to be sure
remove_nums <- c(15, 13, 21, 19 )
#Set up file path for metadata
#downloaded metadata csv - downloaded from Google drive as csv for this year
#https://docs.google.com/spreadsheets/d/1HCAN0_q6y17x0RUXVzID09hVal-RfwWc/edit?usp=sharing&ouid=108994740386869376571&rtpof=true&sd=true
Raw_Metadata = "Raw Data/COMPASS_SynopticCB_PW_SampleLog_2023.csv"
cat("Visualize Data")
### Nitrite + Nitrate
NOx_forplot <- df_all_clean %>%
filter(Test == "Vanadium NOx")
#group the data for plotting
NOx_forplot <- NOx_forplot %>%
group_by(Site) %>%
mutate(row_num = factor(row_number())) %>%  # create row_num as factor per group
ungroup()
viz_NOx_plot <-  ggplot(data = NOx_forplot, aes(x = factor(row_num), y = Conc, fill=Zone)) +
geom_bar(stat = "identity", position = position_dodge2(preserve = "single"),
color="black") +
facet_grid(~ Site, scales="free_x") +
scale_fill_manual(values = c("UP" = "#20063B",
"TR" = "#FFBC42",
"SWAMP" = "darkgrey",
"WC" = "#419973",
"SW" = "#25ABE6")) +
theme_classic() +
labs(x= " ", y="NOx (mg/L)", title="Porewater NOx") +
theme(legend.position = "none") +
scale_x_discrete(drop = TRUE)+
theme(axis.text.x = element_text(angle = 90, hjust = 0.5))
### Ammonia
NH3_forplot <- df_all_clean %>%
filter(Test == "Ammonia 2")
#group the data for plotting
NH3_forplot <- NH3_forplot %>%
group_by(Site) %>%
mutate(row_num = factor(row_number())) %>%  # create row_num as factor per group
ungroup()
viz_NH3_plot <- ggplot(data = NH3_forplot, aes(x = factor(row_num), y = Conc, fill=Zone)) +
geom_bar(stat = "identity", position = position_dodge2(preserve = "single"),
color="black") +
facet_grid(~ Site, scales="free_x") +
scale_fill_manual(values = c("UP" = "#20063B",
"TR" = "#FFBC42",
"SWAMP" = "darkgrey",
"WC" = "#419973",
"SW" = "#25ABE6")) +
theme_classic() +
labs(x= " ", y="H3 (mg/L)", title="Porewater NH3") +
theme(legend.position = "none") +
scale_x_discrete(drop = TRUE)+
theme(axis.text.x = element_text(angle = 90, hjust = 0.5))
### Phosphate
PO4_forplot <- df_all_clean %>%
filter(Test == "o-PHOS 0.3")
#group the data for plotting
PO4_forplot <- PO4_forplot %>%
group_by(Site) %>%
mutate(row_num = factor(row_number())) %>%  # create row_num as factor per group
ungroup()
viz_PO4_plot <- ggplot(data = PO4_forplot, aes(x = factor(row_num), y = Conc, fill=Zone)) +
geom_bar(stat = "identity", position = position_dodge2(preserve = "single"),
color="black") +
facet_grid(~ Site, scales="free_x") +
scale_fill_manual(values = c("UP" = "#20063B",
"TR" = "#FFBC42",
"SWAMP" = "darkgrey",
"WC" = "#419973",
"SW" = "#25ABE6")) +
theme_classic() +
labs(x= " ", y="PO4 (mg/L)", title="Porewater PO4") +
theme(legend.position = "none") +
scale_x_discrete(drop = TRUE)+
theme(axis.text.x = element_text(angle = 90, hjust = 0.5))
print(viz_NOx_plot)
print(viz_NH3_plot)
print(viz_PO4_plot)
cat("Export Processed Data")
#pivot the data set wider to make it wide format
final_data1 <- df_all_clean %>%
pivot_wider(
id_cols = Sample_Name,
names_from = Test,
values_from = Conc,
names_glue = "{Test}_Conc"
)
final_data2 <- df_all_clean %>%
pivot_wider(
id_cols = Sample_Name,
names_from = Test,
values_from = Conc_uM,
names_glue = "{Test}_Conc_uM"
)
final_data3 <- df_all_clean %>%
pivot_wider(
id_cols = Sample_Name,
names_from = Test,
values_from = Conc_flag,
names_glue = "{Test}_Conc_flag"
)
#take out only the columns we want to merge
df_all_clean_cols <- df_all_clean %>%
select(Sample_Name, Site, Zone, Depth, Depth_cm, Lysimeter,
Year, Month, Day, Time..24hr., Time.Zone_EDT.EST,
NOx_flag, NH3_flag, PO4_flag,
Field.Notes)
df_all_clean_cols_one_row <- df_all_clean_cols %>%
group_by(Sample_Name) %>%
slice(1) %>%  # or use summarise() if you want to aggregate
ungroup()
#merge these together
data_list <- list(df_all_clean_cols_one_row, final_data1, final_data2, final_data3)
final_data4 <- reduce(data_list, full_join, by = c("Sample_Name"))
#Add project information
final_data_labeled <- final_data4 %>%
mutate(
Project = "COMPASS: Synoptic",   # new column with same value on every row
Region = "CB",
Run_notes = run_notes,
Analysis_rundate = print(run_date)# new column with notes about the run
)
#Prepare data to be exported
final_data <- final_data_labeled %>%
rename(
Site = Site,
Sample_ID = Sample_Name,
Time = Time..24hr.,
Time_Zone = Time.Zone_EDT.EST,
Replicate = Lysimeter,
NOx_Conc_mgL = `Vanadium NOx_Conc`,
NOx_Conc_uM = `Vanadium NOx_Conc_uM`,
NOx_Conc_Flag = `Vanadium NOx_Conc_flag`,
NOx_QAQC_Flag = NOx_flag,
NH3_Conc_mgL = `Ammonia 2_Conc`,
NH3_Conc_uM = `Ammonia 2_Conc_uM`,
NH3_Conc_Flag =`Ammonia 2_Conc_flag`,
NH3_QAQC_Flag = NH3_flag,
PO4_Conc_mgL = `o-PHOS 0.3_Conc`,
PO4_Conc_uM = `o-PHOS 0.3_Conc_uM`,
PO4_Conc_Flag =`o-PHOS 0.3_Conc_flag`,
PO4_QAQC_Flag = PO4_flag,
Field_notes = Field.Notes
# add more rename pairs as needed
) %>%
select(Project, Region, Site, Zone, Replicate, Depth_cm,
Sample_ID, Year, Month, Day, Time, Time_Zone,
NOx_Conc_mgL, NOx_Conc_uM, NOx_Conc_Flag, NOx_QAQC_Flag,
NH3_Conc_mgL, NH3_Conc_uM, NH3_Conc_Flag, NH3_QAQC_Flag,
PO4_Conc_mgL, PO4_Conc_uM, PO4_Conc_Flag, PO4_QAQC_Flag,
Analysis_rundate,  Run_notes, Field_notes)
#Write out data frame
write.csv(final_data, final_path)
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
dplyr,
purrr,
ggplot2,
ggpubr,
tidyr,
tidyverse,
tinytex,
stringr,
readr,
LaTeX,
broom)
install.packages("tinytex")
#let you know which section you are in
cat("Setup")
#a link to the Gitbook or whatever protocol you are using for this analysis
#load/install packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
dplyr,
purrr,
ggplot2,
ggpubr,
tidyr,
tidyverse,
tinytex,
stringr,
readr,
LaTeX,
MacTeX,
tinytex,
broom)
#Coefficients / constants that are needed for calculations
N_mw <- 14.0067    # molecular weight of N
P_mw <- 30.973762  # molecular weight of P
Con1 <- 1000       # conversion factor value
Con2 <- 1000000    # conversion factor value
#Detection limit and top standards for flagging
NOx_dl <- 0.025  #mgL
NH3_dl <- 0.02  #mgL
PO4_dl <- 0.003 #mgL
NOx_top <- 1  #mgL
NH3_top <- 2  #mgL
PO4_top <- 0.3 #mgL
#Check Standard concnetrations
NOx_CCV <- 0.5
NH3_CCV <- 1.0
PO4_CCV <- 0.15
#Spike Concentrations
NOx_Spk <- 0.5 #ppm or mg/L
NH3_Spk <- 1
PO4_Spk <- 0.152
#expected ranges for sample concentrations used for flags
r2_cutoff = 0.990
chk_flag = 0.10
chk_conc_flag = 15 #cutoff level for percent difference of check stds vs. expected concentration
chks_flag = 60
rep_flag = 25
#^this is a 25% error between samples
#blank_flag is calculated based on samples later in this code
install.packages("MikTex")
version
tinytex::is_tinytex()
summary(cars)
and knit it and see if it works, if it does then it is something in our code that isn't updated, if not then you might need to redo tinytex.
summary(cars)
detach("package:tinytex", unload = TRUE)
remove.packages("tinytex")
install.packages("tinytex")
library(tinytex)
tinytex::install_tinytex()
tinytex::is_tinytex()
avg_slopes <- log %>%
group_by(Test) %>%
summarise(avg_slope = mean(Slope, na.rm = TRUE))
knitr::kable(avg_slopes, caption = "Average Slope by Analyte", digits = 3)
View(NOx_blks)
blk_avg_NOx <- mean(NOx_blks$Conc, na.rm = TRUE)
blk_avg_NH3 <- mean(NH3_chks$Conc, na.rm = TRUE)
blk_avg_PO4 <- mean(PO4_chks$Conc, na.rm = TRUE)
# Create a data frame
blank_avgs <- data.frame(
Test = c("NOx", "NH3", "PO4"),
Blank_Mean_Conc = c(blk_avg_NOx, blk_avg_NH3, blk_avg_PO4)
)
# Pretty print
knitr::kable(blank_avgs, caption = "Mean Concentration of Blanks", digits = 4)
getwd()
file.exists("Raw Data/COMPASS_SynopticCB_PW_SampleLog_2023.csv")
Raw_Metadata_Path = "Raw Data/COMPASS_SynopticCB_PW_SampleLog_2023.csv"
#let you know which section you are in
cat("Setup")
#a link to the Gitbook or whatever protocol you are using for this analysis
#load/install packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
dplyr,
purrr,
ggplot2,
ggpubr,
tidyr,
tidyverse,
tinytex,
stringr,
readr,
LaTeX,
MacTeX,
tinytex,
broom)
#Coefficients / constants that are needed for calculations
N_mw <- 14.0067    # molecular weight of N
P_mw <- 30.973762  # molecular weight of P
Con1 <- 1000       # conversion factor value
Con2 <- 1000000    # conversion factor value
#Detection limit and top standards for flagging
NOx_dl <- 0.025  #mgL
NH3_dl <- 0.02  #mgL
PO4_dl <- 0.003 #mgL
NOx_top <- 1  #mgL
NH3_top <- 2  #mgL
PO4_top <- 0.3 #mgL
#Check Standard concnetrations
NOx_CCV <- 0.5
NH3_CCV <- 1.0
PO4_CCV <- 0.15
#Spike Concentrations
NOx_Spk <- 0.5 #ppm or mg/L
NH3_Spk <- 1
PO4_Spk <- 0.152
#expected ranges for sample concentrations used for flags
r2_cutoff = 0.990
chk_flag = 0.10
chk_conc_flag = 15 #cutoff level for percent difference of check stds vs. expected concentration
chks_flag = 60
rep_flag = 25
#^this is a 25% error between samples
#blank_flag is calculated based on samples later in this code
#read in the raw metadata file
raw_metadata <- read.csv(Raw_Metadata)
#read in the raw metadata file
raw_metadata <- read.csv(Raw_Metadata_Path)
cat("Run Information: Input by User") #lets you know what section you're in
#set the run date & user name
run_date <- "20240114"
sample_year <- 2023
sample_month <- 06
user <- "Stephanie Wilson"
#identify the files you want to read in
#read in as a list to accommadate ultiple runs in a month
NOx_files <- c("Raw Data/SEAL_COMPASS_Synoptic_NOx_June2023_1.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NOx_June2023_2.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NOx_June2023_3.csv")
NH3_PO4_files <- c("Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_June2023_1.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_June2023_2.csv",
"Raw Data/SEAL_COMPASS_Synoptic_NH3_PO4_June2023_3.csv")
# Define the file path for QAQC log file - NO Need to change just check year
file_path <- "Raw Data/SEAL_COMPASS_Synoptic_QAQC_Log_2023.csv"
final_path <- "Processed Data/COMPASS_Synoptic_Nutrients_202306.csv"
#record any notes about the run or anything other info here:
run_notes <- "There are two sample names we suspect were input incorrectly,
they are listed below and have been checked against metadata. The metadata from Goodwin ans Sweethall samples is not present."
#duplicate sample names to be changed
#list the sample iDs that are messed up and create a list
#with run number as well so that we can change them below
wrong_names <- c("GCW_202304_TR_LysC_45cm", "GCW_202304_TR_LysA_20cm_8",
"GWI_202304_UP_LysA_20cm", "GWI_202304_UP_LysA_20cm")
wrong_nums <- c(20, 16, 46, 44)
correct_names <- c("GCW_202304_TR_LysB_45cm", "GCW_202304_TR_LysA_20cm",
"GWI_202304_UP_LysA_10cm", "GWI_202304_UP_LysA_10cm")
#can't determine from metadata - for now unsure
remove_names <- c("GCW_202304_TR_LysA_20cm", "GCW_202304_TR_LysA_20cm",
"GCW_202304_TR_LysB_20cm_13", "GCW_202304_TR_LysB_20cm_13")
#couldn't tell which onethis is from the metadata, no A_10cm which is what we thought
#marked on the sheet, need to check sample vials in freezer
#to see if we have a A_10cm from GCW_TR to be sure
remove_nums <- c(15, 13, 21, 19 )
#Set up file path for metadata
#downloaded metadata csv - downloaded from Google drive as csv for this year
#https://docs.google.com/spreadsheets/d/1HCAN0_q6y17x0RUXVzID09hVal-RfwWc/edit?usp=sharing&ouid=108994740386869376571&rtpof=true&sd=true
Raw_Metadata = "Raw Data/COMPASS_SynopticCB_PW_SampleLog_2023.csv"
#let you know which section you are in
cat("Setup")
#a link to the Gitbook or whatever protocol you are using for this analysis
#load/install packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
dplyr,
purrr,
ggplot2,
ggpubr,
tidyr,
tidyverse,
tinytex,
stringr,
readr,
LaTeX,
MacTeX,
tinytex,
broom)
#Coefficients / constants that are needed for calculations
N_mw <- 14.0067    # molecular weight of N
P_mw <- 30.973762  # molecular weight of P
Con1 <- 1000       # conversion factor value
Con2 <- 1000000    # conversion factor value
#Detection limit and top standards for flagging
NOx_dl <- 0.025  #mgL
NH3_dl <- 0.02  #mgL
PO4_dl <- 0.003 #mgL
NOx_top <- 1  #mgL
NH3_top <- 2  #mgL
PO4_top <- 0.3 #mgL
#Check Standard concnetrations
NOx_CCV <- 0.5
NH3_CCV <- 1.0
PO4_CCV <- 0.15
#Spike Concentrations
NOx_Spk <- 0.5 #ppm or mg/L
NH3_Spk <- 1
PO4_Spk <- 0.152
#expected ranges for sample concentrations used for flags
r2_cutoff = 0.990
chk_flag = 0.10
chk_conc_flag = 15 #cutoff level for percent difference of check stds vs. expected concentration
chks_flag = 60
rep_flag = 25
#^this is a 25% error between samples
#blank_flag is calculated based on samples later in this code
#read in the raw metadata file
raw_metadata <- read.csv(Raw_Metadata)
