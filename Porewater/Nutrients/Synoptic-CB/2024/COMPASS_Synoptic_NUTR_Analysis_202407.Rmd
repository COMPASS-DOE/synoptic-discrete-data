---
title: "Synoptic CB: Porewater Nutrients"
author: "JULY 2024 Samples"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    toc: true
    number_sections: true
    latex_engine: xelatex
output_dir: "To Be Reviewed/PDF"

---

\newpage

##Run Information 
```{r run information, include=TRUE}
cat("Run Information: NAME ") #lets you know what section you're in 
#set the run date & user name 
  run_date <- "05/20/2025"
  sample_year <- "2024"
  sample_month <- "JULY"
  user <- "Isabelle Van Benschoten"

#identify the files you want to read in 
  #read in as a list to accommadate ultiple runs in a month
  NOx_files <- c("Raw Data/COMPASS_Synoptic_CB_202407_VNOx_1.csv", 
                 "Raw Data/COMPASS_Synoptic_CB_202407_VNOx_2.csv",
                 "Raw Data/COMPASS_Synoptic_CB_202407_VNOx_3.csv")
  NH3_PO4_files <- c("Raw Data/COMPASS_Synoptic_CB_202407_NH3_PO4_1.csv", 
                     "Raw Data/COMPASS_Synoptic_CB_202407_NH3_PO4_2.csv",
                     "Raw Data/COMPASS_Synoptic_CB_202407_NH3_PO4_3.csv")

# Define the file path for QAQC log file - NO Need to change just check year 
  file_path <- "Raw Data/SEAL_COMPASS_Synoptic_QAQC_Log_2024.csv"
  final_path <- "Processed Data/COMPASS_Synoptic_Nutrients_202407.csv"

#record any notes about the run or anything other info here: 
  run_notes <- "Reduction Effieciency was not ran for all of the runs included within this month.
                One NH3 check standard was ut of range but CV was within. 
                One PO4 blank was out of range but CV was within.
                PO4 duplicates out of range.
                Metadata is missing:
                MSM_202407_TR_LysC_45cm, SWH_202407_UP_LysC_10cm, and SWH_202407_WC_LysA_45cm" 
  
#Set up file path for metadata 
  #downloaded metadata csv - downloaded from Google drive as csv for this year
  Raw_Metadata = "Raw Data/COMPASS_SynopticCB_PW_SampleLog_2024.csv"

  cat(run_notes)
```

##Setup
```{r setup, include=FALSE}

#let you know which section you are in 
cat("Setup")

#a link to the Gitbook or whatever protocol you are using for this analysis 


#load/install packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
  dplyr,
  purrr,
  ggplot2,
  ggpubr,
  tidyr,
  tidyverse,
  lubridate,
  tinytex,
  stringr,
  writexl,
  readr,
  readxl,
  purrr,
  tinytex,
  broom)

#Coefficients / constants that are needed for calculations 
N_mw <- 14.0067    # molecular weight of N 
P_mw <- 30.973762  # molecular weight of P 
Con1 <- 1000       # conversion factor value
Con2 <- 1000000    # conversion factor value 

#Detection limit and top standards for flagging 
NOx_dl <- 0.025  #mgL
NH3_dl <- 0.02  #mgL
PO4_dl <- 0.003 #mgL

NOx_top <- 1  #mgL
NH3_top <- 2  #mgL
PO4_top <- 0.3 #mgL

#Check Standard concnetrations 
NOx_CCV <- 0.5 
NH3_CCV <- 1.0 
PO4_CCV <- 0.15 

#Spike Concentrations 
NOx_Spk <- 0.5 #ppm or mg/L
NH3_Spk <- 1
PO4_Spk <- 0.152 

#expected ranges for sample concentrations used for flags 
r2_cutoff = 0.990
chk_flag = 0.25
chk_conc_flag = 15 #cutoff level for percent difference of check stds vs. expected concentration 
chks_flag = 60
rep_flag = 25 
#^this is a 25% error between samples
#blank_flag is calculated based on samples later in this code

#pe check Concentrations
NH3_pe <- 1.034
NOx_pe <- 1.51
PO4_pe <- 0.824

```

##Read in metadata and create similar sample IDs for matching to samples 
```{r pull in metadata for later, include=FALSE}

#read in the raw metadata file 
raw_metadata <- read.csv(Raw_Metadata)

#make a new columns in the metadata with important info:
metadata <- raw_metadata %>%
  mutate(Depth = paste0(Depth_cm, "cm")) %>%
  mutate(LysID = paste0("Lys", Lysimeter)) %>%
  mutate(YearMonth = sprintf("%d%02d", Year, Month))  %>%
  mutate(Zone = case_when(
    `Transect.Location` == "Transition" ~ "TR",
    `Transect.Location` == "Wetland"    ~ "WC",
    `Transect.Location` == "Upland"     ~ "UP",   
    `Transect.Location` == "Surface Water" ~ "SW",
    TRUE                 ~ `Transect.Location`    # keep original value if no match
  ))

#Create NUTR IDs from what was collected for comparison later
metadata <- metadata %>%
  mutate(NUTR_ID = ifelse(NUTR == "x",
                          paste(Site,
                                YearMonth,
                                Zone,
                                LysID,
                                Depth,
                                sep = "_"),
                          NA) )

#Change the SW lines because they don't have lysimeters or a depth  
metadata <- metadata %>%
  mutate(
    NUTR_ID = if_else(
      Zone == "SW",
      # Modify the string:
      NUTR_ID %>%
        str_replace("_LysA", "_A") %>%                    # Replace "_LysA" with "_A"
        str_replace("_LysB", "_B") %>%                    # Replace "_LysB" with "_B"
        str_replace("_LysC", "_C") %>%                    # Replace "_LysC" with "_C"
        str_replace("_0cm$", ""),                         # Remove trailing "_0cm"
      NUTR_ID  # else keep original
    )
  )

#Take out the columns and rows that are not relevant
nutr_metadata <- metadata %>%
  select(NUTR_ID, Year, Month, Day, YearMonth, Site, Zone, Lysimeter, LysID, Depth_cm, 
         Depth, Time..24hr., Time.Zone_EDT.EST, Field.Notes, ) %>%        
  # only keep specific columns
  filter(!is.na(NUTR_ID) & NUTR_ID != "")  # remove missing/blank NUTR_ID rows


```

\newpage

## Import Data & Clean
```{r Import Data, include=FALSE}
cat("Import Data")

#set file path for data - in run info chunk 
path <- ("file path")

#Read in Raw Data 
data_NOx <- map(NOx_files, read.csv)
data_NH3_PO4 <- map(NH3_PO4_files, read.csv)

# Combining Files
df_combo <- bind_rows(data_NOx, data_NH3_PO4)

# Rename columns
df_all <- df_combo %>%
  select(Sample_Name = 4,
         Run_Number = 5,
         Conc = 6,
         Absorbance = 7,
         Dilution = 9,
         Unit = 12,
         Test = 13,
         Run_Time = 15) %>%
  mutate(Run_Number = as.numeric(Run_Number))

#Checking column headers
head(df_all)


```



## Assessing standard Curves
  #Pull out standards data  
```{r Pull out Standard Curves, echo=FALSE}
cat("Assess Standard Curves")

#Pull out standards 
stds <- df_all %>%
  filter(str_detect(Sample_Name, "Standard"))

#Making standards dataframe based on the test
stds_NOx <- stds[stds$Test == "Vanadium NOx", ]
stds_NH3 <- stds[stds$Test == "Ammonia 2", ]
stds_PO4 <- stds[stds$Test == "o-PHOS 0.3", ]


#Inputting Standard Values Based on Protocol (LINK PROTOCOL)
stds_NOx <- stds_NOx %>%
  mutate(`Conc` = case_when(
    Sample_Name == "Standard 0" ~  0.0,
    Sample_Name == "Standard 1" ~  0.0,
    Sample_Name == "Standard 90" ~ 0.0222,
    Sample_Name == "Standard 91" ~ 0.05,
    Sample_Name == "Standard 92" ~ 0.1,
    Sample_Name == "Standard 93" ~ 0.25,
    Sample_Name == "Standard 94" ~ 0.5,
    Sample_Name == "Standard 95" ~ 0.75,
    Sample_Name == "Standard 96" ~ 1.0,
    TRUE ~ `Conc`),  # leave unchanged if no match
    Run_Date = format(lubridate::mdy_hm(Run_Time), "%m-%d-%Y")) %>%
  filter(!Sample_Name %in% c("Nitrate Standard" , "Nitrite Standard"))

#ID x and y
x1 <- stds_NOx$Absorbance
y1 <- stds_NOx$Conc

stds_NH3 <- stds_NH3 %>%
  mutate(`Conc` = case_when(
    Sample_Name == "Standard 0" ~  0.0,
    Sample_Name == "Standard 1" ~  0.0,
    Sample_Name == "Standard .0389" ~ 0.0389,
    Sample_Name == "Standard .1000" ~ 0.1,
    Sample_Name == "Standard .2000" ~ 0.2,
    Sample_Name == "Standard .5000" ~ 0.5,
    Sample_Name == "Standard 1.0000" ~ 1.0,
    Sample_Name == "Standard 1.5000" ~ 1.5,
    Sample_Name == "Standard 2.0000" ~ 2,
    TRUE ~ `Conc`),  # leave unchanged if no match
    Run_Date = format(lubridate::mdy_hm(Run_Time), "%m-%d-%Y"))

# identifying x and y
x2 <- stds_NH3$Absorbance
y2 <- stds_NH3$Conc

stds_PO4 <- stds_PO4 %>%
  mutate(`Conc` = case_when(
    Sample_Name == "Standard 0" ~  0.0,
    Sample_Name == "Standard 1" ~  0.0,
    Sample_Name == "Standard 90" ~ 0.0060,
    Sample_Name == "Standard 91" ~ 0.0150,
    Sample_Name == "Standard 92" ~ 0.0300,
    Sample_Name == "Standard 93" ~ 0.0750,
    Sample_Name == "Standard 94" ~ 0.1500,
    Sample_Name == "Standard 95" ~ 0.2250,
    Sample_Name == "Standard 96" ~ 0.3000,
    TRUE ~ `Conc`),  # leave unchanged if no match
    Run_Date = format(lubridate::mdy_hm(Run_Time), "%m-%d-%Y"))

#ID x and y
x3 <- stds_PO4$Absorbance
y3 <- stds_PO4$Conc

#generating line of best fit aka standard curves
#NOx

# Fit the quadratic model
quad_reg_NOx <- lm(y1 ~ x1 + I(x1^2))

#quad_reg_NOx <- lm(Absorbance ~ Conc + Conc2, data = stds_NOx)
NOx_coefs <- coef(quad_reg_NOx)                        # intercept and slopes
NOx_r2 <- summary(quad_reg_NOx)$r.squared              # R squared
# Store in a clean dataframe
std_curve_NOx_1 <- data.frame(
  Test = "NOx",
  Intercept = NOx_coefs["(Intercept)"],
  Slope = NOx_coefs[2],
  #Conc2_Coeff = NOx_coefs["Conc2"],
  R_squared = NOx_r2
)

#NH3
lin_reg_NH3 <- lm(y2 ~ x2)
NH3_coefs <- coef(lin_reg_NH3)                        # intercept and slope
NH3_r2 <- summary(lin_reg_NH3)$r.squared              # R squared
# Store in a clean dataframe
std_curve_NH3_1 <- data.frame(
  Test = "NH3",
  Intercept = NH3_coefs["(Intercept)"],
  Slope = NH3_coefs[2],
  R_squared = NH3_r2
)

#PO4
lin_reg_PO4 <- lm(y3 ~ x3)
PO4_coefs <- coef(lin_reg_PO4)                        # intercept and slope
PO4_r2 <- summary(lin_reg_PO4)$r.squared              # R squared
# Store in a clean dataframe
std_curve_PO4_1 <- data.frame(
  Test = "PO4",
  Intercept = PO4_coefs["(Intercept)"],
  Slope = PO4_coefs[2],
  R_squared = PO4_r2
) 


#Combining standards & curve data frames
stds_combo <- bind_rows(stds_NOx, stds_NH3, stds_PO4)
std_curve_combo <- bind_rows(std_curve_NOx_1, std_curve_NH3_1, std_curve_PO4_1)


```
  #Plot standards data 
```{r Assess Standard Curves, echo=FALSE}
cat("Assess Standard Curves")

#Plot standard Curve or Curves 
  #v-Nox
std_curve_NOx <- ggplot(stds_NOx, aes(x = Conc, y = Absorbance)) +
  geom_point(size=3) +
  geom_smooth(method = "lm", formula = y ~ poly(x, 2, raw = TRUE), color = "coral") +
  theme_bw() + 
  facet_wrap(~Run_Date) +
  labs(x="Concentration (ppm)",
       y="Absorbance",
       title = "NOx Standard Curve")+ 
  annotate("text", x = 0.75, y = max(stds_NOx$Absorbance), 
           label = paste("r^2 =", round(NOx_r2, 4)),
           color = "black", size = 4)
print(std_curve_NOx)

  #NH3 
std_curve_NH3 <- ggplot(stds_NH3, aes(x = Conc, y = Absorbance)) +
  geom_point(size=3) +
  geom_smooth(method = "lm", se = FALSE, color = "darkgoldenrod") +
  theme_bw() + 
  facet_wrap(~Run_Date) +
  labs(x="Concentration (ppm)",
       y="Absorbance",
       title = "NH3 Standard Curve")+ 
  annotate("text", x = 1.7, y = max(stds_NH3$Absorbance), label = paste("r^2 =", round(NH3_r2, 4)),
          color = "black", size = 4)
print(std_curve_NH3)

  #PO4 
std_curve_PO4 <- ggplot(stds_PO4, aes(x = Conc, y = Absorbance)) +
  geom_point(size=3) +
  geom_smooth(method = "lm", se = FALSE, color = "darkkhaki") +
  facet_wrap(~Run_Date) +
  theme_bw() + 
  labs(x="Concentration (ppm)",
       y="Absorbance",
       title = "PO4 Standard Curve")+ 
  annotate("text", x = 0.25, y = max(stds_PO4$Absorbance), label = paste("r^2 =", round(PO4_r2, 4)),
          color = "black", size = 4)
print(std_curve_PO4)

############## Report on Cutoffs 

#Report out a flag if the run has an R2 lower than appropriate 
#Write out to the user whether or not the r2 is above the cutoff of 0.98
  ifelse(std_curve_NOx_1$R_squared <= r2_cutoff, 
         "NOx Curve r2 is below cutoff! - REASSESS", 
         "NOx Curve r2 GOOD - PROCEED")
  ifelse(std_curve_NH3_1$R_squared <= r2_cutoff, 
         "NH3 Curve r2 is below cutoff! - REASSESS", 
         "NH3 Curve r2 GOOD - PROCEED")
  ifelse(std_curve_PO4_1$R_squared <= r2_cutoff, 
         "PO4 Curve r2 is below cutoff! - REASSESS", 
         "PO4 Curve r2 GOOD - PROCEED")
  

#check for the a slope QAQC file, if there is not one, make one 
if (file.exists(file_path)) {
  # If it exists, read it back into R
  stds_log <- read.csv(file_path)
  print("QAQC log file exists and has been read into the code.")
  } else {
  # If it does not exist, create the CSV file
  stds_log <- as.data.frame(matrix(ncol = 6, nrow = 0))
  colnames(stds_log) <- c("Test", "Intercept", "Slope", "R_squared", "run_date", "user")
  
  #maybe add here the last slopes from the previous year
  
  # Write add_log to CSV
  write.csv(stds_log, file = file_path, row.names = FALSE)
  print("QAQC log file does not exist. It has been created.")
  }
  
  #getting rid of first "X" column
  #stds_log <- stds_log %>%
  #  select(-1)
  
#create a dataframe that can be appended to the QAQC log 
add_log <- as.data.frame(bind_rows(std_curve_NOx_1, std_curve_NH3_1, std_curve_PO4_1))
add_log$run_date <- run_date
add_log$user <- user

#compare slopes to previous runs (from log) in order to assess drift 
stds_log$run_date <- as.character(stds_log$run_date)
add_log$run_date  <- as.character(add_log$run_date)     #getting the run_date column in the same type to merge

#Filter to only rows in Slopes that are NOT already in log (by run_date + analyte) but need to add if none
if (nrow(stds_log) == 0) {
  # If log is empty, everything in add_log is new
  new_rows <- add_log
} else {
  # Otherwise, compare to existing log
  new_rows <- anti_join(add_log, stds_log, by = c("run_date", "Test"))
}


# Append the new, non-duplicate rows to log
log <- bind_rows(stds_log, new_rows)


#Plot the slopes through time 
Slopes_chk <- ggplot(log, aes(run_date, Slope, col=Test)) + 
  geom_point(size=4) + 
  geom_line(aes(group = Test)) + 
  theme_bw() + 
  labs(title="Slope Drift Assessment", x="Run Date", y="Slope") +
  scale_color_manual(values=c("coral", "darkgoldenrod", "darkkhaki"))
Slopes_chk

#averaging the slopes from the log and printing
avg_slopes <- log %>%
  group_by(Test) %>%
  summarise(avg_slope = mean(Slope, na.rm = TRUE))
knitr::kable(avg_slopes, caption = "Average Slope by Analyte", digits = 3)


#write out the log file with the added lines for this run date 
write.csv(log, file_path)

#write out a flag to the sample dataframe if the r2 is above the cutoff of 0.98
df_all <- df_all %>%
  mutate(
    NOx_flag = if (NOx_r2 <= r2_cutoff) {
      "NOx r2 low"
    } else {
      ""
    },
    NH3_flag = if (NH3_r2 <= r2_cutoff) {
      "NH3 r2 low"
    } else {
      ""
    },
    PO4_flag = if (PO4_r2 <= r2_cutoff) {
      "PO4 r2 low"
    } else {
      ""
    }
  )



```
 
 \newpage


## Dilution Corrections - ensure the latest dilution is kept
```{r Dilution Corrections, echo=FALSE}

cat("Dilution Corrections")

#Calculate the concentration when accounting for the dilution factor if applicable

#checking to see if duplicate samples (mislabeled/wrongly inputted/reran)
df_duplicates <- df_all %>%
  filter(!if_all(everything(), is.na)) %>%  # Remove rows that are entirely NA

  # Exclude common QC sample names and standard patterns
  filter(
    !(Sample_Name %in% c(
      "Duplicate", "CCV", "CCB", "1mg/L ammonia", "DI",
      "Blank", "Auto Spike", "0.15 mg/L"
    )) &
    !startsWith(Sample_Name, "Standard ") &
    !startsWith(Sample_Name, "Nitrite ") &
    !startsWith(Sample_Name, "Nitrate ") &
    !startsWith(Sample_Name, "Abs_Chk_") &
    !startsWith(Sample_Name, "peChk_") &
    !grepl("^\\d{1,2}/\\d{1,2}/\\d{4}\\s+\\d{1,2}:\\d{2}$", Sample_Name) &  # Remove timestamp-like names
    !grepl("^\\d+$", Sample_Name) &  # Remove sample names that are just numbers
    !is.na(Sample_Name) & Sample_Name != ""  # ðŸ” Remove blank or missing names
  ) %>%
  group_by(Test, Sample_Name) %>%  # Group by test and sample
  filter(n() > 1) %>%              # Keep only those that appear more than once
  ungroup()

#pulling them out into a string and printing them out
dil_dups_string <- df_duplicates %>%
  distinct(Sample_Name) %>%
  pull(Sample_Name) %>%
  paste(collapse = ", ")

# Make sure Dilution is numeric
df_duplicates$Dilution <- as.numeric(df_duplicates$Dilution)

# Report duplicated samples
if (dil_dups_string != "") {
  message("Duplicated samples: ", dil_dups_string)

  bad_dups <- df_duplicates %>%
    group_by(Test, Sample_Name) %>%
    summarise(
      n_dups = n(),
      any_dilution = any(Dilution > 1, na.rm = TRUE),
      .groups = "drop"
    ) %>%
    filter(!any_dilution)

  if (nrow(bad_dups) > 0) {
    cat("\nWARNING: Duplicated samples with NO dilution (possible input error):\n")
    print(bad_dups)
  } else {
    cat("\n All duplicated samples have valid dilutions. No naming issues detected.\n")
  }

} else {
  message("No duplicated samples.")
}





df_all_cor <- df_all %>%
  arrange(row_number()) %>%
  mutate(
    Dilution = case_when(
      Dilution == "0" ~ 1.0,
      TRUE ~ as.numeric(Dilution)
    ),
    Pair_ID = ifelse(
      grepl("Duplicate", Sample_Name, ignore.case = TRUE),
      paste0(lag(Sample_Name), "_", lag(Run_Number)),  # pair only if same run
      paste0(Sample_Name, "_", Run_Number)
    ),
    Original_Name = Sample_Name
  ) %>%
  group_by(Pair_ID, Test, Run_Number) %>%  # group by Pair_ID, Test, and Run_Number
  filter(
    Dilution == ifelse(any(Dilution > 1, na.rm = TRUE), max(Dilution, na.rm = TRUE), 1)
  ) %>%
  ungroup()




```


## Performance Check
```{r pe Check, echo = FALSE}

NOx_peChk <- df_all_cor %>%
  filter(Test == "Vanadium NOx", 
         str_detect(Sample_Name, "peChk_NOx")) %>%
  summarise(
    Mean_Chk_Conc = mean(Conc, na.rm = TRUE),
    SD_Chk_Conc = sd(Conc, na.rm = TRUE),
    CV = (SD_Chk_Conc / Mean_Chk_Conc) * 100,
    pct_diff_Chk = abs(Mean_Chk_Conc - NOx_pe) / NOx_pe,
    NOx_pe_flag = ifelse(abs(pct_diff_Chk) < 25, "YES, Pass", "NO, rerun"))
      

NH3_peChk <- df_all_cor %>%
  filter(Test == "Ammonia 2", 
         str_detect(Sample_Name, "peChk_")) %>%
  summarise(
    Mean_Chk_Conc = mean(Conc, na.rm = TRUE),
    SD_Chk_Conc = sd(Conc, na.rm = TRUE),
    CV = (SD_Chk_Conc / Mean_Chk_Conc) * 100,
    pct_diff_Chk = abs(Mean_Chk_Conc - NH3_pe) / NH3_pe,
    NH3_pe_flag = ifelse(abs(pct_diff_Chk) < 25, "YES, Pass", "NO, rerun"))

PO4_peChk <- df_all_cor %>%
  filter(Test == "o-PHOS 0.3", 
         str_detect(Sample_Name, "peChk_")) %>%
  summarise(
    Mean_Chk_Conc = mean(Conc, na.rm = TRUE),
    SD_Chk_Conc = sd(Conc, na.rm = TRUE),
    CV = (SD_Chk_Conc / Mean_Chk_Conc) * 100,
    pct_diff_Chk = abs(Mean_Chk_Conc - PO4_pe) / PO4_pe,
    PO4_pe_flag = ifelse(abs(pct_diff_Chk) < 25, "YES, Pass", "NO, rerun"))
  


#flag write out 
ifelse(NOx_peChk$pct_diff_Chk >= chk_flag, 
       "NOx pe Check has a % Difference >25% - REASSESS",  
       "NOx pe Check has a % Difference <25% - PROCEED")
cat("Run mean =", NOx_peChk$Mean_Chk_Conc, "\n")
cat("Expected  =", NOx_pe, "\n\n")
ifelse(NH3_peChk$pct_diff_Chk >= chk_flag, 
       "NH3 pe Check has a % Difference >25% - REASSESS",  
       "NH3 pe Check has a % Difference <25% - PROCEED")
cat("Run mean =", NH3_peChk$Mean_Chk_Conc, "\n")
cat("Expected  =", NH3_pe, "\n\n")
ifelse(PO4_peChk$pct_diff_Chk >= chk_flag, 
       "PO4 pe Check has a % Difference >25% - REASSESS",  
       "PO4 pe Check has a % Difference <25% - PROCEED")
cat("Run mean =", PO4_peChk$Mean_Chk_Conc, "\n")
cat("Expected  =", PO4_pe, "\n")




```

 
##Check NOx Reduction Efficiency 
```{r Assess reduction Efficiency, echo=FALSE}
cat("Assess Reduction Efficiency")

#check on the reduction efficiency for the NOx test: 
#Pull out test stds 
red_eff <- df_all %>%
  filter(Sample_Name %in% c("Nitrate Standard", "Nitrite Standard"))

red_eff$Eff_Percent <- (red_eff$Conc / 0.5)*100
red_eff$Eff_flag <-  ifelse(red_eff$Eff_Percent >= 90, 'YES', 'NO, rerun')

red_eff <- red_eff %>%
  mutate(row_num = row_number())

#Plot these efficencies 
red_effs_plot <-  ggplot(data = red_eff, aes(x = factor(row_num), y = Conc, fill=Eff_flag)) +
       geom_bar(stat = 'identity') + 
       facet_wrap(~Sample_Name) +
       scale_fill_manual(values = c("YES" = "midnightblue", "NO, rerun" = "darkred")) +
       theme_classic() + labs(x= " ", y="NOx (mg/L)", title=" ") + 
       theme(legend.position="bottom") +  
       geom_hline(yintercept= 0.5, linetype="dashed", 
                color = "black", linewidth=1)  + 
       guides(fill=guide_legend(title="Reduction Efficiency >90%"))+
      scale_x_discrete(drop = TRUE)
print(red_effs_plot)

#create a flag 
NOx_mean_red_eff <- mean(red_eff$Eff_Percent)

#report out if flags indicate need for rerun and what the value is
ifelse(NOx_mean_red_eff >= 95,
       "Mean NOx Reduction Efficiency >95% - PROCEED",
       "Mean NOx Reduction Efficiency <95% - REASSESS")
print(NOx_mean_red_eff)

#write out a flag to the sample dataframe if red eff is low
if (NOx_mean_red_eff <= 95) {
    df_all$NOx_flag <- ifelse(
    df_all$NOx_flag != "",
    paste0(df_all$NOx_flag, "; NOx reduction efficiency low"),
    "NOx reduction efficiency low")}

```

\newpage

## Analyze the Check Standards
```{r Check Standards, echo=FALSE}

cat("Analyze Check Standards")

#Pull out check standards from raw file 
NOx_chks <- df_all %>%
  filter(str_detect(Sample_Name, "CCV"))%>% 
  mutate(rep = row_number())

NH3_chks <- df_all %>%
  filter(str_detect(Sample_Name, "1mg/L ammonia"))%>% 
  mutate(rep = row_number())

PO4_chks <- df_all %>%
  filter(str_detect(Sample_Name, "0.15 mg/L"))%>% 
  mutate(rep = row_number())


#RSV of standards 
chks_NOx_rsv <- ((sd(NOx_chks$Conc))/mean(NOx_chks$Conc))
chks_NH3_rsv <- ((sd(NH3_chks$Conc))/mean(NH3_chks$Conc))
chks_PO4_rsv <- ((sd(PO4_chks$Conc))/mean(PO4_chks$Conc))

#write out to user about whether or not to continue 
ifelse(chks_NOx_rsv >= chk_flag, 
       "NOx CHECK STANDARD RSD TOO HIGH - REASSESS",
       "NOx Check Standard RSD within Range - PROCEED")
ifelse(chks_NH3_rsv >= chk_flag, 
       "NH3 CHECK STANDARD RSD TOO HIGH - REASSESS",
       "NH3 Check Standard RSD within Range - PROCEED")
ifelse(chks_PO4_rsv >= chk_flag, 
       "PO4 CHECK STANDARD RSD TOO HIGH - REASSESS",
       "PO4 Check Standard RSD within Range - PROCEED")


#calculate percent difference between check standards & expected concentration 
#flag if the percent difference is over X% (defined in setup)
#calculate percent difference of check standards 
NOx_chks$NOx_diff <- ((NOx_chks$Conc - NOx_CCV)/((NOx_chks$Conc + NOx_CCV)/2)) * 100
NOx_chks$NOx_diff_flag <-  ifelse(NOx_chks$NOx_diff <= chk_conc_flag, 'YES', 'NO, rerun')

NH3_chks$NH3_diff <- ((NH3_chks$Conc - NH3_CCV)/((NH3_chks$Conc + NH3_CCV)/2)) * 100
NH3_chks$NH3_diff_flag <-  ifelse(NH3_chks$NH3_diff <= chk_conc_flag, 'YES', 'NO, rerun')

PO4_chks$PO4_diff <- ((PO4_chks$Conc - PO4_CCV)/((PO4_chks$Conc + PO4_CCV)/2)) * 100
PO4_chks$PO4_diff_flag <-  ifelse(PO4_chks$PO4_diff <= chk_conc_flag, 'YES', 'NO, rerun')


#plot the check standards
NOx_chks_plot <-  ggplot(data = NOx_chks, aes(x = rep, y = Conc, fill=NOx_diff_flag)) +
       geom_bar(stat = 'identity') + 
        scale_fill_manual(values = c("YES" = "chartreuse4", "NO, rerun" = "darkred")) +
        labs(x= " ", y="NOx (mg/L)", title="Check Stds: NOx") + 
        theme(legend.position="bottom") +  
        geom_hline(yintercept=NOx_CCV,
              linetype="dashed", color = "black", linewidth=1) + 
        guides(fill=guide_legend(title="% Difference <10%")) +
        theme_classic()

NH3_chks_plot <-  ggplot(data = NH3_chks, aes(x = rep, y = Conc, fill=NH3_diff_flag)) +
       geom_bar(stat = 'identity') + 
       scale_fill_manual(values = c("YES" = "chartreuse4", "NO, rerun" = "darkred")) +
       theme_classic() + 
       labs(x= " ", y="NH3  (mg/L)", title="Check Stds: NH3") + 
       theme(legend.position="bottom") +  
       geom_hline(yintercept=NH3_CCV,
              linetype="dashed",  color = "black", linewidth=1) + 
       guides(fill=guide_legend(title="% Difference <10%"))

PO4_chks_plot <-  ggplot(data = PO4_chks, aes(x = rep, y = Conc, fill=PO4_diff_flag)) +
       geom_bar(stat = 'identity') + 
       scale_fill_manual(values = c("YES" = "chartreuse4", "NO, rerun" = "darkred")) +
        theme_classic() + labs(x= " ", y="PO4  (mg/L)", title="Check Stds: PO4") + 
        theme(legend.position="bottom") +  geom_hline(yintercept=PO4_CCV,
              linetype="dashed",  color = "black", linewidth=1) + 
        guides(fill=guide_legend(title="% Difference <10%"))

#Combined Plot
Chk_Std_Plots <- ggarrange(
  NOx_chks_plot, 
  NH3_chks_plot, 
  PO4_chks_plot,   
  nrow = 1, 
  ncol = 3,
  common.legend = TRUE,
  legend = "bottom")
print(Chk_Std_Plots)

#calculate the percent of check standards that are within the range based on the flag 
NOx_chks_percent <- (sum(NOx_chks$NOx_diff_flag == "YES")/nrow(NOx_chks))*100
NH3_chks_percent <- (sum(NH3_chks$NH3_diff_flag == "YES")/nrow(NH3_chks))*100
PO4_chks_percent <- (sum(PO4_chks$PO4_diff_flag == "YES")/nrow(PO4_chks))*100

#report out if flags indicate need for rerun
ifelse(NOx_chks_percent >= chks_flag, 
       ">60% of NOx Check Standards are within range of expected concentration - PROCEED",
       "<60% of NOx Check Standards are within range of expected concentration - REASSESS")
ifelse(NH3_chks_percent >= chks_flag,
       ">60% of NH3 Check Standards are within range of expected concentration - PROCEED",
       "<60% of NH3 Check Standards are within range of expected concentration - REASSESS")
ifelse(PO4_chks_percent >= chks_flag,
       ">60% of PO4 Check Standards are within range of expected concentration - PROCEED",
       "<60% of PO4 Check Standards are within range of expected concentration - REASSESS")


#write out a flag to the sample dataframe if less than 60% of the checks are within the expected CV
if (NOx_chks_percent <= chks_flag) {
    df_all_cor$NOx_flag <- ifelse(
    df_all_cor$NOx_flag != "",
    paste0(df_all_cor$NOx_flag, "; NOx checks out of range"),
    "NOx checks out of range"
  )
}

if (NH3_chks_percent <= chks_flag) {  
    df_all_cor$NH3_flag <- ifelse(
    df_all_cor$NH3_flag != "",
    paste0(df_all_cor$NH3_flag, "; NH3 checks out of range"),
    "NH3 checks out of range"
  )
}

if (PO4_chks_percent <= chks_flag) {  
    df_all_cor$PO4_flag <- ifelse(
    df_all_cor$PO4_flag != "",
    paste0(df_all_cor$PO4_flag, "; PO4 checks out of range"),
    "PO4 checks out of range"
  )
}



```

\newpage

## Analyze Blanks 
```{r Analyze Blanks, echo=FALSE}

cat("Assess Blanks")

#Pull out check standards from raw file 
NOx_blks <- df_all %>%
  filter(str_detect(Sample_Name, "CCB"))%>% 
  mutate(rep = row_number())

NH3_blks <- df_all %>%
  filter(Test == "Ammonia 2")%>% 
  filter(str_detect(Sample_Name, "Blank"))%>% 
  mutate(rep = row_number())

PO4_blks <- df_all %>%
  filter(Test == "o-PHOS 0.3")%>% 
  filter(str_detect(Sample_Name, "Blank"))%>% 
  mutate(rep = row_number())

#Pull out samples from df_all to calc quantile
samples <- df_all %>%  
  filter(str_detect(Sample_Name, c("GCW|GWI|MSM|SWH"))) 

#Calculating the lowest 25% of sample concentrations to compare to the blank concentrations
NOx_only <- samples %>%
  filter(Test == "Vanadium NOx")
blk_flag_NOx <- quantile(NOx_only$Conc, prob=c(.25))   #this gives you the lower 25% quartile of the data 
blk_flag_NOx <- ifelse(blk_flag_NOx < NOx_dl, 0.0125, blk_flag_NOx) #this will determine if the Q1 of samples is below the detection limit, if it is then it will replace the flag with half of the detection limit 
NOx_blks$NOx_diff_flag <-  ifelse(NOx_blks$Conc <= blk_flag_NOx, 'YES', 'NO, rerun')

NH3_only <- samples %>%
  filter(Test == "Ammonia 2")
blk_flag_NH3 <- quantile(NH3_only$Conc, prob=c(.25))   #this gives you the lower 25% quartile of the data 
NH3_blks$NH3_diff_flag <-  ifelse(NH3_blks$Conc <= blk_flag_NH3, 'YES', 'NO, rerun')

PO4_only <- samples %>%
  filter(Test == "o-PHOS 0.3")
blk_flag_PO4 <- quantile(PO4_only$Conc, prob=c(.25))   #this gives you the lower 25% quartile of the data 
PO4_blks$PO4_diff_flag <-  ifelse(PO4_blks$Conc <= blk_flag_PO4, 'YES', 'NO, rerun')

#calculate the percent of check standards that are within the range based on the flag 
NOx_blks_percent <- (sum(NOx_blks$NOx_diff_flag == "YES")/nrow(NOx_blks))*100
NH3_blks_percent <- (sum(NH3_blks$NH3_diff_flag == "YES")/nrow(NH3_blks))*100
PO4_blks_percent <- (sum(PO4_blks$PO4_diff_flag == "YES")/nrow(PO4_blks))*100

#report out if flags indicate need for rerun
ifelse(NOx_blks_percent >= 60,
       ">60% of NOx Blanks are below the lower 25% quartile of samples or 1/2 detection limit - PROCEED",
       "<60% of NOx blaks are lower 25% quartile of samples or 1/2 the detection limit - REASSESS")
ifelse(NH3_blks_percent >= 60,
       ">60% of NH3 Blanks are below the lower 25% quartile of samples - PROCEED",
       "<60% of NH3 blaks are lower 25% quartile of samples - REASSESS")
ifelse(PO4_blks_percent >= 60,
       ">60% of PO4 Blanks  are below the lower 25% quartile of samples- PROCEED",
       "<60% of PO4 blaks are lower 25% quartile of samples - REASSESS")

#plotting the blanks compared to the lower 25% of conc (what the flag is)
NOx_blks_plot <-  ggplot(data = NOx_blks, aes(x = rep, y = Conc, fill=NOx_diff_flag)) +
       geom_bar(stat = 'identity') + 
       scale_fill_manual(values = c("YES" = "deepskyblue3", "NO, rerun" = "darkred")) +
       theme_classic() + labs(x= " ", y="NOx (mg/L)", title="NOx Blanks") + 
       theme(legend.position="bottom") +  
       geom_hline(yintercept= as.numeric(blk_flag_NOx), linetype="dashed", 
                color = "black", linewidth=1)  + 
       guides(fill=guide_legend(title="Blank Conc <25% Quartile Samples"))

NH3_blks_plot <-  ggplot(data = NH3_blks, aes(x = rep, y = Conc, fill=NH3_diff_flag)) +
       geom_bar(stat = 'identity') + 
       scale_fill_manual(values = c("YES" = "deepskyblue3", "NO, rerun" = "darkred")) +
       theme_classic() + labs(x= " ", y="NH3  (mg/L)", title="NH3 Blanks") + 
       theme(legend.position="bottom") +  
       geom_hline(yintercept=as.numeric(blk_flag_NH3), linetype="dashed",
                color = "black", linewidth=1)  + 
       guides(fill=guide_legend(title="Blank Conc <25% Quartile Samples"))

PO4_blks_plot <-  ggplot(data = PO4_blks, aes(x = rep, y = Conc, fill=PO4_diff_flag)) +
       geom_bar(stat = 'identity') + 
       scale_fill_manual(values = c("YES" = "deepskyblue3", "NO, rerun" = "darkred")) +
       theme_classic() + labs(x= " ", y="PO4 (mg/L)", title="PO4 Blanks") + 
       theme(legend.position="bottom") +  
       geom_hline(yintercept=as.numeric(blk_flag_PO4), linetype="dashed", 
                color = "black", linewidth=1)  + 
       guides(fill=guide_legend(title="Blank Conc <25% Quartile Samples"))

#Combined Plot
Blks_Plots <- ggarrange(
  NOx_blks_plot, 
  NH3_blks_plot, 
  PO4_blks_plot,   # (you had NH3 twice!)
  nrow = 1, 
  ncol = 3,
  common.legend = TRUE,
  legend = "bottom")
print(Blks_Plots)


#find average of run blanks for flagging samples later 

# Compute averages
blk_avg_NOx <- mean(NOx_blks$Conc, na.rm = TRUE)
blk_avg_NH3 <- mean(NH3_blks$Conc, na.rm = TRUE)
blk_avg_PO4 <- mean(PO4_blks$Conc, na.rm = TRUE)

# Create a data frame
blank_avgs <- data.frame(
  Test = c("NOx", "NH3", "PO4"),
  Blank_Mean_Conc = c(blk_avg_NOx, blk_avg_NH3, blk_avg_PO4)
)

# Pretty print
knitr::kable(blank_avgs, caption = "Mean Concentration of Blanks", digits = 4)


#write out a flag to the sample dataframe if more than 60% of the blanks are above the lower 25% quantile of samples
if (NOx_blks_percent <= chks_flag) {
    df_all_cor$NOx_flag <- ifelse(
    df_all_cor$NOx_flag != "",
    paste0(df_all_cor$NOx_flag, "; NOx blanks out of range"),
    "NOx blanks out of range"
  )
}

if (NH3_blks_percent <= chks_flag) {  # assuming you have tn_chks_percent similarly
    df_all_cor$NH3_flag <- ifelse(
    df_all_cor$NH3_flag != "",
    paste0(df_all_cor$NH3_flag, "; NH3 blanks out of range"),
    "NH3 blanks out of range"
  )
}

if (PO4_blks_percent <= chks_flag) {  # assuming you have tn_chks_percent similarly
    df_all_cor$PO4_flag <- ifelse(
    df_all_cor$PO4_flag != "",
    paste0(df_all_cor$PO4_flag, "; PO4 blanks out of range"),
    "PO4 blanks out of range"
  )
}

```

\newpage

## Analyze Duplicates
```{r Analyze Duplicates, echo=FALSE}

cat("Analyze Duplicates")

#Getting dataframe of just duplicated samples
df_NOx_dup <- df_all_cor %>%
  filter(Test == "Vanadium NOx") %>%
  filter(
     !grepl("CCV|CCB|Standard|Auto Spike|Abs_Chk_20ppt|Abs_Chk_10ppt", Sample_Name, ignore.case = TRUE), 
     #^removes autospice, ccv, ccb, standards
     !is.na(Sample_Name),                                         # Remove NA
     !grepl("^\\d+$", Sample_Name),                               # removes all numbers
     !grepl("^\\d{1,2}/\\d{1,2}/\\d{2,4}", Sample_Name)) %>%      # removes all date/time
  mutate(`Duplicate?` = if_else(                                  # adds duplicate column
     grepl("Duplicate", Sample_Name, ignore.case = TRUE),         # keeps sample ID if there
     lag(Sample_Name),                                            # get previous row's SampleID
     Sample_Name)) %>%                                            # keeps sample ID if not duplicate
  group_by(`Duplicate?`) %>%                                      # groups by duplicate 
  filter(n() > 1) %>%                                             # filters anything that appears more than once 
  ungroup() %>%                          
  transmute(   
     Pair_ID = `Duplicate?`,                                      # changing heading to pair_id
     Sample_Name,                                                 #keeping sample name and conc
     Conc,                                                        #if sample name duplicate then put duplicate 
     Type = if_else(str_detect(Sample_Name, "Duplicate"), "Duplicate", "Original"))  #, if not put original to ID 
  
df_NH3_dup <- df_all_cor %>%
  filter(Test == "Ammonia 2") %>%
  filter(
     !grepl("CCV|CCB|Blank|1mg/L ammonia|Abs_Chk_20ppt|Abs_Chk_10ppt|Standard|Auto Spike", Sample_Name, ignore.case = TRUE), 
     #^removes autospice, ccv, ccb, standards
     !is.na(Sample_Name),                                         # Remove NA
     !grepl("^\\d+$", Sample_Name),                               # removes all numbers
     !grepl("^\\d{1,2}/\\d{1,2}/\\d{2,4}", Sample_Name)) %>%      # removes all date/time
  mutate(`Duplicate?` = if_else(                                  # adds duplicate column
     grepl("Duplicate", Sample_Name, ignore.case = TRUE),         # keeps sample ID if there
     lag(Sample_Name),                                            # get previous row's SampleID
     Sample_Name)) %>%                                            # keeps sample ID if not duplicate
  group_by(`Duplicate?`) %>%                                      # groups by duplicate 
  filter(n() > 1) %>%                                             # filters anything that appears more than once 
  ungroup() %>%                      
  transmute(   
     Pair_ID = `Duplicate?`,                                      # changing heading to pair_id
     Sample_Name,                                                 #keeping sample name and conc
     Conc,                                                        #if sample name duplicate then put duplicate 
     Type = if_else(str_detect(Sample_Name, "Duplicate"), "Duplicate", "Original"))  #, if not put original to ID 

df_PO4_dup <- df_all_cor %>%
  filter(Test == "o-PHOS 0.3") %>%
  filter(
     !grepl("CCV|CCB|Standard|Auto Spike|Blank|1mg/L ammonia|Abs_Chk_20ppt|Abs_Chk_10ppt|	
0.15 mg/L", Sample_Name, ignore.case = TRUE), 
     #^removes autospice, ccv, ccb, standards
     !is.na(Sample_Name),                                         # Remove NA
     !grepl("^\\d+$", Sample_Name),                               # removes all numbers
     !grepl("^\\d{1,2}/\\d{1,2}/\\d{2,4}", Sample_Name)) %>%      # removes all date/time
  mutate(`Duplicate?` = if_else(                                  # adds duplicate column
     grepl("Duplicate", Sample_Name, ignore.case = TRUE),         # keeps sample ID if there
     lag(Sample_Name),                                            # get previous row's SampleID
     Sample_Name)) %>%                                            # keeps sample ID if not duplicate
  group_by(`Duplicate?`) %>%                                      # groups by duplicate 
  filter(n() > 1) %>%                                             # filters anything that appears more than once 
  ungroup() %>%                      
  transmute(   
     Pair_ID = `Duplicate?`,                                      # changing heading to pair_id
     Sample_Name,                                                 #keeping sample name and conc
     Conc,                                                        #if sample name duplicate then put duplicate 
     Type = if_else(str_detect(Sample_Name, "Duplicate"), "Duplicate", "Original")) 

# Duplicate Stats
Nox_dup_chk <- df_NOx_dup %>%
  group_by(Pair_ID) %>%  # Use Pair_ID as it groups Originals and Duplicates
  filter(n_distinct(Type) == 2) %>%  # Keep only groups that have both Original and Duplicate
  summarise(
    OG_Conc = Conc[Type == "Original"],
    Dup_Conc = Conc[Type == "Duplicate"],
    Mean_Conc = mean(c(OG_Conc, Dup_Conc)),
    SD_Conc = sd(c(OG_Conc, Dup_Conc)),
    CV = (SD_Conc / Mean_Conc) * 100,
    pct_diff = abs(Dup_Conc - OG_Conc) / Mean_Conc * 100,
    NOx_diff_flag = ifelse(abs(CV) < 10, "YES", "NO, rerun"),
    .groups = "drop") 

NH3_dup_chk <- df_NH3_dup %>%
  group_by(Pair_ID) %>%  # Use Pair_ID as it groups Originals and Duplicates
  filter(n_distinct(Type) == 2) %>%  # Keep only groups that have both Original and Duplicate
  summarise(
    OG_Conc = Conc[Type == "Original"],
    Dup_Conc = Conc[Type == "Duplicate"],
    Mean_Conc = mean(c(OG_Conc, Dup_Conc)),
    SD_Conc = sd(c(OG_Conc, Dup_Conc)),
    CV = (SD_Conc / Mean_Conc) * 100,
    pct_diff = abs(Dup_Conc - OG_Conc) / Mean_Conc * 100,
    NH3_diff_flag = ifelse(abs(CV) < 10, "YES", "NO, rerun"),
    .groups = "drop") 

PO4_dup_chk <- df_PO4_dup %>%
  filter(Sample_Name != "0.15 mg/L") %>%
  group_by(Pair_ID) %>%  # Use Pair_ID as it groups Originals and Duplicates
  filter(n_distinct(Type) == 2) %>%  # Keep only groups that have both Original and Duplicate
  summarise(
    OG_Conc = Conc[Type == "Original"],
    Dup_Conc = Conc[Type == "Duplicate"],
    Mean_Conc = mean(c(OG_Conc, Dup_Conc)),
    SD_Conc = sd(c(OG_Conc, Dup_Conc)),
    CV = (SD_Conc / Mean_Conc) * 100,
    pct_diff = abs(Dup_Conc - OG_Conc) / Mean_Conc * 100,
    PO4_diff_flag = ifelse(abs(CV) < 10, "YES", "NO, rerun"),
    .groups = "drop") 

#check to see if NOx dups are below the detection limit, this is very common for NOx and leads to 
# very high cvs between dups, so we will accept them if the samples are below detection 
Nox_dup_chk <- Nox_dup_chk %>%
  mutate(NOx_diff_flag = ifelse(OG_Conc < NOx_dl, "bdl", NOx_diff_flag))

#calculate the percent of check standards that are within the range based on the flag 
NOx_dup_percent <- (sum(Nox_dup_chk$NOx_diff_flag %in% c("YES", "bdl")) / nrow(Nox_dup_chk)) * 100
NH3_dup_percent <- (sum(NH3_dup_chk$NH3_diff_flag == "YES")/nrow(NH3_dup_chk))*100
PO4_dup_percent <- (sum(PO4_dup_chk$PO4_diff_flag == "YES")/nrow(PO4_dup_chk))*100

#dup flag report out
ifelse(NOx_dup_percent >= chks_flag, 
       ">60% of NOx Duplicates have a CV <10% - PROCEED",
       "<60% of NOx Duplicates have a CV <10% - REASSESS")
ifelse(NH3_dup_percent >= chks_flag, 
       ">60% of NH3 Duplicates have a CV <10% - PROCEED",
       "<60% of NH3 Duplicates have a CV <10% - REASSESS")
ifelse(PO4_dup_percent >= chks_flag, 
       ">60% of PO4 Duplicates have a CV <10% - PROCEED",
       "<60% of PO4 Duplicates have a CV <10% - REASSESS")

#Create row numbers for plotting
Nox_dup_chk <- Nox_dup_chk %>%
  mutate(row_num = row_number())

NH3_dup_chk <- NH3_dup_chk %>%
  mutate(row_num = row_number())

PO4_dup_chk <- PO4_dup_chk %>%
  mutate(row_num = row_number())

#plot dups output as a bar graph to easily check - want any over 10% to be red need to work on this 
NOx_dups_plot <- ggplot(data =Nox_dup_chk, aes(x =Pair_ID, y =CV, fill=NOx_diff_flag)) +
        geom_bar(stat = 'identity') + 
        theme_classic() + 
        labs(x= "Sample ID", y="CV between dups", title = "NOx Duplicates") + 
        scale_fill_manual(values = c("bdl" = "darkslateblue","YES" = "darkslateblue",  "NO, rerun" = "darkred")) +
        theme(legend.position="none") +  
        geom_hline(yintercept=10, linetype="dashed", 
            color = "black", size=1)  + 
        guides(fill=guide_legend(title="<10%:"))+
        theme(axis.text.x = element_text(angle = 90, hjust = 0.5))

NH3_dups_plot <- ggplot(data = NH3_dup_chk, aes(x =Pair_ID, y =CV, fill=NH3_diff_flag)) +
        geom_bar(stat = 'identity') + 
        theme_classic() + 
        labs(x= "Sample ID", y="CV between dups", title = "NH3 Duplicates") + 
        scale_fill_manual(values = c("YES" = "darkslateblue", "NO, rerun" = "darkred")) +
        theme(legend.position="none") +  
        geom_hline(yintercept=10, linetype="dashed", 
              color = "black", size=1) + 
        guides(fill=guide_legend(title="<10%:"))+
        theme(axis.text.x = element_text(angle = 90, hjust = 0.5))

PO4_dups_plot <- ggplot(data =PO4_dup_chk, aes(x =Pair_ID, y =CV, fill=PO4_diff_flag)) +
       geom_bar(stat = 'identity') + 
       theme_classic() + 
        labs(x= "Sample ID", y="CV between dups", title = "PO4 Duplicates") + 
       scale_fill_manual(values = c("YES" = "darkslateblue", "NO, rerun" = "darkred")) +
       theme(legend.position="none") +  
       geom_hline(yintercept=10, linetype="dashed", 
                color = "black", size=1) + 
        guides(fill=guide_legend(title="<10%:"))+
        theme(axis.text.x = element_text(angle = 90, hjust = 0.5))

#Combined Plot
Dups_Plots <- ggarrange(
  NOx_dups_plot, 
  NH3_dups_plot, 
  PO4_dups_plot,  
  nrow = 1, 
  ncol = 3,
  common.legend = FALSE,
  legend = "bottom")
print(Dups_Plots)

#write out a flag to the sample dataframe if more than 60% of the dups have CVs out of range 
if (NOx_dup_percent <= chks_flag) {
    df_all_cor$NOx_flag <- ifelse(
    df_all_cor$NOx_flag != "",
    paste0(df_all_cor$NOx_flag, "; NOx dups out of range"),
    "NOx dups out of range"
  )
}

if (NH3_dup_percent <= chks_flag) {  # assuming you have tn_chks_percent similarly
    df_all_cor$NH3_flag <- ifelse(
    df_all_cor$NH3_flag != "",
    paste0(df_all_cor$NH3_flag, "; NH3 dups out of range"),
    "NH3 dups out of range"
  )
}

if (PO4_dup_percent <= chks_flag) {  # assuming you have tn_chks_percent similarly
    df_all_cor$PO4_flag <- ifelse(
    df_all_cor$PO4_flag != "",
    paste0(df_all_cor$PO4_flag, "; PO4 dups out of range"),
    "PO4 dups out of range"
  )
}



```

\newpage

## Spikes
```{r Analyze Spikes, echo=FALSE}

#getting spikes and samples pulled 
df_NOx_spk <- df_all_cor %>%
  filter(Test == "Vanadium NOx") %>%
  filter(
     !grepl("CCV|CCB|Standard|Duplicate", Sample_Name, ignore.case = TRUE),
     #^removes dup, ccv, ccb, standards
     !is.na(Sample_Name),                                     # Remove NA
     !grepl("^\\d+$", Sample_Name),                           # removes all numbers
     !grepl("^\\d{1,2}/\\d{1,2}/\\d{2,4}", Sample_Name)) %>%  # removes all date/time
  mutate(`Spike?` = if_else(                                  # adds duplicate column
     grepl("Auto Spike", Sample_Name, ignore.case = TRUE),    # keeps sample ID if there
     lag(Sample_Name),                                        # get previous row's SampleID
     Sample_Name)) %>%                                        # keeps sample ID if not duplicate
  group_by(`Spike?`) %>%                                      # groups by duplicate
  filter(n() > 1) %>%                                         # filters anything that appears more than once
  ungroup()  %>%
  transmute(
    Pair_ID = `Spike?`,
    Sample_Name,
    Conc,
    Type = if_else(str_detect(Sample_Name, "Auto Spike"), "Auto_Spike", "Original"))
 
df_NH3_spk <- df_all_cor %>%
  filter(Test == "Ammonia 2") %>%
  filter(
     !grepl("CCV|CCB|Blank|1mg/L ammonia|Standard|Duplicate", Sample_Name, ignore.case = TRUE),
     #^removes dup, ccv, ccb, standards
     !is.na(Sample_Name),                                         # Remove NA
     !grepl("^\\d+$", Sample_Name),                               # removes all numbers
     !grepl("^\\d{1,2}/\\d{1,2}/\\d{2,4}", Sample_Name)) %>%      # removes all date/time
  mutate(`Spike?` = if_else(                                      # adds duplicate column
     grepl("Auto Spike", Sample_Name, ignore.case = TRUE),        # keeps sample ID if there
     lag(Sample_Name),                                            # get previous row's SampleID
     Sample_Name)) %>%                                            # keeps sample ID if not duplicate
  group_by(`Spike?`) %>%                                          # groups by duplicate
  filter(n() > 1) %>%                                             # filters anything that appears more than once
  ungroup()  %>%
  transmute(
    Pair_ID = `Spike?`,
    Sample_Name,
    Conc,
    Type = if_else(str_detect(Sample_Name, "Auto Spike"), "Auto_Spike", "Original"))
 
df_PO4_spk <- df_all_cor %>%
  filter(Test == "o-PHOS 0.3") %>%
  filter(
     !grepl("CCV|CCB|Standard|Duplicate", Sample_Name, ignore.case = TRUE),
     #^removes dup, ccv, ccb, standards
     !is.na(Sample_Name),                                         # Remove NA
     !grepl("^\\d+$", Sample_Name),                               # removes all numbers
     !grepl("^\\d{1,2}/\\d{1,2}/\\d{2,4}", Sample_Name)) %>%      # removes all date/time
   mutate(`Spike?` = if_else(                                     # adds duplicate column
     grepl("Auto Spike", Sample_Name, ignore.case = TRUE),        # keeps sample ID if there
     lag(Sample_Name),                                            # get previous row's SampleID
     Sample_Name)) %>%                                            # keeps sample ID if not duplicate
  group_by(`Spike?`) %>%                                          # groups by duplicate
  filter(n() > 1) %>%                                             # filters anything that appears more than once
  ungroup()  %>%
  transmute(
    Pair_ID = `Spike?`,
    Sample_Name,
    Conc,
    Type = if_else(str_detect(Sample_Name, "Auto Spike"), "Auto_Spike", "Original"))
 

#checking and flagging against the expected spike conc
df_spk_NOx_chk <- df_NOx_spk %>%
  select(Pair_ID, Conc, Type) %>%
  pivot_wider(
    names_from = Type,
    values_from = Conc,
    values_fn = mean,  # in case there are duplicates
    names_prefix = "" ) %>%
  rename(
    Spike_Conc = Auto_Spike,
    OG_Conc = Original) %>%
  filter(!is.na(Spike_Conc), !is.na(OG_Conc)) %>%
  rowwise() %>%# keep only rows with both
   mutate(
    Exp_Conc = OG_Conc + NOx_Spk,
    Mean_Conc = mean(c(Spike_Conc, Exp_Conc), na.rm = TRUE),
    Pct_Diff = abs(Spike_Conc - Exp_Conc) / Mean_Conc * 100,
    SD_Conc = sd(c(Spike_Conc, Exp_Conc)),
    CV = (SD_Conc / Mean_Conc) * 100,
    Spike_diff_flag = ifelse(CV < 50, "YES", "NO, check"),
    Test = "Vanadium NOx") %>%
    ungroup()
  
df_spk_NH3_chk <- df_NH3_spk %>%
  select(Pair_ID, Conc, Type) %>%
  pivot_wider(
    names_from = Type,
    values_from = Conc,
    values_fn = mean,  # in case there are duplicates
    names_prefix = "" ) %>%
  rename(
    Spike_Conc = Auto_Spike,
    OG_Conc = Original) %>%
  filter(!is.na(Spike_Conc), !is.na(OG_Conc)) %>%
  rowwise() %>%# keep only rows with both
   mutate(
    Exp_Conc = OG_Conc + NH3_Spk,
    Mean_Conc = mean(c(Spike_Conc, Exp_Conc), na.rm = TRUE),
    Pct_Diff = abs(Spike_Conc - Exp_Conc) / Mean_Conc * 100,
    SD_Conc = sd(c(Spike_Conc, Exp_Conc)),
    CV = (SD_Conc / Mean_Conc) * 100,
    Spike_diff_flag = ifelse(CV < 50, "YES", "NO, check"),
    Test = "Ammonia 2") %>%
    ungroup()

df_spk_PO4_chk <- df_PO4_spk %>%
  select(Pair_ID, Conc, Type) %>%
  pivot_wider(
    names_from = Type,
    values_from = Conc,
    values_fn = mean,  # in case there are duplicates
    names_prefix = "" ) %>%
  rename(
    Spike_Conc = Auto_Spike,
    OG_Conc = Original) %>%
  filter(!is.na(Spike_Conc), !is.na(OG_Conc)) %>%
  rowwise() %>%# keep only rows with both
   mutate(
    Exp_Conc = OG_Conc + PO4_Spk,
    Mean_Conc = mean(c(Spike_Conc, Exp_Conc), na.rm = TRUE),
    Pct_Diff = abs(Spike_Conc - Exp_Conc) / Mean_Conc * 100,
    SD_Conc = sd(c(Spike_Conc, Exp_Conc)),
    CV = (SD_Conc / Mean_Conc) * 100,
    Spike_diff_flag = ifelse(CV < 50, "YES", "NO, check"),
    Test = "o-PHOS 0.3") %>%
    ungroup()


# Combining Auto Spike data frames
df_spk_combo <- bind_rows(df_spk_NOx_chk, df_spk_NH3_chk, df_spk_PO4_chk)

#add column for test ^^ aand then combine


#calculate the percent of check standards that are within the range based on the flag
NOx_spk_percent <- (sum(df_spk_NOx_chk$Spike_diff_flag == "YES")/nrow(df_spk_NOx_chk))*100
NH3_spk_percent <- (sum(df_spk_NH3_chk$Spike_diff_flag == "YES")/nrow(df_spk_NH3_chk))*100
PO4_spk_percent <- (sum(df_spk_PO4_chk$Spike_diff_flag == "YES")/nrow(df_spk_PO4_chk))*100
 

#spk flag report out
ifelse(NOx_spk_percent >= chks_flag, 
       ">60% of Spikes have a CV <50% - PROCEED",
       "<60% of Carbon Spikes have a CV <50% - REASSESS")
ifelse(NH3_spk_percent >= chks_flag, 
       ">60% of Spikes have a CV <50% - PROCEED",
       "<60% of Carbon Spikes have a CV <50% - REASSESS")
ifelse(PO4_spk_percent >= chks_flag, 
       ">60% of Spikes have a CV <50% - PROCEED",
       "<60% of Carbon Spikes have a CV <50% - REASSESS")
 

#plot spikes output as a bar graph to easily check - want any over 10% to be red need to work on this 
NOx_spk_plot <- ggplot(data =df_spk_NOx_chk, aes(x =Pair_ID, y =CV, fill=Spike_diff_flag)) +
        geom_bar(stat = 'identity') + 
        theme_classic() + 
        labs(x= "Sample ID", y="NOx N (mg/L)", title = "NOx Auto Spike CV") + 
        scale_fill_manual(values = c("YES" = "darkcyan", "NO, check" = "darkred")) +
        theme(legend.position="none") + 
        geom_hline(yintercept=50, linetype="dashed", 
            color = "black", size=1)  +
        guides(fill=guide_legend(title="CV Between Spks <50%"))+
        theme(axis.text.x = element_text(angle = 90, hjust = 0.5))

NH3_spk_plot <- ggplot(data = df_spk_NH3_chk, aes(x =Pair_ID, y =CV, fill=Spike_diff_flag)) +
        geom_bar(stat = 'identity') + 
        theme_classic() + 
        labs(x= "Sample ID", y="NH3 N(mg/L)", title = "NH3 Auto Spike CV") + 
        scale_fill_manual(values = c("YES" = "darkcyan", "NO, check" = "darkred")) +
        theme(legend.position="none")  + 
        geom_hline(yintercept=50, linetype="dashed", 
            color = "black", size=1)  +
        guides(fill=guide_legend(title="CV Between Spks <50%"))+
        theme(axis.text.x = element_text(angle = 90, hjust = 0.5))

PO4_spk_plot <- ggplot(data =df_spk_PO4_chk, aes(x =Pair_ID, y =CV, fill=Spike_diff_flag)) +
       geom_bar(stat = 'identity') + 
       theme_classic() + 
        labs(x= "Sample ID", y="PO4 P(mg/L)", title = "PO4 Auto Spike CV") + 
       scale_fill_manual(values = c("YES" = "darkcyan", "NO, check" = "darkred")) +
       theme(legend.position="none")  + 
       geom_hline(yintercept=50, linetype="dashed", 
            color = "black", size=1)  +
        guides(fill=guide_legend(title="CV Between Spks <50%"))+
        theme(axis.text.x = element_text(angle = 90, hjust = 0.5))
 

Spk_Plots <- ggarrange(
  NOx_spk_plot, 
  NH3_spk_plot, 
  PO4_spk_plot,   # (you had NH3 twice!)
  nrow = 1, 
  ncol = 3,
  common.legend = TRUE,
  legend = "bottom")
print(Spk_Plots)


#write out a flag to the sample dataframe if more than 60% of the dups have CVs out of range
if (NOx_spk_percent <= chks_flag) {
    df_all_cor$NOx_flag <- ifelse(
    df_all_cor$NOx_flag != "",
    paste0(df_all_cor$NOx_flag, "; NOx spikes out of range"),
    "NOx spikes out of range"
  )
}

if (NH3_spk_percent <= chks_flag) {  
    df_all_cor$NH3_flag <- ifelse(
    df_all_cor$NH3_flag != "",
    paste0(df_all_cor$NH3_flag, "; NH3 spikes out of range"),
    "NH3 spikes out of range"
  )
}

if (PO4_spk_percent <= chks_flag) {  
    df_all_cor$PO4_flag <- ifelse(
    df_all_cor$PO4_flag != "",
    paste0(df_all_cor$PO4_flag, "; PO4 spikes out of range"),
    "PO4 spikes out of range"
  )
}


```

\newpage

## Matrix Effects
```{r Analyze Matrix Effects, echo=FALSE}

df_matrix <- df_spk_combo%>%
  filter(str_detect(Pair_ID, "Abs_Chk")) 

df_matrix_NOx <- df_matrix %>%
  filter(str_detect(Test, "Vanadium")) 
  ifelse(
  all(df_matrix_NOx$Spike_diff_flag == "YES"),
  "NO NOx Matrix Effect, PROCEED",
  ">20% CV in ASW NOx matrix effect checks - REASSESS"
)
  
df_matrix_NH3 <- df_matrix %>%
  filter(str_detect(Test, "Ammonia")) 
  ifelse(
  all(df_matrix_NH3$Spike_diff_flag == "YES"),
  "NO NH3 Matrix Effect, PROCEED",
  ">20% CV in ASW NH3 matrix effect checks - REASSESS"
)
  
df_matrix_PO4 <- df_matrix %>%
  filter(str_detect(Test, "PHOS")) 
  ifelse(
  all(df_matrix_PO4$Spike_diff_flag == "YES"),
  "NO PO4 Matrix Effect, PROCEED",
  ">20% CV in ASW PO4 matrix effect checks - REASSESS"
)



#write out a flag to the sample dataframe if more than 60% of the dups have CVs out of range
if (any(df_matrix$Spike_diff_flag[df_matrix$Test == "Vanadium NOx"] != "YES")) {
  
    df_all_cor$NOx_flag <- ifelse(
    df_all_cor$NOx_flag != "",
    paste0(df_all_cor$NOx_flag, "; NOx matrix check out of range"),
    "NOx matrix check out of range"
  )

}

if (any(df_matrix$Spike_diff_flag[df_matrix$Test == "Ammonia 2"] != "YES")) {
  
    df_all_cor$NOx_flag <- ifelse(
    df_all_cor$NOx_flag != "",
    paste0(df_all_cor$NOx_flag, "; NH3 matrix check out of range"),
    "NH3 matrix check out of range"
  )

}

if (any(df_matrix$Spike_diff_flag[df_matrix$Test == "o-PHOS 0.3"] != "YES")) {
  
    df_all_cor$NOx_flag <- ifelse(
    df_all_cor$NOx_flag != "",
    paste0(df_all_cor$NOx_flag, "; PO4 matrix check out of range"),
    "PO4 matrix check out of range"
  )

}

```

## Unit Converted Data Column Added (mg/L to uM )
```{r Add unit conversion, include=FALSE}

#Pull out samples 
samples <- df_all_cor %>%  
  filter(str_detect(Sample_Name, c("GCW|GWI|MSM|SWH")))     


#Convert values based on the Test ID 
samples <- samples %>%
  mutate(
    Conc_uM = case_when(
      Test == "Vanadium NOx" ~ (((as.numeric(samples$Conc))/Con1)/N_mw)*Con2,
      Test == "Ammonia 2" ~ (((as.numeric(samples$Conc))/Con1)/N_mw)*Con2,
      Test == "o-PHOS 0.3" ~ (((as.numeric(samples$Conc))/Con1)/P_mw)*Con2,
      TRUE ~ as.numeric(NA)  # fallback in case of unexpected value
    ),
    # Replace negatives with 0 in 'value' and 'value_converted'
    Conc = pmax(Conc, 0),
    Conc_uM = pmax(Conc_uM, 0)
  )

head(samples)

```

## Sample Flagging - Within range of standard curve
```{r Sample Flagging, echo=FALSE}

cat("Sample Flagging")

#Flagging data if the concentration is outside the standards range 
samples_flagged <- samples %>%
  mutate(
    Conc_flag = case_when(
      Test == "Vanadium NOx" & Conc < NOx_dl ~ "bdl",
      Test == "Vanadium NOx" & Conc > NOx_top    ~ "adl",
      Test == "Vanadium NOx"               ~ "Within_Range",
      
      Test == "Ammonia 2" & Conc < NH3_dl ~ "bdl",
      Test == "Ammonia 2" & Conc > NH3_top    ~ "adl",
      Test == "Ammonia 2"                ~ "Within_Range",
      
      Test == "o-PHOS 0.3" & Conc < PO4_dl  ~ "bdl",
      Test == "o-PHOS 0.3" & Conc > PO4_top   ~ "adl",
      Test == "o-PHOS 0.3"                ~ "Within_Range",
      
      TRUE ~ NA_character_  # fallback for unexpected values
    )
  )

```

## Pull out sample id information 
```{r Sample Identification, echo=FALSE}

cat("Sample Processing")

samples_flagged <- samples_flagged %>%
  filter(str_detect(Sample_Name, "GCW|GWI|MSM|SWH")) %>%
  filter(!str_detect(Sample_Name, "RHZ|PPR")) %>% 
  mutate(Run_Time = lubridate::mdy_hm(Run_Time)) %>%
  separate(
    col = Sample_Name,
    sep = "_",
    into = c("Site", "Samp_Time", "Zone", "Replicate", "Depth"),
    remove = FALSE) %>%
  mutate(Samp_Time = ym(Samp_Time))



```

## Check to see if samples run match metadata & merge info
```{r check sample ids with metadata, echo=FALSE}

cat("Check Sample IDs with Metadata")

#check to see if all samples are present in the metadata 
all_present <- all(samples_flagged$Sample_Name %in% nutr_metadata$NUTR_ID)

if (all_present) {
  message("All sample IDs are present in metadata.")
} else {
  message("Some sample IDs are missing from metadata.")
  
  # Optional: Which ones are missing?
  missing_ids <- setdiff(samples_flagged$Sample_Name, nutr_metadata$NUTR_ID)
  print(missing_ids)
}

nutr_metadata_selected <- nutr_metadata %>%
  select(NUTR_ID, Year, Month, Day, Depth_cm, Lysimeter, Time..24hr., Time.Zone_EDT.EST,  Field.Notes) 

#merge metadata with sample run data 
merged_data <- samples_flagged %>%
  left_join(nutr_metadata_selected, by = c("Sample_Name" = "NUTR_ID"))

df_all_clean <- merged_data %>%
  #filter(str_detect(Sample_Name, "GCW|GWI|MSM|SWH")) %>%
  #mutate(Run_Time = lubridate::mdy_hm(Run_Time)) %>%
  separate(
    col = Sample_Name,
    sep = "_",
    into = c("Site", "Samp_Time", "Zone", "Replicate", "Depth"),
    remove = FALSE) %>%
  mutate(Samp_Time = ym(Samp_Time)) 


```

\newpage

## Visualize Data
```{r Visualize Data, echo=FALSE}
cat("Visualize Data")

### Nitrite + Nitrate 

NOx_forplot <- df_all_clean %>%
  filter(Test == "Vanadium NOx")

#group the data for plotting
NOx_forplot <- NOx_forplot %>%
  group_by(Site) %>%
  mutate(row_num = factor(row_number())) %>%  # create row_num as factor per group
  ungroup()

viz_NOx_plot <-  ggplot(data = NOx_forplot, aes(x = factor(row_num), y = Conc, fill=Zone)) +
       geom_bar(stat = "identity", position = position_dodge2(preserve = "single"), 
                 color="black") +
       facet_grid(~ Site, scales="free_x") +
        scale_fill_manual(values = c("UP" = "#20063B", 
                                     "TR" = "#FFBC42", 
                                     "SWAMP" = "darkgrey",
                                     "WC" = "#419973", 
                                     "SW" = "#25ABE6")) +
        theme_classic() + 
        labs(x= " ", y="NOx (mg/L)", title="Porewater NOx") + 
          theme(legend.position = "none") +
          scale_x_discrete(drop = TRUE)+
        theme(axis.text.x = element_text(angle = 90, hjust = 0.5))

### Ammonia 

NH3_forplot <- df_all_clean %>%
  filter(Test == "Ammonia 2")

#group the data for plotting
NH3_forplot <- NH3_forplot %>%
  group_by(Site) %>%
  mutate(row_num = factor(row_number())) %>%  # create row_num as factor per group
  ungroup()

viz_NH3_plot <- ggplot(data = NH3_forplot, aes(x = factor(row_num), y = Conc, fill=Zone)) +
       geom_bar(stat = "identity", position = position_dodge2(preserve = "single"), 
                 color="black") + 
       facet_grid(~ Site, scales="free_x") +
        scale_fill_manual(values = c("UP" = "#20063B", 
                                     "TR" = "#FFBC42", 
                                     "SWAMP" = "darkgrey",
                                     "WC" = "#419973", 
                                     "SW" = "#25ABE6")) +
        theme_classic() + 
        labs(x= " ", y="NH3 (mg/L)", title="Porewater NH3") + 
          theme(legend.position = "none") +
          scale_x_discrete(drop = TRUE)+
        theme(axis.text.x = element_text(angle = 90, hjust = 0.5))

### Phosphate 

PO4_forplot <- df_all_clean %>%
  filter(Test == "o-PHOS 0.3")

#group the data for plotting
PO4_forplot <- PO4_forplot %>%
  group_by(Site) %>%
  mutate(row_num = factor(row_number())) %>%  # create row_num as factor per group
  ungroup()

viz_PO4_plot <- ggplot(data = PO4_forplot, aes(x = factor(row_num), y = Conc, fill=Zone)) +
       geom_bar(stat = "identity", position = position_dodge2(preserve = "single"), 
                 color="black") + 
       facet_grid(~ Site, scales="free_x") +
        scale_fill_manual(values = c("UP" = "#20063B", 
                                     "TR" = "#FFBC42", 
                                     "SWAMP" = "darkgrey",
                                     "WC" = "#419973", 
                                     "SW" = "#25ABE6")) +
        theme_classic() + 
        labs(x= " ", y="PO4 (mg/L)", title="Porewater PO4") + 
          theme(legend.position = "none") +
          scale_x_discrete(drop = TRUE)+
        theme(axis.text.x = element_text(angle = 90, hjust = 0.5))


print(viz_NOx_plot)
print(viz_NH3_plot) 
print(viz_PO4_plot)

```

## Export Processed Data
```{r Export Processed Data, include=FALSE}

cat("Export Processed Data")

#pivot the data set wider to make it wide format 
final_data1 <- df_all_clean %>%
  pivot_wider(
    id_cols = Sample_Name,
    names_from = Test,
    values_from = Conc,
    names_glue = "{Test}_Conc"
  )

final_data2 <- df_all_clean %>%
  pivot_wider(
    id_cols = Sample_Name,
    names_from = Test,
    values_from = Conc_uM,
    names_glue = "{Test}_Conc_uM"
  )

final_data3 <- df_all_clean %>%
  pivot_wider(
    id_cols = Sample_Name,
    names_from = Test,
    values_from = Conc_flag,
    names_glue = "{Test}_Conc_flag"
  )

#take out only the columns we want to merge 
df_all_clean_cols <- df_all_clean %>%
  select(Sample_Name, Site, Zone, Depth, Depth_cm, Lysimeter,
         Year, Month, Day, Time..24hr., Time.Zone_EDT.EST,
         NOx_flag, NH3_flag, PO4_flag, 
         Field.Notes)

df_all_clean_cols_one_row <- df_all_clean_cols %>%
  group_by(Sample_Name) %>%
  slice(1) %>%  # or use summarise() if you want to aggregate
  ungroup()

#merge these together
data_list <- list(df_all_clean_cols_one_row, final_data1, final_data2, final_data3)

final_data4 <- reduce(data_list, full_join, by = c("Sample_Name"))


#Add project information 
final_data_labeled <- final_data4 %>% 
  mutate(
    Project = "COMPASS: Synoptic",   # new column with same value on every row
    Region = "CB",
    Run_notes = run_notes, 
    Analysis_rundate = print(run_date)# new column with notes about the run
  ) 

#Prepare data to be exported 
final_data <- final_data_labeled %>%
    rename(
    Site = Site,
    Sample_ID = Sample_Name, 
    Time = Time..24hr., 
    Time_Zone = Time.Zone_EDT.EST,
    Replicate = Lysimeter,
    
    NOx_Conc_mgL = `Vanadium NOx_Conc`,
    NOx_Conc_uM = `Vanadium NOx_Conc_uM`,
    NOx_Conc_Flag = `Vanadium NOx_Conc_flag`,
    NOx_QAQC_Flag = NOx_flag,
    
    NH3_Conc_mgL = `Ammonia 2_Conc`,
    NH3_Conc_uM = `Ammonia 2_Conc_uM`,
    NH3_Conc_Flag =`Ammonia 2_Conc_flag`,
    NH3_QAQC_Flag = NH3_flag,
    
    PO4_Conc_mgL = `o-PHOS 0.3_Conc`,
    PO4_Conc_uM = `o-PHOS 0.3_Conc_uM`,
    PO4_Conc_Flag =`o-PHOS 0.3_Conc_flag`,
    PO4_QAQC_Flag = PO4_flag,
    
    Field_notes = Field.Notes
    # add more rename pairs as needed
  ) %>%
  select(Project, Region, Site, Zone, Replicate, Depth_cm, 
         Sample_ID, Year, Month, Day, Time, Time_Zone,
         NOx_Conc_mgL, NOx_Conc_uM, NOx_Conc_Flag, NOx_QAQC_Flag,
         NH3_Conc_mgL, NH3_Conc_uM, NH3_Conc_Flag, NH3_QAQC_Flag,
         PO4_Conc_mgL, PO4_Conc_uM, PO4_Conc_Flag, PO4_QAQC_Flag,
         Analysis_rundate,  Run_notes, Field_notes)


#Write out data frame 
  write.csv(final_data, final_path)
  

```


#end



