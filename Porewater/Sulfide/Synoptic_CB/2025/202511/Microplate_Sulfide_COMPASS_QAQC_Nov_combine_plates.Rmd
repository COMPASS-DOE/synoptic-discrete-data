---
title: "Synoptic CB: Porewater Sulfide"
author: "November 2025 All Plates"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    toc: false
    number_sections: false
geometry: "left=2cm,right=2cm,top=1cm,bottom=2cm"
output_dir: "To Be Reviewed/PDF"
---

##Run Notes
```{r}
# All sample IDs are present in metadata.
# Some samples still have high CVs after one replicate was removed. 


```


##Read in packages
```{r packages, include = FALSE}
#packages
library(ggplot2)
library(dplyr)
library(data.table)
library(matrixStats)
library(gridExtra)
library(ggpubr)
library(grid)
library(stringr)
library(plater)
library(raster)
library(tidyverse)
library(readxl)
library(dplyr)

```

##Read in raw data
```{r Read in raw data, include = FALSE}

#Read in list of processed data files
files <- list.files(path = "Processed Data", pattern = "\\d\\.csv$", full.names = TRUE)

files_date1 <- files[grepl("20251110", files)]


#Read and combine all csvs
all_data1 <- files_date1 %>%
  lapply(read.csv, 
        colClasses = c("IDs" = "character")) %>%    # or read.csv if you prefer base R
  bind_rows()             # combine into one data frame

all_data1$X <- NULL

colnames(all_data1)

all_data1 <- all_data1 %>%
  rename(
    H2S_Conc_flag = H2S_flag,
    H2S_QAQC_flag = QAQC_flag, 
    
  )

##Remove Dups and Spikes
Sample_data1 <- all_data1 %>% 
  subset((!IDs %like% " Dup")) %>% 
  subset((!IDs %like% " Spike"))%>% 
  subset((!IDs %like% "TMP"))

```

##Read in and Fix Sample IDs
```{r Read in and Fix Sample IDs, include = FALSE}

#Read in Sample IDs
SampleIDs1 <- read_excel("Raw Data/COMPASS_Nov2025_SampleIDs_20251110.xlsx")
SampleIDs1$Number <- as.character(SampleIDs1$Number)
names(SampleIDs1) <- tools::toTitleCase(names(SampleIDs1))

```


##Convert Sample Numbers to Sample IDs
```{r Convert Sample Numbers to Sample IDs, include = FALSE}
##Merge with data
Sample_data_IDs1 <- Sample_data1 %>%
  left_join(SampleIDs1, by = c("IDs" = "Number"))

##Make full sample IDs
##Depths for SW samples should be 0 
Sample_data_IDs1$Depth <-  ifelse((Sample_data_IDs1$Zone == "SW"), "0cm", Sample_data_IDs1$Depth)

#Create IDs from what was collected for comparison later
Sample_data_IDs1 <- Sample_data_IDs1 %>%
  mutate(Sample_ID = paste(Site, Date, Zone, Replicate, Depth, sep = "_"))

#Change the SW lines because they don't have lysimeters or a depth  
Sample_data_IDs1 <- Sample_data_IDs1 %>%
  mutate(
    Sample_ID = if_else(
      Zone == "SW",
      # Modify the string:
      Sample_ID %>%
        str_replace("_LysA", "_A") %>%                    # Replace "_LysA" with "_A"
        str_replace("_LysB", "_B") %>%                    # Replace "_LysB" with "_B"
        str_replace("_LysC", "_C") %>%                    # Replace "_LysC" with "_C"
        str_replace("_0cm$", ""),                          # Remove trailing "_0cm"
      Sample_ID  # else keep original
    )
  )

##Capitalize all sample IDs
Sample_data_IDs1$Sample_ID <- toupper(Sample_data_IDs1$Sample_ID)
  
```


##Read in raw data 20251114
```{r Read in raw data 20251114, include = FALSE}

#Read in list of processed data files
files <- list.files(path = "Processed Data", pattern = "\\d\\.csv$", full.names = TRUE)

files_date2 <- files[grepl("20251114", files)]


#Read and combine all csvs
all_data2 <- files_date2 %>%
  lapply(read.csv, 
        colClasses = c("IDs" = "character")) %>%    # or read.csv if you prefer base R
  bind_rows()             # combine into one data frame

all_data2$X <- NULL

colnames(all_data2)

all_data2 <- all_data2 %>%
  rename(
    H2S_Conc_flag = H2S_flag,
    H2S_QAQC_flag = QAQC_flag, 
    
  )

##Remove Dups and Spikes
Sample_data2 <- all_data2 %>% 
  subset((!IDs %like% " Dup")) %>% 
  subset((!IDs %like% " Spike"))%>% 
  subset((!IDs %like% "TMP"))

```

##Read in and Fix Sample IDs 20251114
```{r Read in and Fix Sample IDs, include = FALSE}

#Read in Sample IDs
SampleIDs2 <- read_excel("Raw Data/COMPASS_Nov2025_SampleIDs_20251114.xlsx")
SampleIDs2$Number <- as.character(SampleIDs2$Number)
names(SampleIDs2) <- tools::toTitleCase(names(SampleIDs2))

```


##Convert Sample Numbers to Sample IDs
```{r Convert Sample Numbers to Sample IDs, include = FALSE}
##Merge with data
Sample_data_IDs2 <- Sample_data2 %>%
  left_join(SampleIDs2, by = c("IDs" = "Number"))

##Make full sample IDs
##Depths for SW samples should be 0 
Sample_data_IDs2$Depth <-  ifelse((Sample_data_IDs2$Zone == "SW"), "0cm", Sample_data_IDs2$Depth)

#Create IDs from what was collected for comparison later
Sample_data_IDs2 <- Sample_data_IDs2 %>%
  mutate(Sample_ID = paste(Site, Date, Zone, Replicate, Depth, sep = "_"))

#Change the SW lines because they don't have lysimeters or a depth  
Sample_data_IDs2 <- Sample_data_IDs2 %>%
  mutate(
    Sample_ID = if_else(
      Zone == "SW",
      # Modify the string:
      Sample_ID %>%
        str_replace("_LysA", "_A") %>%                    # Replace "_LysA" with "_A"
        str_replace("_LysB", "_B") %>%                    # Replace "_LysB" with "_B"
        str_replace("_LysC", "_C") %>%                    # Replace "_LysC" with "_C"
        str_replace("_0cm$", ""),                          # Remove trailing "_0cm"
      Sample_ID  # else keep original
    )
  )

##Capitalize all sample IDs
Sample_data_IDs2$Sample_ID <- toupper(Sample_data_IDs2$Sample_ID)
  
```

```{r combine samples from 20251114 and 20251110}
Sample_data_IDs <- rbind(Sample_data_IDs1, Sample_data_IDs2)
Sample_data_IDs$IDs <- NULL
```


##Remove ADL/BDL samples that were later diluted differently
```{r Remove ADL/BDL samples that were later diluted differently, include = FALSE}

#filter the high CV data in to one table
HighCV<-filter(Sample_data_IDs, H2S_cv_flag=="High CV")

#filter out the samples that need to be run at a higher dilution
ADL<-filter(Sample_data_IDs, H2S_Conc_flag=="adl")

#remove the samples that have already been run at a higher dilution 
ww_ADL<-subset(Sample_data_IDs, (Sample_ID %in% ADL$Sample_ID))
ww_ADL<-filter(ww_ADL, H2S_Conc_flag=="Within_Range") 
ADL_not_fixed<-ADL %>% 
  subset((!Sample_ID %in% ww_ADL$Sample_ID)) %>% 
  subset((!Sample_ID %like% " Dup")) %>% 
  subset((!Sample_ID %like% " Spike"))

#filter out the samples that need to be run at a lower dilution
BDL<-filter(Sample_data_IDs, H2S_Conc_flag=="bdl"& Dilution!=1)

#remove the samples that have already been run at a lower dilution 
ww_BDL<-subset(Sample_data_IDs, (Sample_ID %in% BDL$Sample_ID))
ww_BDL<-filter(ww_BDL,H2S_Conc_flag=="Within_Range") 
BDL_not_fixed<-BDL %>% 
  subset((!Sample_ID %in% ww_BDL$Sample_ID)) %>% 
  subset((!Sample_ID %like% " Dup")) %>% 
  subset((!Sample_ID %like% " Spike"))


##Remove samples that were ADL/BDL and are now fixed
ADL_fixed<-ADL %>% 
  subset((Sample_ID %in% ww_ADL$Sample_ID)) %>% 
  subset((!Sample_ID %like% " Dup")) %>% 
  subset((!Sample_ID %like% " Spike"))
ADL_fixed$ID_conc <- paste(ADL_fixed$Sample_ID, ADL_fixed$H2S_Conc_flag, sep = "_")

BDL_fixed<-BDL %>% 
  subset((Sample_ID %in% ww_BDL$Sample_ID)) %>% 
  subset((!Sample_ID %like% " Dup")) %>% 
  subset((!Sample_ID %like% " Spike"))
BDL_fixed$ID_conc <- paste(BDL_fixed$Sample_ID, BDL_fixed$H2S_Conc_flag, sep = "_")


Sample_data_IDs$ID_conc <- paste(Sample_data_IDs$Sample_ID, Sample_data_IDs$H2S_Conc_flag, sep = "_")

Sample_data_wr <- Sample_data_IDs %>% 
  subset(!ID_conc %in% BDL_fixed$ID_conc) %>% 
  subset(!ID_conc %in% ADL_fixed$ID_conc)

##If there are duplicates, remove the one with the lowest CV
Sample_data_nodups <- Sample_data_wr %>%
  arrange(Sample_ID, H2S_cv) %>% # Sort by ID ascending, Value ascending
  distinct(Sample_ID, .keep_all = TRUE) # Keep distinct IDs, retaining all other columns

print(HighCV)
print(ADL_not_fixed)
print(BDL_not_fixed)

```

##Pull in Metadata
```{r Pull in Metadata, include = FALSE}

Raw_Metadata = "Raw Data/COMPASS_SynopticCB_PW_SampleLog_2025.csv"

#read in the raw metadata file 
raw_metadata <- read.csv(Raw_Metadata)

#make a new columns in the metadata with important info:
metadata <- raw_metadata %>%
  mutate(Depth = paste0(Depth_cm, "cm")) %>%
  mutate(LysID = paste0("Lys", Lysimeter)) %>%
  mutate(YearMonth = sprintf("%d%02d", Year, Month))  %>%
  mutate(Zone = case_when(
    `Transect.Location` == "Transition" ~ "TR",
    `Transect.Location` == "Wetland"    ~ "WC",
    `Transect.Location` == "Upland"     ~ "UP",   
    `Transect.Location` == "Surface Water" ~ "SW",
    TRUE                 ~ `Transect.Location`    # keep original value if no match
  ))

#Create IDs from what was collected for comparison later
metadata <- metadata %>%
  mutate(H2S_ID = ifelse(SO4 == "x",
                                     paste(Site,
                                           YearMonth,
                                           Zone,
                                           LysID,
                                           Depth,
                                           sep = "_"),
                                     NA),  )

#Change the SW lines because they don't have lysimeters or a depth  
metadata <- metadata %>%
  mutate(
    H2S_ID = if_else(
      Zone == "SW",
      # Modify the string:
      H2S_ID %>%
        str_replace("_LysA", "_A") %>%                    # Replace "_LysA" with "_A"
        str_replace("_LysB", "_B") %>%                    # Replace "_LysB" with "_B"
        str_replace("_LysC", "_C") %>%                    # Replace "_LysC" with "_C"
        str_replace("_0cm$", ""),                          # Remove trailing "_0cm"
      H2S_ID  # else keep original
    )
  )

#Take out the columns and rows that are not relevant
sulfide_metadata <- metadata %>%
  dplyr::select(H2S_ID, Year, Month, Day, YearMonth, Site, Zone, Lysimeter, LysID, Depth_cm, 
         Depth, Time..24hr., Time.Zone_EDT.EST, Field.Notes, ) %>%        
  # only keep specific columns
  filter(!is.na(H2S_ID) & H2S_ID != "")  # remove missing/blank Cl_SO4_ID rows

head(sulfide_metadata)

```


##Check to see if samples run match metadata & merge info
```{r Check to see if samples run match metadata & merge info, echo = FALSE}

#check to see if all samples are present in the metadata 
Sample_data_nodups$Sample_ID <- toupper(Sample_data_nodups$Sample_ID)
sulfide_metadata$H2S_ID <- toupper(sulfide_metadata$H2S_ID)

all_present <- all(Sample_data_nodups$Sample_ID %in% sulfide_metadata$H2S_ID)

if (all_present) {
  message("All sample IDs are present in metadata.")
} else {
  message("Some sample IDs are missing from metadata.")
  
  # Optional: Which ones are missing?
  missing_ids <- setdiff(Sample_data_nodups$Sample_ID, sulfide_metadata$H2S_ID)
  print(missing_ids)
}

# missing_ids <- data.frame(missing_ids)
# 
# ##Export missing IDs to csv
# write.csv(missing_ids, "20250529_COMPASS_H2S_missing_IDs.csv")

##Remove Lys from Replicate Column
Sample_data_nodups <- Sample_data_nodups %>%
  mutate(Replicate = gsub("Lys", "", as.character(Replicate)))%>%
  mutate(Replicate = gsub("lys", "", as.character(Replicate)))

##Remove cm units from Depth
Sample_data_nodups$Depth_cm <- gsub("cm", "", Sample_data_nodups$Depth)

##Select only necessary columns
all_data_selected <- Sample_data_nodups %>%
  dplyr::select(-c("ID_conc", "Depth"))

all_data_selected$Depth_cm <- as.integer(all_data_selected$Depth_cm)

##Select only necessary columns
sulfide_metadata_selected <- sulfide_metadata %>%
  dplyr::select(H2S_ID, Year, Month, Day, Depth_cm, Lysimeter, Time..24hr., Time.Zone_EDT.EST,  Field.Notes) 

#merge metadata with sample run data 
merged_data <- all_data_selected %>%
  left_join(sulfide_metadata_selected, by = c("Sample_ID" = "H2S_ID", "Replicate" = "Lysimeter", "Depth_cm"))


```


## Visualize Data by Plot   
```{r Visualize Data, echo=FALSE, warning=FALSE}

#Plot samples to get a first look at concentrations (sanity check)
data_plotting <- merged_data

#Order by Zone from Upland to Surface Water
data_plotting$Zone = factor(data_plotting$Zone, levels = c("UP",  "SWAMP","TR", "WC", "SW"))
data_plotting <- data_plotting[order(data_plotting$Zone), ]

#Order by Site from SWH, GCW, MSM, GWI order, which is oligohaline to polyhaline
data_plotting$Site = factor(data_plotting$Site, levels = c("SWH", "GCW", "MSM", "GWI"))
data_plotting <- data_plotting[order(data_plotting$Site), ]

#group the data for plotting
data_plotting <- data_plotting %>%
  group_by(Site) %>%
  mutate(row_num = factor(row_number())) %>%  # create row_num as factor per group
  ungroup()

#Plot data and change colors based on Zone:
viz_H2S_plot <- ggplot(data_plotting, aes(x = row_num, y = H2S_mean, fill = Zone)) +
  geom_bar(stat = "identity", position = position_dodge2(preserve = "single")) +
  facet_grid(~ Site, scales="free") +
  scale_fill_manual(values = c(
    "UP" = "#20063B",
    "SWAMP" = "darkgrey",
    "TR" = "#FFBC42",
    "WC" = "#419973",
    "SW" = "#25ABE6"
  )) +
  theme_classic() +
  theme(axis.text.x = element_blank()) +
  labs(x = " ", y = "Sulfide (uM)", title = "Samples: Sulfide") +
  scale_x_discrete(drop = TRUE)+
  geom_text(aes(label = ifelse(H2S_mean == 0, "0", "")), vjust = -0.5)+
  theme(
    panel.spacing = unit(.05, "lines"), 
    panel.border = element_rect(color = "black", fill = NA, linewidth = 0.1))

viz_H2S_plot

```


##Export Combined Data
```{r Export Combined Data, include = FALSE}

#Prepare data to be exported - if there is anything else to add 
#Add any necessary identifiers to the samples  ### VERY IMPORTANT AND STANDARD FOR PROJECT ####
  #example read in sample IDs list and merge 
  #create required ID columns in R, etc. 
final_data <- merged_data %>% 
  mutate(
    Project = "COMPASS: Synoptic",   # new column with same value on every row
    Region = "CB", 
    Analysis_rundate = "20250925" #need to make it so this comes out in plate processed file
  ) 

colnames(final_data)

final_data <- final_data %>%
  rename(
    Time = Time..24hr.,
    Time_Zone = Time.Zone_EDT.EST,
    Field_notes = Field.Notes
    # add more rename pairs as needed
  ) %>%
  dplyr::select(
    Project, Region, Site, Zone, Replicate, Depth_cm, 
         Sample_ID, Year, Month, Day, Time, Time_Zone,
         H2S_mean, H2S_sd, H2S_cv, H2S_Conc_flag, H2S_cv_flag, H2S_QAQC_flag, Dilution, 
         Analysis_rundate, Field_notes
        # list columns in the order you want them
  )

head(final_data)

#Write out final data frame 
write.csv(final_data, "COMPASS_H2S_202511_Plates_Combined.csv")

#Write out samples that still have high CVs
write.csv(HighCV, "COMPASS_H2S_202511_Plates_HighCVs.csv")

#Write out ADL samples
write.csv(ADL_not_fixed, "COMPASS_H2S_202511_Plates_ADL.csv")

#Write out BDL samples
write.csv(BDL_not_fixed, "COMPASS_H2S_202511_Plates_BDL.csv")


```


##END